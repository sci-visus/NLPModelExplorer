\section{Evaluation and Feedback}

The initial motivation for designing the proposed tool is driven by the error analysis challenges faces by NLP researchers working on the natural language inference task. We work closely with two NLP experts, and their constant evaluation and feedback have guided the design and development process.
%
However, since the two NLP experts are heavy involved in the design process, they may be blinded for the potential problems of the tool due to familiarity.  In order to undercover the limitation and identify areas for improvements we gathered a wider audience from both visualization (4 researchers include 3 Ph.D. level student and one postdoc researcher) and NLP background (5 Ph.D. level students who are familiar with the concept of natural language inference and attention) for the evaluation of the tool.  

We first conduct an informal feedback session with the visualization group, with the goal to identify the potential interface design issues. During the feedback session, we first explain the NLP concept in an easily to approach manner, and then demonstrate the feature of tool in detail, while answering questions and address comments.
%
From this session, we have gather a number of complaints and suggestion on improve the user interface. These  including difficult to distinguish predictions, hard to recognize ground truth label, as well as the lack of legends to understand the key elements in several plot. We address these interface issues in the version of tool presented to the NLP group.

We then conduct a revaluation session with the NLP group, in which each of the participants is given 30 minutes to experiment with the tool after an overall feature demonstration. As the participants explore the tool, we continue answering more detailed questions regarding the individual component, as well as on how we implement the model update feature.
%
One participant hypothesis about the role attention is playing. After playing with the tool, he show us two sentence pair that he think is interesting. One sentence give a correct final prediction but he tell us that when he see the attention layer, the alignment is incorrect. At the other example, he show us a sentence pair which give a wrong prediction, he force two sentence?s attention to align but the final prediction is still incorrect. He tell us that through those two example  he can tell that a alignment may not give the correct prediction and correct prediction does not mean correct alignment. 
%
The other interesting observation that he get is that once he force the incorrect final prediction to the ground truth label. In the update pipeline,  he observed that only update the attention stage won?t make the current sentence pair to the correct prediction. 
%
After explaining the tool, the one participant try to use two same sentences and check how each component of the platform show. He also negate the meaning of a sentence ``A couple is taking a break from bicycling .''  by using ``A couple is not taking a break from bicycling .'' and see whether the relationship between two sentence is contradiction. He also comment that the ability to enable and disable update in the pipeline view is really helpful.
%
Overall, all the user think this tool is very convenient for them to verify their hypothesis and help them build a better intuition to improve the current model.


