\firstsection{Introduction}
\maketitle

% (What is the high level motivation)
% What is the obsatcle for effectively apply machine learning model
With the recent advances in neural network based model, machine learning has
gained unprecedented popularity, and its adaption permeated many fields of studies.
%
However, from researchers to practitioners, one often need to overcome many
obstacles during the training, debugging, and tuning processes to unleash
the full potential of these models.
%
Identify where and how does the error occur and understand why does the model
fail is critical to the design and application of various models.
%quickly identify where the errors are
However, providing meaningful answers to these questions is an extremely challenging task.
% Naturally the identification of failure scenarios is an essential first step in diagnosing procedure.
%the potential limitation of the test dataset
On the one hand, the standard evaluation approach provides limited information. The performance number (i.e., prediction accuracy on the test set) alone often cannot answer many important questions for the model diagnostic process. Understanding what the often made mistakes are, and how sensitive are the model concerning perturbation in the input, etc., are instrumental. On the other hand, understanding why the model fails is challenging as well, which undoubtedly will require the ability to peek inside the model and make sense of the critical internal mechanisms.

Making sense and explaining predictions made by neural networks is also becoming a necessity with increasing demands for model accountability (e.g., what is the evidence for making the decision) and model fairness (e.g., is the prediction affected by the bias in the training data).
%
Due to these demands, many works have been dedicated to providing intuitive explanations for a given prediction. Such a system often approach the problem from a model agnostic approach that made them applicable to different applications (i.e., by fitting a simplier linear model near the prediction of interests).
%
However, despite being invaluable for the prediction interpretation task these methods often cannot adequately address the challenge in the model diagnostic process. More importantly, due to the model agnostic nature, they lack of the ability to access and explore the internal states of the model, which is vitally important to make sense of why a model fail.

In this work, we introduce a visualization system that through a tight yet flexible integration between visual analytic elements and the underlying model, allow a user to interrogate the model by perturbing the input, the internal state, as well as prediction while observing changes in other parts of the pipeline.
We use textual entailment task~\cite{BowmanAngeliPotts2015} as an example to illustrate how this system help natural language processing (NLP) researchers quickly identify the potential limitation of an NLP model and probe the inner states of the model for interpreting key mechanism such as attention.

% ######## Why use perturbation ###########
% Iterate the model design and debug the system hinged on the ability to quickly
% identify the errors made by a model.
%
% Perturbe the input is what NLP researchers have subconsciously been doing to study and test a model.
%
% Interpret/probe the relationship between attention and the prediction result


The key contributions of the proposed works is summarized as the following:
\begin{itemize}
    \item Identify the mistakes made by the model through perturbation of input sentences and visual summarization of the predictions;

    \item Enhance the visual representation of attention by overlaying sentence linguistic structure to allow grammar guided simplification;

    \item Enable the interrogation of the attention mechanism by interactively exploring how the change in prediction affect the attention and vice versa while fixing other part of the model

\end{itemize}

% NLP application using attention
% \begin{itemize}
%     \item Neural translation
%     \item Text summarization
%     \item Text entailment
%     \item Text comprehension (question answering)
% \end{itemize
%
%
% Attention type:
% \begin{itemize}
%     \item soft vs. hard
%     \item local vs. global
%     \item hierarchical
%     \item attention over attention
%     \item gated
% \end{itemize}
