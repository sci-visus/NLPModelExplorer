\firstsection{Introduction}
\maketitle

% (What is the high level motivation)
% What is the obsatcle for effectively apply machine learning model
With the recent advances in neural network based model, machine learning has
gained unprecedented popularity, and its adaption permeated many fields of studies.
%
However, from researchers to practitioners, one often need to overcome many
obstacles during the training, debugging, and tuning processes to unleash
the full potential of these models.
%
Identify where and how does the error occur and understand why does the model
fail is critical to the design and application of various models.
%quickly identify where the errors are
However, providing meaningful answers to these questions is an extremely challenging task.
% Naturally the identification of failure scenarios is an essential first step in diagnosing procedure.
%the potential limitation of the test dataset
On the one hand, the standard evaluation approach provides limited information. Often only performance number is used (i.e., prediction accuracy on the test set) without answering many important questions for the diagnostic process. It would be instrumental to understand what are the often made mistakes, and how sensitive are the model concerning perturbation in the input, etc. On the other hand, the understanding why the model fails is even more challenging, which likely require the ability to peak into the model and make sense of the key mechanisms.

Making sense and explaining predictions made by neural networks is also becoming a necessity with increasing demands for model accountability (e.g., what is the evidence for making the decision) and model fairness (e.g., is the prediction affected by the bias in the training data).
%
Due to these demands, many works have been dedicated to providing a more intuitive explanation for a given prediction. Such a system often approach the problem from a model agnostic approach that made them applicable to different applications (i.e., by fitting a similar linear model near the sample of interests).
%
However, these methods despite being invaluable for the prediction interpretation task cannot adequately address the challenge in the model diagnostic process. More importantly, due to the model agnostic nature, they often the lack of the ability to access and explore the inner states of the model, which is vitally important to make sense of why a model fail.

In this work, we introduce a visualization system that through a tight yet flexible integration between visualization and the underlying model, allow a user to interrogate the model by perturbing the input, the internal state, as well as prediction while observing changes in other parts of the pipeline.
We use textual entailment task~\cite{} as an example to illustrate how this system can help natural language processing (NLP) researchers quickly identify the potential limitation of an NLP model and also probe the inner states of the model for interpreting key mechanism such as attention.

% ######## Why use perturbation ###########
% Iterate the model design and debug the system hinged on the ability to quickly
% identify the errors made by a model.
%
% Perturbe the input is what NLP researchers have subconsciously been doing to study and test a model.
%
% Interpret/probe the relationship between attention and the prediction result


The key contributions of the proposed works is summarized as the following:
\begin{itemize}
    \item Allow user to quickly identify the mistakes made by the model through input perturbation and visual summerization;

    \item Introduce visual encoding for interpreting the attention that incorporate sentence linguistic structure;

    \item Interactively explore the relationship between attention and prediction via constrained optimization
\end{itemize}

% NLP application using attention
% \begin{itemize}
%     \item Neural translation
%     \item Text summarization
%     \item Text entailment
%     \item Text comprehension (question answering)
% \end{itemize
%
%
% Attention type:
% \begin{itemize}
%     \item soft vs. hard
%     \item local vs. global
%     \item hierarchical
%     \item attention over attention
%     \item gated
% \end{itemize}
