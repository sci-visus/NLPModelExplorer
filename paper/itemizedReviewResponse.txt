Response to the reviews

We greatly appreciate all reviewers' valuable comments. The summary of major changes are listed below. We have itemized the 44 questions/comments and answer each individually.

Summary of major changes:
- Revised section 6 to better convey the relationship between the different scenarios and provide further clarification on the result observed in 6.3.
- Revised the introduction to remove hyperbole words, clarify the NLP vs. CNN data modality comparison, and simplify the contribution list.
- Clarified the domain experts' involvement at the beginning of section 4, and link the task with the application scenarios.
- Revised section 5 to better explain the user interactions and add discussion on how to interpret the visual encodings.
- Reworked the video, included a new introduction section and added a voiceover.

------------------------------- Reviewer 1 -------------------------------


Q1. The usage scenarios also look interesting, especially the Scenario 3. Does the result to some extent suggest that the attention mechanism is not a very efficient component in this task? I expect the authors dig it further.

A: The domain experts find this observation very interesting and suggest a preliminary interpretation. They believe the attention provides a way to compose word semantics. Individual word semantics are yielded from the encoder and input embedding, while the composed semantics participate in classification layer. From this analysis, we can extrapolate that the ultimate decision relies on the semantics (i.e., encodings and composed encodings in classifier). The encoder and classifier layer can swiftly adjust weights for word/composed semantics to correct prediction. But the attention layer, which only works on how individual words are aligned, affects the prediction less significantly. Recent works also support this observation in word embeddings, e.g., ELMo~\cite{salant2017contextualized}, where better word embeddings can substantially benefit a model. However, it by no means implies attention is not useful, as it serves as a way to compose word semantics although it does not directly output that. We revised section 6.3 to include this comment on the interpretation of the visualization result.


Q2. In Section 2, the neural net in NLP and attention mechanisms are introduced. But the descriptions are unsatisfactory. There is no formal definition or description of the model and the attention mechanism. It's still unclear how the attention mechanism is applied in the model. I would suggest the authors include a concise and formal introduction in the background part and include some formula.

A: The exact computation of attention can vary from model to model despite the shared overall concept, i.e., the alignment between words. As a result, when we discuss the general concept of attention we can not fix on a single mathematical formulation. The exact formulation for the model we investigated is discussed in Appendix A. 


Q3, In Section 4, the paper indicates that the system is developed under a long-term collaboration with NLP experts, but there is no description describing the details of the collaboration (the number of experts, the length and the form of the collaboration, the frequency of the meetings). It's not until Section 7 did I learn that there are 2 NLP experts in collaboration. The task analysis can also be improved by including more detailed justification of the three tasks.

A: We had added additional details of the collaboration at the beginning of section 4, including the number of NLP collaborators, frequency, duration of the meeting period for the proposed work.


Q4, The presentation of the system design in Section 5 could be improved.
- In Section 5.2, Attention View includes both a bipartite graph and a matrix view, which visualize the same information. From the description of the paper, the graph view is only good for highlighting the most dominant alignments. I suspect that matrix view can also reveal the most dominant alignments by identifying the most salient color. Please justify the design decision.

A: The advantage of the bipartite graph is the ability to allow the domain experts to quickly uncover not only the most dominant alignments but also the corresponding words. However, in the matrix view, it takes the user more efforts to link the strong alignment with the corresponding words (especially if there are several strong alignments). We have updated the text to better reflect this point.


Q5, It's unclear how the simplification of attention representation is done from Section 5.2, please include more details.

A: The simplification is achieved by replacing the children of the dependency tree structure with the parents. We assume by focusing on the more important grammar structure, we can remove the decorative words and the reduce sentence length to focus on the more crucial part of the sentences. We have revise the section 5.2 to clarify the simplification process.


Q6, In Section 5.3, how do you compute the density contour? Why is a contour needed in the analysis?

A: We employed the standard kernel density estimation technique in 2D. As stated in Section 5.3, the primary motivation is to highlight overlapped point (where multiple predictions fall on top of/near each other) and identify outliers. We have included the description for density computation in Section 5.3.


Q7, It's better if the authors present the relation between Section 5.3 and 5.4 in a clearer way. It's confusing to read how one can perturb a prediction in Section 5.3 before he/she read the algorithm in Section 5.4. I suggest put the algorithm along with the perturbation-driven paradigm at the beginning of Section 5.

A: Thanks for catching the ordering problem and providing a solution. To address the issue, we added references to the optimization discussed in section 5.4 at the beginning of section 5 as well as in section 5.3. We didn't move all the optimization discussion at the beginning of section 5, since we believe presenting details of the all three perturbations (input, attention, prediction) without any discussion about the interface can also be very confusing. And the separation between the operation and UI component may also make the description hard to read (require the reader to refer back to the computation discussion when describing the user interface). We believe the revised version provide a decent tradeoff.


Q8, Except for the presentation issue, the contribution of this paper is somewhat limited to only NLI models with attention mechanisms. It's not sure how the visualization can be easily extended for other NLP tasks. For example, I am not sure how the proposed visualization can easily adapt to machine translation, considering that there are no neutral/contradiction/entailment labels.

A: The composability of the system is the key to extend its capability. The proposed API allows the user to include only the view that is necessary for the given task. For new task (i.e., machine translation), we do not need to include the prediction view for the NLI task. We can reuse the attention views to representing the alignment between the original sentence and the translated sentence and introduce new views for visualizing other information that may not present in the NLI model. The main idea is to allow user to combine the view/functionality and add new view if necessary to suit their analysis goals.


Q9, In addition, the perturbation-driven scheme is somewhat related to the gradient-based analysis (both are the local analysis of the model on a specific prediction). It is better if the authors discuss the two and differentiate them.

A: Gradient-based sensitivity analysis can often be carried out for domain that is differentiable (i.e., image pixel values). In the proposed work, the challenge of using gradient-based method in NLP actually inspired us to utilize perturbation. This point is partly discussion in the introduction where the difference between NLP and CV is highlighted (image has a differentiable domain).


Q10, The evaluation is acceptable but a bit weak. There is no description of what questions have the authors asked during the evaluation sessions. It would be better to have formal interviews and ask the participants to perform specific tasks and observe how they performed.

A: We didn't design a specific list of tasks and the corresponding answers mostly due to the the open-ended analysis goal. If the user didn't follow the particular exploration path the designer of the question goes, he/she might find some unexpected result that may not directly correspond to the "correct" answer, but instead viewing the problem from a different perspective. However, we do believe extensive evaluation the system is extremely important. We plan to recruit more domain experts to test and evaluate the system in the future.


Q11, Please also proofread the work and fix typos. For example, the word 'work' in Section 3 should be uncountable; In Section 5.3, "the three points defines a triangle" -> "the three points defining a triangle"

A: Thanks for pointing out the grammar issues, we have fixed the mentioned problem. And the renewed version has been through a copy edit pass by an editor.

------------------------------- Reviewer 2 -------------------------------

Q12, A brief guidance of how to interpret visual patterns that emerge in each view would be very beneficial. In particular, did the authors notice any systematic / repetitive patterns in the triangular prediction view? Do these patterns indicate certain issues in the model / attention / perturbation schemes?

A: As discussed in the experiment of section 6.1, the spread of the pattern directly corresponds to the stability of the prediction. A recurring pattern we noticed is illustrated in Fig. 9(d), where the given sentence pair has low stability due to the fact the original prediction is a boundary prediction (probability is in between two classes). In addition, the perturbation procedure will also affect the pattern as the longer sentence will likely have more perturbed variations (contains more nouns and verbs). We include a brief discussion on the potential variability caused by the perturbation procedure in section 5.4.

Q13, Same thing applies to the attention heatmap, the parameter histograms, and the overview scatterplots in Figure 8 (e.g. does the curve in Figure 8d tell us something?)

A: The curve patterns in the Figure 8d are likely caused by the different number of words that was perturbed (i.e., each line pattern corresponds to sentence pairs that include the same numbers of nouns plus verbs that will be perturbed). This demonstrates the added variation the perturbation bring into the system. We include a brief discussion on the additional variability caused by the perturbation procedure and sentence length in section 5.4.

Q14, Discuss scalability of the system. Can it visually handle long sentences? Would collapsing the heatmaps help here? Can it handle a large number of sentences? This is important for the noted future applicability to question answering where the data items can be as large as text documents.

A: The key rationale for collapsing the sentence to reduce the length while still preserving the primary structure of the sentence. Therefore, the collapsing operation will significantly improve the scalability of the show a long sentence. However, it may not suitable for a whole paragraph (multiple sentences), when the length of collapsed sentence can still be too long to be effectively represented in the matrix or bipartite graph view. For the task such as machine comprehension, in which the context paragraph and be extremely long, we likely will need a hierarchical type of structure.

Q15, Explain more about the Bowman's dataset in use [24], its dimensionality, coverage, complexity, language features, etc.

A: The SNLI dataset (https://nlp.stanford.edu/projects/snli/) includes "570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral". Therefore, it does not have a direct connection to the word embedding dimension or language features. It is a benchmark dataset for natural language processing task, which can be attacked by different types of models. In our case, we investigated a typical neural network based approach.


Q16, A brief discussion of the applicability to other languages would be interesting maybe? Any anticipated challenges?

A: Since we have utilized Unicode text encoding throughout the code, the proposed system can be easily adapting to other alphabetical languages (however, we have not tested the capability). One potential challenge may be originated from NLP training dataset, as there are not many large-scale training data in languages other than English.

Q17, Add label to the color scale in Figure 3 (the caption mentions attention by just to avoid confusion). Same for Figure 7a (frequency to the vertical axis), Figure 8b, and Figure 9a-c.

A: We've added caption "attention" to the color scale as well as the "frequency" captions to the histograms.

Q18, Add narration to the video and maybe include a 1-min self-contained demo of the system before illustrating the use cases in the video.

A: We have added an introduction section to illustrate the NLP problem and interface. We also included voice over to make understanding the content easier.

Q19, Language mispredictions (misspelling):
As discussion in [8, 13]
tasks T1-3 (maybe T1-T3?)
correspondance
studys

A: these errors have been fixed.

------------------------------- Reviewer 3 -------------------------------

Q20, After the teaser image, the paper spends the first four pages on neural networks, NLP, and inference. One has to look hard to detect the lede in the next to last paragraph of the introduction ("Moreover, we propose...") Highlight it!

A: We have revised the last paragraph of the introduction to highlight the visualization contributions. The text following "Moreover, we propose..." is not the only place describe visualization contributions, the integrated model pipeline that allows user perturbation in all stages is another contribution, the same holds for the visual encoding for the prediction for the NLI problem.

Q21, Even as a visualization-centric researcher who is aware of NNs and has done a little direct work in NLP, I found it hard to connect to the organization and balance of coverage of these topics in the paper. Despite the prominent teaser visualization and the description of individual views in section 5, the paper comes off as very visualization-light.

A: We appreciated the reviewer's comment as organizing a visualization paper for a domain specific application is a very challenge task. The rationale for our current organization is that the NLP background provides the minimally necessary information for the average reader to understand the application problem. It is an essential part of the paper which make it self-contained. In addition, a lot of the technical details is directly connected to how the visualization encoding is designed (such as the attention view and prediction view). Without a sufficient understanding of the model and related NLP background, it would be impossible for the reader to understand the purpose of most views and the application scenarios. Finally, we also try to compress the background information, we spend less than one page on the background, even though other sections mentioned NLP related topics but they mostly still focus on presenting the visualization system.


Q22,For each view there it's clear what the visual representation is, but the majority of description is dedicated to the underlying mechanics of calculating and thinking about the NL inference. The specific interactions involved are also mostly implied, although I was able to deduce them. They should be made explicit.

A: We've revised descriptions to make interaction more explicit (i.e., for the prediction, attention, summary view).


Q23, How does one handle very different sentence lengths in the sentence view?

A: One can expand the text box to include multiple lines to show the longer sentence. There is no particular encoding here since we are just showing the raw text.


Q24, What if the sentence structures between premise and hypothesis are not drastically different; will the matrix be as effective, and thus the graph need to be focused on?

A: If the sentence structures are drastically different, the matrix view may be the better option as the structure difference likely result in crossed lines in the bipartite graph view, which can lead to poorer perception. The most significant benefit of the graph is the ability for the domain expert to see the connection between words directly. In the matrix, one needs to first identify the high-value entry and then finding the corresponding row and column to recognize the words. If there are multiple correspondences, the user needs to check them one by one in the matrix view.


Q25, In the matrix view, how hard is it to control rows when they're renormalizing?

A: For the given model there are two attention matrices, one have row normalization while the other has column normalization. We follow the same rule to apply renormalization after sentence collapsing.


Q26, How much reduction in the grammar dependency tree is necessary to combat visual clutter, and how does that relate to the expert's ability to dissect sentences at the desired level of detail?

A: The amount of necessary reduction is influenced by the structure of the sentences as well as the capability of the parser. There is a trade-off between visual clutter and text readability. The more collapse is equal to less visual clutter, but likely reduce the readability of the text. The From our experiment, we notice the NLP experts have a far better capability to understand the collapsed sentence compared to others. The desired level should be a good trade-off based on the expert's preference.



Q27, How do the matrices combined in figure 5f align for comparison?

A: We make sure to only compute the comparison when the two matrices are of same size and utilizing the same normalization pattern.


Q28, Why does the prediction view use a continuous interaction like drag when the target is to select one of only three discrete options?

A: There are two rationales to design the re-assignment as drag. Firstly, the semantic of changing prediction corresponds well to a drag operation. We initially plan to implement the re-assignment as a continuous drag operation. However, we believe it is more meaningful for a human to assign discrete labels (instead of a probability). Secondly, we want to distinguish this action from the mouse click which is reserved for selection operation.


Q29, What happens in the prediction view if many predictions are close to each other? Between the predictions and the density contour map, the view could get very dense, particular if much data is involved from the 10k set.

A: The number of points in the prediction view is limited by the number of perturbations per sentence pair. In another word, we will only look at one sentence pair at a time for the detailed analysis. The motivation for including the density contour is to help convey the overlapping information.


Q30, In the pipeline view, doesn't the formulation to approximate the assigned label introduce another black box that the user need to factor into their analytic thinking?

A: The MIRA optimization process indeed introduces unpredictability and opaqueness in the solution. To mitigate the limitation, we provide a summary of the parameter changes in the pipeline view to help reveal the effect of the optimization on the parameters. Moreover, we can also utilize the attention visualization to interpret the impact of the optimization. Finally, our MIRA optimization is a simplified version that only added a L2 regularization on the weight change during backpropagation. Compared to an end-to-end neural network (which is often referred to as a black box) this optimization has a more restricted setting that is easier to interpret as we are only fitting the model to the given instance. 



Q31, Why a treemap in the summary view? It's just a 3x3 set of quantities. A simple 3x3 matrix heatmap would be more familiar, more readable, and assure that all of the prediction/label combinations are large enough to select easily.

A: We agree that a 3x3 heatmap (essentially a confusion matrix) is also an efficient alternative to represent the summary prediction result. The motivation to use treemap is that it provides a more direct encoding for conveying the count (area instead of a variation of colors). And the separate between orange and green tile also intuitively expresses the correct and incorrect predictions. However, we do think a confusion matrix like encoding could also be beneficial. In the future, we plan to add the confusion matrix as an alternative so that the user can use either one of them based on their preference.


Q32, The description of interaction for the E/E category in the summary view says what one can do, but it's not clear how or why.

A: The description is revised, we specified the exact operation the user need to take.


Q33, Part of the problem is that the language is very dense in this paper. Although the grammar is acceptable, it was a slow read and there were some passages that I found all but indecipherable, such as the figure 7 caption, the last paragraph of section 5.5, and the bullet list at the end of the introduction.

A: We've revised the text in the mentioned sections to improve the readability.


Q34, There were many small errors that need correcting, too many to bother listing here. There was also some hyperbole ("stunning", "unprecedented", "vision", "paradigm") that distracts me as a serious reader and should be replaced. A thorough copyediting should fix both issues.

A: We removed/replaced the words mentioned by the reviewer. For example, we updated the first sentence to "Demonstrated by many recent successes, neural networks based machine learning approaches have garnered increasing popularity, and have been adopted in a wide variety of applications."


Q35, The application scenarios in section 6 look useful taken individually, but I wonder about how they are used in combination. The scenarios essentially describe individual tasks that experts might perform in individual views. Scenario 4 goes a little further, but is brief. The paper would very much benefit from a more complete example story of how an analyst might work with the various views in concert to perform higher-level activities. For an application paper like this, some sense of those activities, and how well the tool design works for them, is needed. The last couple paragraphs of section 7 offers only a glimpse of "interrogation" as the authors say.
Their conclusion (participants believe it convenient) isn't sufficiently supported. As it stands, there isn't clear justification of the many visualization design choices. A longer scenario encompassing the larger process would go a long way toward rectifying that.

A: These different scenarios are interconnected and often arise naturally during the exploration sessions. The scenarios 1 is often used as the first step to identify the sentence pair of interests (the user can also manually type the one they interested in scenarios 5). Then the user can close examine the individual pair as shown in scenarios 2, 3, 4 (depend on what question they want to ask). We included a brief discussion on how these scenarios related to each other and expanded the scenarios 3 to include domain experts'  interpretation of the result. We didn't following a specific exploration path of a single user, because they may focus on only one or two scenarios and repeatedly applied the same analysis on different data, which may not be the best way to showcase the variety of the functionality this tool can provide.


Q36, The supplemental materials are okay. The video should be editing to speed up the (slow!) interactions and preferably include audio.

A: We have revised the video and included voice over and a simple introduction at the beginning.


------------------------------- Reviewer 4 -------------------------------

Q37, I was confused by the distinction between image networks and language networks. CNNs are not only used to make binary classifications, and there are certainly challenges in image networks that do not provide "clear meaning" and seem like they would also benefit from the proposed work. In other words, I understand the focus on NLP tasks, but the reasoning for it doesn't seem accurate (in the 3rd paragraph of the introduction).

A: In the introduction, we want to highlight the input modality difference. Continuous for the image, and discrete for natural language. The difference has introduced additional challenge especially regarding optimization as well as interpretation. In addition, in CNN we often can reveal human interpretable neuron filter (but these methods can not be easily generalized for NLP), whereas the attention is often the only interpretable part of the NLP model. We have updated the description in the introduction to better convey this message.

Q38, It was unclear to me if the idea of perturbing a model is novel, or an extension/visualization of previously introduced work in this area applied to NLP NNs. If it's the former (as it seems to be), then I think this needs to be emphasized in the introduction.

A: The perturbation of nouns and verbs on itself is not novel from NLP perspective, and truly solving the challenge of producing grammatically correct and meaningful perturbation/paraphrasing is still an open research area. In our case, we believe the novelty comes from the integration of the model with the three-stage perturbation scheme in an explorable visual analytic system. We have revised the introduction to highlight the core contribution.

Q39, I appreciated the task analysis in section 4. However, it seems a bit too brief, and the tasks don't seem to directly follow from the description of the authors experience with the NLP researchers. The scenarios described in Section 6 provide much more detail about these tasks, and Section 5 clarifies them as well, but a bit more detail here would be useful. For example, it's not clear who the NLP researchers are, how many of them were interviewed, what type of NLP projects they were working on, etc.

A: We moved the description of the collaboration into the beginning of section 4, in which we described the number of NLP experts, frequency, and the duration of the meeting for this specific projects. We also added a reference to application scenarios that corresponds to the tasks to help instantiate the more abstract concepts.

Q40, Work by Ma et al. ("Visualizing dynamic brain networks using an animated dual-representation" from EuroVis 2015) is work related to NLIZE having both graph and matrix views that complement each other and provide the same information from different perspectives, as described in Section 5.2.

A: We've cited this work in Section 5.2 when discussing the due visual representations.

Q41, Placing the grammar dependency tree over the matrix / bipartite graph is interesting (described in Section 5 and Section 6.4). I wonder if it would make sense to use other types of annotations here, such as those created from event extraction tools or information extraction tools that would highlight other structures (besides grammar/POS) that could be useful in helping understanding the inference model. Work by Forbes et al. supports the use of semantic hypergraphs to provide richer textual annotations alongside text sequences ("Text annotation graphs: Annotating complex natural language phenomena" from LREC 2018).

A: After discussing with domain experts, we believe the reviewer's comment would be a very interesting direction for future works. Coming up with efficient visual encoding for these types of information that go beyond grammar tree is a challenge on its own. For example, the extract structure can be a graph (instead of a tree), which likely requires a complete redesign of the existing visualization.

Q42, In Sections 6.1 and 6.2, the application scenario gives an example of having a user perturbing the model by changing the input words (switching ?pile? with ?heap?). This updates the system and changes the inference output. Are the successful results of such an interaction remembered by the system? That is, could NLIZE be used to tweak/update the model so that, say, the ambiguity between pile and heap is automatically and more accurately resolved in future queries?

A: In the current system, we did not record the user interaction/correction result. The MIRA optimization update may correct the model for the given example (to some extend overfit to the example), however, we don't think there is a guarantee that the fix can be readily generalized to other cases. Also, the ambiguity between pile and heap may also originate from the word embedding (the numerical input representation for words). The proposed system suggests to NLP experts that the ambiguity between pile and heap is likely the cause of the incorrect prediction. The experts can choose to dive further and close examine the root cause.

Q43, Section 6.3 is very interesting, but I don't understand why perturbing the attention stage has less of an effect that the other perturbations. This seems like a preliminary contribution in and of itself (i.e., that using the NLIZE application leads to global understanding such as this), and worthy of further examination.

A: As discussed in the answer for Q1, the domain experts mentioned that they are interested in exploring more from NLP perspective to understand this result fully. They also provide some preliminary explanation. We included them in the revised 6.3 section.

Q44, The application scenarios are all quite brief and come across as somewhat preliminary, but on the other hand, the range of tasks that are supported shows the promise of such an approach. It might make more sense to focus more on only one or two scenarios and cover them in more depth.

A: We added an overview at the beginning of section 6 to illustrate how different tasks related to one another and provided additional discussion on section 6.3 to dive deeper into the interpretation of the result.
