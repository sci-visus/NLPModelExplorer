Response to the reviews

We greatly appreciate all reviewers' valuable comments. The summary of major changes are listed below. We have itemized the 35 questions/comments and answer each individually.

Summary of major changes:
1. Revise section 6 to better convey the relationship between the different senarios and provide further clarification on the result observered in 6.3


------------------------------- Reviewer 1 -------------------------------


Q1. The usage scenarios also look interesting, especially the Scenario 3. Does the result to some extent suggest that the attention mechanism is not a very efficient component in this task? I expect the authors dig it further.

A: To interpret the result, we need to carry out a case by case analysis, as the separation of the stages depends on the individual implementation. In this case, the result indicates that the tunable parameters of the attention stage (the transformation before the alignment operation, see details in Appendix A) has less impact on the final prediction compared to the other two stages. The domain experts comment that this observation is interesting and worth further investigation from the perspective of NLP research. However, this result does not necessarily imply the limitation of attention mechanism as the core alignment computation does not have tunable parameters that can be modified by the proposed optimization. We revised section 6.3 to clarify this point.


Q2. In Section 2, the neural net in NLP and attention mechanisms are introduced. But the descriptions are unsatisfactory. There is no formal definition or description of the model and the attention mechanism. It's still unclear how the attention mechanism is applied in the model. I would suggest the authors include a concise and formal introduction in the background part and include some formula.

A: The exact computation of attention can vary from model to model, though the overall concept is shared as they are specially designed for understanding the corresponding relationship between sequence of texts.

Q3, In Section 4, the paper indicates that the system is developed under a long-term collaboration with NLP experts, but there is no description describing the details of the collaboration (the number of experts, the length and the form of the collaboration, the frequency of the meetings). It's not until Section 7 did I learn that there are 2 NLP experts in collaboration. The task analysis can also be improved by including more detailed justification of the three tasks.

A: We had added additional details of the collobration in the begining of the section 4, include the number of NLP collaborators, frequency, duration of the meeting for this specific tasks.

Q4, The presentation of the system design in Section 5 could be improved.
- In Section 5.2, Attention View include both a bipartite graph and a matrix view, which visualize the same information. From the description of the paper, the graph view is only good for highlighting the most dominant alignments. I suspect that matrix view can also reveal the most dominant alignments by identifying the most salient color. Please justify the design decision.

A: The advantage of the bipartite graph is not only the ability to allow the domain experts quickly understand the domain alignment but more importantly the corresponding words. However, in the matrix view, it is much harder to instantaously link the alignment with the corresponding words. [We update the text to better reflect this point]

Q5, It's unclear how the simplification of attention representation is done from Section 5.2, please include more details.

A: The simplification is achieve by collapsing the dependency tree structure. We assume by focusing on the more important grammar structure, we can remove the decorative words and the reduce sentence length to focus on the more crucial part of the sentences.

Q6, In Section 5.3, how do you compute the density contour? Why is a contour needed in the analysis?

A: We employed the standard kernel density estimation technique in 2D. As stated in Section 5.3, the primary motivation is to highlight overlaped point (where multiple prediction fall on top of each other) and identify outliers.

Q7, It's better if the authors present the relation between Section 5.3 and 5.4 in a clearer way. It's confusing to read how one can perturb a prediction in Section 5.3 before he/she read the algorithm in Section 5.4. I suggest put the algorithm along with the perturbation-driven paradigm at the beginning of Section 5.

A: Thanks for catching the ordering problem and providing a soluation. To address the problem, we add references to the optimization discussed in section 5.4 in the beginning of section 5 as well as in section 5.3. We didn't move all the optimization discussion in the beginning of the section 5, because we believe that presenting details of the all three perturbations (input, attention, prediciton) without any discussion about the interface can also be confusing. And the separation between the operation and UI componenet may also make the description hard to read (requre the reader to refer back to the computation discussion while describing the user interface)

Q8, Except for the presentation issue, the contribution of this paper is somewhat limited to only NLI models with attention mechanisms. It's not sure how the visualization can be easily extended for other NLP tasks. For example, I am not sure how the proposed visualization can easily adapt to machine translation, considering that there are no neutral/contradiction/entailment labels.

A: The composability of the system is the key to extend its capability. The proposed API allow user to include only the panel that is necessary for the given task. For new task (i.e., machine translation), we do not need to include the prediction view for NLI task. We can reuse the attention view to representating the alignment between the original sentence and the translated sentence and introduce new panel for visualizing other information that may not present in the NLI model. However, the main idea is to allow use the combine the panels/functionality to suit their goals.

Q9, In addition, the perturbation-driven scheme is somewhat related to the gradient-based analysis (both are the local analysis of the model on a specific prediction). It is better if the authors discuss the two and differentiate them.

A: Gradient-based sensitivity analysis can often be carried out for domain that is differentiable (i.e., image pixel values), however, for natural language sentences these techniques often can not directly be adopted directly. [?? add the discussion to where?]

Q10, The evaluation is acceptable but a bit weak. There is no description of what questions have the authors asked during the evaluation sessions. It would be better to have formal interviews and ask the participants to perform specific tasks and observe how they performed.

A: We didn't design a specific list tasks and the corresponding answers due to the exploratory nature of system as well as the open ended analysis goal. If the user didn't follow the particular exploration path the designer of the question goes, it may find some unexpected result that may not directly corresponds to the "correct" answer, but view the problem from a different perspective. However, to properly evaluation the proposed technique is extremely important, so we plan to recurite more domain experts to test and evaluation the system in the new future.

Q11, Please also proofread the work and fix typos. For example, the word 'work' in Section 3 should be uncountable; In Section 5.3, "the three points defines a triangle" -> "the three points defining a triangle"

A: Thanks for pointing out the grammar issues, we have fixed the mentioned problem. And the renew version has been through a thorough copy edit pass by an editor.

------------------------------- Reviewer 2 -------------------------------

Q12, A brief guidance of how to interpret visual patterns that emerge in each view would be very beneficial. In particular, did the authors notice any systematic / repetitive patterns in the triangular prediction view? Do these patterns indicate certain issues in the model / attention / perturbation schemes?

A: As discussed in the experiment of section 6.1, the spread of the pattern directly corresponds to the stability of the prediction. A recurring pattern we noticed is illustrated in Fig. 9(d), where the given sentence pair have low stability due to the fact the original prediction is a boundary prediction (probability is in between two classes). In addition, the perturbation procedure will also affect the pattern as longer sentence will likely have more perturbed variations (contains more nouns and verbs). We include a brief discusison on the potential variability caused by the perturbation procedure in section 5.4.

Q13, Same thing applies to the attention heatmap, the parameter histograms, and the overview scatterplots in Figure 8 (e.g. does the curve in Figure 8d tell us something?)

A: The curve pattern in the Figure 8d are likely cause by the different number of words that was perturbed (i.e., each line pattern corresponds to sentence pair that include the same number of nouns and verbs that to be perturbed). This illustrate the additional variation the perturbation bring into the system. We include a brief discusison on the potential variability caused by the perturbation procedure in section 5.4.

Q14, Discuss scalability of the system. Can it visually handle long sentences? Would collapsing the heatmaps help here? Can it handle a large number of sentences? This is important for the noted future applicability to question answering where the data items can be as large as text documents.

A: The key rational for collasping the sentence to reduce the length while still preserving the main structure of the sentence. Therefore, the collasping operation will greatly improve the scability of the show a long sentence. However, it may not suitable for a whole paragraph (multiple sentence), when the length of collapsed sentence can still be too long to be effectively represented in the matrix or biparite graph view. For task such as machine comprehension, in which the context paragraph and be extremely long, we likely will need a hierarchical type of structure.

Q15, Explain more about the Bowman's dataset in use [24], its dimensionality, coverage, complexity, language features, etc.

A: The SNLI dataset (https://nlp.stanford.edu/projects/snli/) includes "570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral". Therefore, it does not have direct connection to the word embedding dimension or language features. It is a benchmark dataset for natural language processing task, which can be attacked by different type of models. In our case, we investigated a neural network based approach.

Q16, A brief discussion of the applicability to other languages would be interesting maybe? Any anticipated challenges?

A: Since we utilize unicode text representation through out the code, the proposed system can be easily adapting to other aphateical language (however, we have not test the capability). One potential challenge may originated from NLP training set, as there are not as many large scale training data in language other than english.

Q17, Add label to the color scale in Figure 3 (the caption mentions attention by just to avoid confusion). Same for Figure 7a (frequency to the vertical axis), Figure 8b, and Figure 9a-c.

A: We've added caption "attention" to the color scale as well as the "frequency" captions to the histograms.

Q18, Add narration to the video and maybe include a 1-min self-contained demo of the system before illustrating the use cases in the video.

A: We add an introduction section to illustrate the NLP problem and interface. We also include voice over to better convey the contains.

Q19, Language mispredictions (misspelling):
As discussion in [8, 13]
tasks T1-3 (maybe T1-T3?)
correspondance
studys

A: these errors have been fixed.

------------------------------- Reviewer 3 -------------------------------

Q20, After the teaser image, the paper spends the first four pages on neural networks, NLP, and inference. One has to look hard to detect the lede in the next to last paragraph of the introduction ("Moreover, we propose...") Highlight it!

A: We have revise the last paragraph of the introduction to highlight the visualization contributions. The text following "Moreover, we propose..." is not the only place describe visualization contributions, the integrated model pipeline that allow user perturbation in all stages is another contribution, the same holds for the visual encoding for the prediction for the NLI problem.

Q21, Even as a visualization-centric researcher who is aware of NNs and has done a little direct work in NLP, I found it hard to connect to the organization and balance of coverage of these topics in the paper. Despite the prominent teaser visualization and the description of individual views in section 5, the paper comes off as very visualization-light.

A: We appreciated the reviewer concern as organizing a visualization paper for a domain specific application is a very challenge task. The rational for our current orgnaiziation is that the NLP background provides the minimally necessary information for the average reader to understand the application problem. It is an essential part of the paper which make it self-contained. In addition, a lot of the technical details is directly connected to how the visualization encoding is designed (such as the attention view and prediction view). Without a highlevel understanding of the model, it would be impossible for the reader to understand the purpose of most views and the application senarios. Finally, we also try to compress the background information, we spend less than one page on the background, even through other sections mentioned NLP related topics but they mostly still focus on presenting the visualization system.


Q22,For each view there it's clear what the visual representation is, but the majority of description is dedicated to the underlying mechanics of calculating and thinking about the NL inference. The specific interactions involved are also mostly implied, although I was able to deduce them. They should be made explicit.

A: [We've revised descriptions to make interaction more explicit. TODO]


Q23, More importantly, there is little rationale for the visual representation designs of the various views. The design choices do make sense (at least to an experienced visualization designer) but there are alternatives in each case. It's not clear that the visualization are particularly good or bad for their intended uses as described in section 6. A few questions that arise:

* How does one handle very different sentence lengths in the sentence view?

A: One can expand the text box to include multiple line to show the longer sentence. There is no special encoding here, since we are just showing the raw text.

* What if the sentence structures between premise and hypothesis are not drastically different; will the matrix be as effective, and thus the graph need to be focused on?

A: If the sentence structures are drastically different, the matrix view may have benefit as the structure difference likely result in crossed lines in the biparite graph view, which can lead to poorer perception. The biggest benefit of the graph is the ability for the domain expert to directly see the connection between words. In the matrix, one need to first identify the high value entry and then finding the corresponding row and column to identify the words. If there are multiple correspondences, the user need to check them one by one in the matrix view.

* In the matrix view, how hard is it to control rows when they're renormalizing?

A: For the given model there are two attention matrices, one have row normalization while the other have column normalization. We follow the same rule to apply renormalization after sentence collapsing.

* How much reduction in the grammar dependency tree is necessary to combat visual clutter, and how does that relate to the expert's ability to dissect sentences at the desired level of detail?

A: The amount of necessary reduction is influenced by the structure of the sentences as well as the capability of the parser. There is a trade-off between visual clutter and text readability. The more collapse is equal to less visual clutter, but likely reduce the readability of the text. The From our experiment, we notice the NLP experts have far better ability to understand the collapsed sentence compared to others. The desired level should be a good trade-off based on the experts preference.

* How do the matrices combined in figure 5f align for comparison?

A: We make sure to only compute the comparison when the two matrices are of same size and utilizing the same normalization pattern.

* Why does the prediction view use a continuous interaction like drag when the target is to select one of only three discrete options?

A: There are two rational to design the re-assignment as drag. Firstly, the semantic of changing prediction corresponds well to a drag operation. We intially plan to implement the re-assignment as a continuous drag operation. However, we believe it is more meaningful for human to assign discrete label (instead of a probability). Secondly, we want to distingish this action with click which is already reserved for selection operation.

* What happens in the prediction view if many predictions are close to each other? Between the predictions and the density contour map, the view could get very dense, particular if much data is involved from the 10k set.

A: The number of points in the prediction view is limited by the number of perturbations per sentence pair. In another work, we will only look at one sentence pair at a time for the detailed analysis. The motivation for including the density contour is to help convey the overlapping information.

* In the pipeline view, doesn't the formulation to approximate the assigned label introduce another black box that the user need to factor into their analytic thinking?

A: The MIRA optimization process indeed introduces unpredibility and opaqueness in the solution. To mitigate the limitation, we provide summary of the paramter changes in the pipeline view to help reveal the effect of the optimization on the parameter. Morever, we can also utilizing the attention visualization to interpret the effect the optimiztion. Finally, compared to a end-to-end neural network (which is often referred to as a blackbox) this optimization has a more restricted setting as we are only fitting the model to the given example instead of jointly optimizing for the entire dataset.


* Why a treemap in the summary view? It's just a 3x3 set of quantities. A simple 3x3 matrix heatmap would be more familiar, more readable, and assure that all of the prediction/label combinations are large enough to select easily.

A: We agree that a 3x3 heatmap (essentially a confusion matrix) is also an efficient alternative to represent the summary prediction result. The motivation is use treemap is that it provides a more direct encoding for conveying the count (area instead of variation of colors). And the separate between orange and green tile intuitively convey the correct and incorrect predictions. However, we do think a confusion matrix like encoding could also be beneficial. In the future, we plan to add the confusion matrix as an alternative, so the user can use either one of them based on their preference.

* The description of interaction for the E/E category in the summary view says what one can do, but it's not clear how or why.

A:

Q24, Part of the problem is that the language is very dense in this paper. Although the grammar is acceptable, it was a slow read and there were some passages that I found all but indecipherable, such as the figure 7 caption, the last paragraph of section 5.5, and the bullet list at the end of the introduction.

A: These sections has been revised to improve the readability.

Q25, There were many small errors that need correcting, too many to bother listing here. There was also some hyperbole ("stunning", "unprecedented", "vision", "paradigm") that distracts me as a serious reader and should be replaced. A thorough copyediting should fix both issues.

A: We remove/replace the words mentioned by the reviewer. For example, the following is the updated first sentence of the introduction in which "stunning", "unprecedented" are removed. "Demonstrated by many recent successes, neural networks based machine learning approaches have garnered increasing popularity, and have been adopted in a wide variety of applications."


Q26, The application scenarios in section 6 look useful taken individually, but I wonder about how they are used in combination. The scenarios essentially describe individual tasks that experts might perform in individual views. Scenario 4 goes a little further, but is brief. The paper would very much benefit from a more complete example story of how an analyst might work with the various views in concert to perform higher-level activities. For an application paper like this, some sense of those activities, and how well the tool design works for them, is needed. The last couple paragraphs of section 7 offers only a glimpse of "interrogation" as the authors say.
Their conclusion (participants believe it convenient) isn't sufficiently supported. As it stands, there isn't clear justification of the many visualization design choices. A longer scenario encompassing the larger process would go a long way toward rectifying that.

A: These different senarios should naturally arise during the exploration session, the senarios 1 is often the first step to identify the sentence pair of interests (the user can also manually type the one they interested in senarios 6).

Q27, The supplemental materials are okay. The video should be editing to speed up the (slow!) interactions and preferably include audio.

A: We have revised the video and included voice over and a simple introduction in the begninning.


------------------------------- Reviewer 4 -------------------------------

Q28, I was confused by the distinction between image networks and language networks. CNNs are not only used to make binary classifications, and there are certainly challenges in image networks that do not provide "clear meaning" and seem like they would also benefit from the proposed work. In other words, I understand the focus on NLP tasks, but the reasoning for it doesn't seem accurate (in the 3rd paragraph of the introduction).

A: In the introduction we want to highlgith the input modality different. Continuous for image, and discrete for natural language. The different has introduced additional challenge especially regarding optimization as well as interpretation. In addition, in CNN we often can reveal human interpretable neuron filter, but these method has been generalized for NLP. The attention is the exception, which represent often the only interpretable part of the model.

Q29, It was unclear to me if the idea of perturbing a model is novel, or an extension/visualization of previously introduced work in this area applied to NLP NNs. If it's the former (as it seems to be), then I think this needs to be emphasized in the introduction.

A: The perturbation of nous and verbs on itself is not novel from NLP perspective, and truly solving the challenge of producing grammarly correct and meaningful perturbation/paraphrasing is still an open research area. In our case, we believe the novality come from the integration of the model with the three stage perturbation scheme in an explorable visual analytic system.

Q30, I appreciated the task analysis in section 4. However, it seems a bit too brief, and the tasks don't seem to directly follow from the description of the authors experience with the NLP researchers. The scenarios described in Section 6 provide much more detail about these tasks, and Section 5 clarifies them as well, but a bit more detail here would be useful. For example, it's not clear who the NLP researchers are, how many of them were interviewed, what type of NLP projects they were working on, etc.

A: We moved the description of the collabration into the beginning of section 4, in which we describe the number of NLP experts, frequency, and the duration of the meeting for this specific projects. We also add pointer to application senarios that corresponds to the tasks to instantiate the more abstract concepts.

Q31, Work by Ma et al. ("Visualizing dynamic brain networks using an animated dual-representation" from EuroVis 2015) is work related to NLIZE having both graph and matrix views that complement each other and provide the same information from different perspectives, as described in Section 5.2.

A: We've citated this work in Section 5.2 when discussing the due visual representations.

Q32, Placing the grammar dependency tree over the matrix / bipartite graph is interesting (described in Section 5 and Section 6.4). I wonder if it would make sense to use other types of annotations here, such as those created from event extraction tools or information extraction tools that would highlight other structures (besides grammar/POS) that could be useful in helping understanding the inference model. Work by Forbes et al. supports the use of semantic hypergraphs to provide richer textual annotations alongside text sequences ("Text annotation graphs: Annotating complex natural language phenomena" from LREC 2018).

A: After discussing with domain experts, they believe this would be a very interesting direction for future works. Coming up with efficient visual encoding for these type of information they go beyond grammar tree is a challenge on its own. For example the extract structure can be graph, which likely require a complete redesign of the annotation visualization.

Q33, In Sections 6.1 and 6.2, the application scenario gives an example of having a user perturbing the model by changing the input words (switching ?pile? with ?heap?). This updates the system and changes the inference output. Are the successful results of such an interaction remembered by the system? That is, could NLIZE be used to tweak/update the model so that, say, the ambiguity between pile and heap is automatically and more accurately resolved in future queries?

A: In the current system, we did not record the user interaction/correction result. The mira optimization update may correct the model for the given example (to some extend overfit to the example), however, we don't think there is guarantee that the fix can be easily generalized to other examples. In addition, the ambiguity between pile and heap may also originated from the word embedding (the input numerical representation for words). What the proposed system do is to communicate to the NLP experts that the ambiguity between pile and heap is likely the cause of the wrong prediciton. The experts can chose to dive further and examine the problem with their NLP background.

Q34, Section 6.3 is very interesting, but I don't understand why perturbing the attention stage has less of an effect that the other perturbations. This seems like a preliminary contribution in and of itself (i.e., that using the NLIZE application leads to global understanding such as this), and worthy of further examination.

A: As discussion in the answer for Q1, the core attention operation is not tunable, only the intial transformation in the beginning of the attention stage includes tunable parameters. This can partially explain the result. However, the domain experts mentioned they are interested in exploring more from NLP perspective to understand this result fully.

Q35, The application scenarios are all quite brief and come across as somewhat preliminary, but on the other hand, the range of tasks that are supported shows the promise of such an approach. It might make more sense to focus more on only one or two scenarios and cover them in more depth.

A: We added a overview in the begining of the section 6 to illustrate how different tasks related to one another and provide addtional discussion on section 6.3.
