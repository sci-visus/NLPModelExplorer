\firstsection{Introduction}
\maketitle

With the advances of deep learning, neural network based models have reset the state-of-the-art for nearly all linguistic tasks in natural language processing. The disruptive advance also brings enormous challenges. The opaque nature of neural network model leads to hard to debug system and difficult to interpret mechanism~cite{}. In this work, we use textual entailment task as an example to illustrate how a flexible visualization system can not only help NLP researchers quickly identify the potential limitation of a neural models and also probe the inner states of model for interpreting key mechanism such as attention.


(What is the high level motivation)

The importance of attention visualization.
For natural language processing application, the discrete nature of words and sentences presents additional challenge in interpreting the model. Recently, the advances in attention mechanism~\cite{} allow simpler models to match or even outperform more complex / deeper models by exploiting the alignment of bits of local text between sentences. The new challenges


% ####### Model Interpretability Section ##########
Making sense and explaining predictions made by deep neural networks is not only essential for validating and improving the model, but also becoming a necessity with increasing demands for model accountability (e.g., what is the evidence for making the decision) and model fairness (e.g., is the prediction affected by the bias in the training data).

However, investigating the inner mechanism of the model and explaining the model prediction is still an extremely challenging task.

% ######## Why use perturbation ###########
Iterate the model design and debug the system hinged on the ability to quickly and identify the errors made by a model.

Perturbe the input is what NLP researchers have subconsciously been doing to study and test a model.

Interpret/probe the relationship between attention and the prediction result


% NLP application using attention
% \begin{itemize}
%     \item Neural translation
%     \item Text summarization
%     \item Text entailment
%     \item Text comprehension (question answering)
% \end{itemize
%
%
% Attention type:
% \begin{itemize}
%     \item soft vs. hard
%     \item local vs. global
%     \item hierarchical
%     \item attention over attention
%     \item gated
% \end{itemize}
