loading word vector from ./data/glove.hdf5
loading data from ./data/snli_1.0-train.hdf5
loading data from ./data/snli_1.0-val.hdf5
Epoch: 1, Batch: 1000/9683, LR: 0.0500, Grad: 0.13/68.05, Loss: 1.0990, Acc: 0.3392, Speed: 149.5k, Time: 9.2019
Epoch: 1, Batch: 2000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0952, Acc: 0.3572, Speed: 150.3k, Time: 18.1815
Epoch: 1, Batch: 3000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0921, Acc: 0.3672, Speed: 151.1k, Time: 27.3083
Epoch: 1, Batch: 4000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0900, Acc: 0.3736, Speed: 151.8k, Time: 36.4878
Epoch: 1, Batch: 5000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0882, Acc: 0.3784, Speed: 151.3k, Time: 45.6565
Epoch: 1, Batch: 6000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0873, Acc: 0.3809, Speed: 151.8k, Time: 54.8065
Epoch: 1, Batch: 7000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0863, Acc: 0.3833, Speed: 151.4k, Time: 63.9658
Epoch: 1, Batch: 8000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0798, Acc: 0.3923, Speed: 151.1k, Time: 73.1576
Epoch: 1, Batch: 9000/9683, LR: 0.0500, Grad: 0.13/194.67, Loss: 1.0726, Acc: 0.4015, Speed: 150.7k, Time: 82.3329
Train 0.4074
Val 0.4982
1	0.407430	0.498222

saving model to local_300_parikh
Epoch: 2, Batch: 1000/9683, LR: 0.0500, Grad: 1.08/83.42, Loss: 0.9958, Acc: 0.4912, Speed: 147.4k, Time: 9.1506
Epoch: 2, Batch: 2000/9683, LR: 0.0500, Grad: 1.06/90.95, Loss: 0.9926, Acc: 0.4942, Speed: 147.8k, Time: 18.3022
Epoch: 2, Batch: 3000/9683, LR: 0.0500, Grad: 1.06/90.95, Loss: 0.9888, Acc: 0.4966, Speed: 149.6k, Time: 27.2292
Epoch: 2, Batch: 4000/9683, LR: 0.0500, Grad: 1.06/90.95, Loss: 0.9857, Acc: 0.4994, Speed: 150.1k, Time: 36.3352
Epoch: 2, Batch: 5000/9683, LR: 0.0500, Grad: 1.06/90.95, Loss: 0.9830, Acc: 0.5024, Speed: 150.2k, Time: 45.5092
Epoch: 2, Batch: 6000/9683, LR: 0.0500, Grad: 0.84/90.95, Loss: 0.9810, Acc: 0.5050, Speed: 150.3k, Time: 54.6987
Epoch: 2, Batch: 7000/9683, LR: 0.0500, Grad: 0.84/90.95, Loss: 0.9786, Acc: 0.5071, Speed: 151.0k, Time: 63.8201
Epoch: 2, Batch: 8000/9683, LR: 0.0500, Grad: 0.84/90.95, Loss: 0.9765, Acc: 0.5099, Speed: 151.1k, Time: 73.0340
Epoch: 2, Batch: 9000/9683, LR: 0.0500, Grad: 0.84/127.10, Loss: 0.9746, Acc: 0.5124, Speed: 151.1k, Time: 82.2547
Train 0.5145
Val 0.5580
1	0.407430	0.498222
2	0.514475	0.557972

saving model to local_300_parikh
Epoch: 3, Batch: 1000/9683, LR: 0.0500, Grad: 1.56/95.53, Loss: 0.9480, Acc: 0.5493, Speed: 149.7k, Time: 9.1409
Epoch: 3, Batch: 2000/9683, LR: 0.0500, Grad: 1.56/147.67, Loss: 0.9407, Acc: 0.5563, Speed: 149.6k, Time: 18.2797
Epoch: 3, Batch: 3000/9683, LR: 0.0500, Grad: 0.41/147.67, Loss: 0.9291, Acc: 0.5641, Speed: 150.9k, Time: 27.4319
Epoch: 3, Batch: 4000/9683, LR: 0.0500, Grad: 0.41/147.67, Loss: 0.9210, Acc: 0.5689, Speed: 150.4k, Time: 36.5682
Epoch: 3, Batch: 5000/9683, LR: 0.0500, Grad: 0.41/147.67, Loss: 0.9119, Acc: 0.5742, Speed: 151.1k, Time: 45.7255
Epoch: 3, Batch: 6000/9683, LR: 0.0500, Grad: 0.17/147.67, Loss: 0.9069, Acc: 0.5768, Speed: 151.3k, Time: 54.8607
Epoch: 3, Batch: 7000/9683, LR: 0.0500, Grad: 0.05/147.67, Loss: 0.9011, Acc: 0.5800, Speed: 151.3k, Time: 63.9779
Epoch: 3, Batch: 8000/9683, LR: 0.0500, Grad: 0.05/169.50, Loss: 0.8966, Acc: 0.5825, Speed: 151.4k, Time: 73.0890
Epoch: 3, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/169.50, Loss: 0.8923, Acc: 0.5851, Speed: 151.4k, Time: 82.0636
Train 0.5867
Val 0.6301
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119

saving model to local_300_parikh
Epoch: 4, Batch: 1000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8531, Acc: 0.6095, Speed: 149.8k, Time: 9.1256
Epoch: 4, Batch: 2000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8494, Acc: 0.6113, Speed: 150.6k, Time: 18.3448
Epoch: 4, Batch: 3000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8465, Acc: 0.6130, Speed: 150.8k, Time: 27.4670
Epoch: 4, Batch: 4000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8466, Acc: 0.6134, Speed: 151.3k, Time: 36.5688
Epoch: 4, Batch: 5000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8453, Acc: 0.6138, Speed: 150.5k, Time: 45.7220
Epoch: 4, Batch: 6000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8433, Acc: 0.6148, Speed: 150.7k, Time: 54.9354
Epoch: 4, Batch: 7000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8416, Acc: 0.6161, Speed: 150.8k, Time: 64.1220
Epoch: 4, Batch: 8000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8406, Acc: 0.6166, Speed: 150.3k, Time: 73.2559
Epoch: 4, Batch: 9000/9683, LR: 0.0500, Grad: 0.06/913.62, Loss: 0.8402, Acc: 0.6166, Speed: 150.3k, Time: 82.4238
Train 0.6171
Val 0.6415
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500

saving model to local_300_parikh
Epoch: 5, Batch: 1000/9683, LR: 0.0500, Grad: 0.02/107.87, Loss: 0.8209, Acc: 0.6288, Speed: 151.3k, Time: 9.1699
Epoch: 5, Batch: 2000/9683, LR: 0.0500, Grad: 0.02/107.87, Loss: 0.8183, Acc: 0.6328, Speed: 150.0k, Time: 18.3550
Epoch: 5, Batch: 3000/9683, LR: 0.0500, Grad: 0.02/130.87, Loss: 0.8173, Acc: 0.6331, Speed: 149.9k, Time: 27.5122
Epoch: 5, Batch: 4000/9683, LR: 0.0500, Grad: 0.02/130.87, Loss: 0.8186, Acc: 0.6323, Speed: 150.2k, Time: 36.6288
Epoch: 5, Batch: 5000/9683, LR: 0.0500, Grad: 0.02/130.87, Loss: 0.8180, Acc: 0.6325, Speed: 150.9k, Time: 45.6515
Epoch: 5, Batch: 6000/9683, LR: 0.0500, Grad: 0.02/153.71, Loss: 0.8158, Acc: 0.6340, Speed: 151.4k, Time: 54.8561
Epoch: 5, Batch: 7000/9683, LR: 0.0500, Grad: 0.02/153.71, Loss: 0.8148, Acc: 0.6351, Speed: 151.2k, Time: 64.0102
Epoch: 5, Batch: 8000/9683, LR: 0.0500, Grad: 0.02/153.71, Loss: 0.8130, Acc: 0.6361, Speed: 150.8k, Time: 73.2033
Epoch: 5, Batch: 9000/9683, LR: 0.0500, Grad: 0.02/153.71, Loss: 0.8122, Acc: 0.6367, Speed: 150.3k, Time: 82.3817
Train 0.6373
Val 0.6643
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262

saving model to local_300_parikh
Epoch: 6, Batch: 1000/9683, LR: 0.0500, Grad: 0.18/92.83, Loss: 0.7969, Acc: 0.6459, Speed: 151.1k, Time: 9.1656
Epoch: 6, Batch: 2000/9683, LR: 0.0500, Grad: 0.05/97.97, Loss: 0.7970, Acc: 0.6473, Speed: 150.5k, Time: 18.3341
Epoch: 6, Batch: 3000/9683, LR: 0.0500, Grad: 0.05/97.97, Loss: 0.7948, Acc: 0.6488, Speed: 150.5k, Time: 27.5032
Epoch: 6, Batch: 4000/9683, LR: 0.0500, Grad: 0.04/112.90, Loss: 0.7923, Acc: 0.6500, Speed: 151.3k, Time: 36.6778
Epoch: 6, Batch: 5000/9683, LR: 0.0500, Grad: 0.04/117.59, Loss: 0.7906, Acc: 0.6511, Speed: 151.4k, Time: 45.7922
Epoch: 6, Batch: 6000/9683, LR: 0.0500, Grad: 0.04/117.59, Loss: 0.7889, Acc: 0.6517, Speed: 151.1k, Time: 54.9556
Epoch: 6, Batch: 7000/9683, LR: 0.0500, Grad: 0.04/117.59, Loss: 0.7872, Acc: 0.6530, Speed: 151.1k, Time: 64.0541
Epoch: 6, Batch: 8000/9683, LR: 0.0500, Grad: 0.04/117.59, Loss: 0.7860, Acc: 0.6538, Speed: 150.8k, Time: 73.2776
Epoch: 6, Batch: 9000/9683, LR: 0.0500, Grad: 0.04/117.59, Loss: 0.7845, Acc: 0.6546, Speed: 150.4k, Time: 82.4138
Train 0.6554
Val 0.6870
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024

saving model to local_300_parikh
Epoch: 7, Batch: 1000/9683, LR: 0.0500, Grad: 0.02/111.71, Loss: 0.7656, Acc: 0.6650, Speed: 154.5k, Time: 9.0912
Epoch: 7, Batch: 2000/9683, LR: 0.0500, Grad: 0.02/114.74, Loss: 0.7642, Acc: 0.6659, Speed: 153.2k, Time: 18.2976
Epoch: 7, Batch: 3000/9683, LR: 0.0500, Grad: 0.02/114.74, Loss: 0.7629, Acc: 0.6663, Speed: 151.7k, Time: 27.4416
Epoch: 7, Batch: 4000/9683, LR: 0.0500, Grad: 0.02/114.74, Loss: 0.7624, Acc: 0.6668, Speed: 150.6k, Time: 36.6277
Epoch: 7, Batch: 5000/9683, LR: 0.0500, Grad: 0.02/114.74, Loss: 0.7617, Acc: 0.6677, Speed: 150.5k, Time: 45.7880
Epoch: 7, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/114.74, Loss: 0.7606, Acc: 0.6683, Speed: 150.6k, Time: 54.9566
Epoch: 7, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/114.74, Loss: 0.7605, Acc: 0.6681, Speed: 150.5k, Time: 64.1523
Epoch: 7, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/114.74, Loss: 0.7592, Acc: 0.6689, Speed: 150.7k, Time: 73.2842
Epoch: 7, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/114.74, Loss: 0.7580, Acc: 0.6696, Speed: 150.7k, Time: 82.4282
Train 0.6699
Val 0.6966
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576

saving model to local_300_parikh
Epoch: 8, Batch: 1000/9683, LR: 0.0500, Grad: 0.33/128.35, Loss: 0.7444, Acc: 0.6798, Speed: 148.0k, Time: 9.1607
Epoch: 8, Batch: 2000/9683, LR: 0.0500, Grad: 0.33/128.35, Loss: 0.7445, Acc: 0.6795, Speed: 149.4k, Time: 18.3458
Epoch: 8, Batch: 3000/9683, LR: 0.0500, Grad: 0.05/128.35, Loss: 0.7442, Acc: 0.6792, Speed: 149.2k, Time: 27.5293
Epoch: 8, Batch: 4000/9683, LR: 0.0500, Grad: 0.05/128.35, Loss: 0.7422, Acc: 0.6803, Speed: 149.8k, Time: 36.7178
Epoch: 8, Batch: 5000/9683, LR: 0.0500, Grad: 0.05/128.35, Loss: 0.7416, Acc: 0.6803, Speed: 149.4k, Time: 45.8997
Epoch: 8, Batch: 6000/9683, LR: 0.0500, Grad: 0.01/128.35, Loss: 0.7411, Acc: 0.6804, Speed: 150.0k, Time: 54.9513
Epoch: 8, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/153.11, Loss: 0.7395, Acc: 0.6813, Speed: 150.1k, Time: 64.1484
Epoch: 8, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/153.11, Loss: 0.7392, Acc: 0.6813, Speed: 150.4k, Time: 73.3290
Epoch: 8, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/153.11, Loss: 0.7385, Acc: 0.6816, Speed: 150.6k, Time: 82.4870
Train 0.6819
Val 0.7180
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016

saving model to local_300_parikh
Epoch: 9, Batch: 1000/9683, LR: 0.0500, Grad: 0.03/125.96, Loss: 0.7215, Acc: 0.6922, Speed: 146.4k, Time: 9.1669
Epoch: 9, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/125.96, Loss: 0.7266, Acc: 0.6888, Speed: 150.6k, Time: 18.3468
Epoch: 9, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/125.96, Loss: 0.7233, Acc: 0.6899, Speed: 151.0k, Time: 27.5380
Epoch: 9, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/143.22, Loss: 0.7204, Acc: 0.6918, Speed: 150.6k, Time: 36.6767
Epoch: 9, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/143.22, Loss: 0.7197, Acc: 0.6922, Speed: 150.0k, Time: 45.8294
Epoch: 9, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/143.22, Loss: 0.7200, Acc: 0.6921, Speed: 149.8k, Time: 55.0065
Epoch: 9, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/143.22, Loss: 0.7187, Acc: 0.6929, Speed: 149.5k, Time: 64.1521
Epoch: 9, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/143.22, Loss: 0.7168, Acc: 0.6940, Speed: 149.7k, Time: 73.3018
Epoch: 9, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/161.72, Loss: 0.7165, Acc: 0.6942, Speed: 150.1k, Time: 82.4498
Train 0.6943
Val 0.7289
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889

saving model to local_300_parikh
Epoch: 10, Batch: 1000/9683, LR: 0.0500, Grad: 0.61/112.58, Loss: 0.6979, Acc: 0.7032, Speed: 151.1k, Time: 9.2014
Epoch: 10, Batch: 2000/9683, LR: 0.0500, Grad: 0.49/137.86, Loss: 0.6966, Acc: 0.7049, Speed: 152.7k, Time: 18.1930
Epoch: 10, Batch: 3000/9683, LR: 0.0500, Grad: 0.01/137.86, Loss: 0.6953, Acc: 0.7055, Speed: 151.6k, Time: 27.3587
Epoch: 10, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/165.51, Loss: 0.6934, Acc: 0.7066, Speed: 151.4k, Time: 36.5566
Epoch: 10, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/165.51, Loss: 0.6924, Acc: 0.7073, Speed: 151.3k, Time: 45.7635
Epoch: 10, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/165.51, Loss: 0.6905, Acc: 0.7083, Speed: 151.4k, Time: 54.9006
Epoch: 10, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/165.51, Loss: 0.6874, Acc: 0.7099, Speed: 151.2k, Time: 64.0983
Epoch: 10, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/165.51, Loss: 0.6843, Acc: 0.7116, Speed: 151.0k, Time: 73.2977
Epoch: 10, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/165.51, Loss: 0.6816, Acc: 0.7131, Speed: 150.6k, Time: 82.4253
Train 0.7141
Val 0.7578
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850

saving model to local_300_parikh
Epoch: 11, Batch: 1000/9683, LR: 0.0500, Grad: 0.02/146.76, Loss: 0.6440, Acc: 0.7333, Speed: 149.4k, Time: 9.2202
Epoch: 11, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/146.76, Loss: 0.6417, Acc: 0.7341, Speed: 149.8k, Time: 18.4595
Epoch: 11, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/146.76, Loss: 0.6404, Acc: 0.7347, Speed: 150.9k, Time: 27.6157
Epoch: 11, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/146.76, Loss: 0.6401, Acc: 0.7352, Speed: 150.5k, Time: 36.8014
Epoch: 11, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/146.76, Loss: 0.6404, Acc: 0.7351, Speed: 149.7k, Time: 45.9232
Epoch: 11, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/215.84, Loss: 0.6395, Acc: 0.7357, Speed: 149.3k, Time: 55.0748
Epoch: 11, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/215.84, Loss: 0.6388, Acc: 0.7361, Speed: 149.7k, Time: 64.2781
Epoch: 11, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/215.84, Loss: 0.6375, Acc: 0.7367, Speed: 150.3k, Time: 73.2757
Epoch: 11, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/215.84, Loss: 0.6359, Acc: 0.7379, Speed: 150.3k, Time: 82.4564
Train 0.7382
Val 0.7765
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547

saving model to local_300_parikh
Epoch: 12, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/124.92, Loss: 0.6130, Acc: 0.7506, Speed: 150.1k, Time: 9.1105
Epoch: 12, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/145.00, Loss: 0.6108, Acc: 0.7520, Speed: 150.1k, Time: 18.3196
Epoch: 12, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/158.45, Loss: 0.6128, Acc: 0.7509, Speed: 150.0k, Time: 27.5074
Epoch: 12, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/158.45, Loss: 0.6135, Acc: 0.7507, Speed: 150.0k, Time: 36.6860
Epoch: 12, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/158.45, Loss: 0.6123, Acc: 0.7510, Speed: 150.2k, Time: 45.8540
Epoch: 12, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/158.45, Loss: 0.6125, Acc: 0.7505, Speed: 150.2k, Time: 55.0965
Epoch: 12, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/158.45, Loss: 0.6112, Acc: 0.7510, Speed: 149.8k, Time: 64.2640
Epoch: 12, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/158.45, Loss: 0.6101, Acc: 0.7514, Speed: 149.5k, Time: 73.4435
Epoch: 12, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/158.45, Loss: 0.6095, Acc: 0.7517, Speed: 149.6k, Time: 82.6179
Train 0.7519
Val 0.7930
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009

saving model to local_300_parikh
Epoch: 13, Batch: 1000/9683, LR: 0.0500, Grad: 0.08/142.48, Loss: 0.5903, Acc: 0.7597, Speed: 148.0k, Time: 9.1388
Epoch: 13, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/143.63, Loss: 0.5951, Acc: 0.7588, Speed: 149.6k, Time: 18.2594
Epoch: 13, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/180.95, Loss: 0.5949, Acc: 0.7587, Speed: 149.6k, Time: 27.4124
Epoch: 13, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/180.95, Loss: 0.5958, Acc: 0.7582, Speed: 146.9k, Time: 37.1417
Epoch: 13, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/180.95, Loss: 0.5952, Acc: 0.7584, Speed: 148.2k, Time: 46.2805
Epoch: 13, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/180.95, Loss: 0.5954, Acc: 0.7581, Speed: 148.7k, Time: 55.4150
Epoch: 13, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/180.95, Loss: 0.5959, Acc: 0.7576, Speed: 148.8k, Time: 64.4308
Epoch: 13, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.5948, Acc: 0.7583, Speed: 149.2k, Time: 73.6028
Epoch: 13, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.5936, Acc: 0.7589, Speed: 149.7k, Time: 82.7738
Train 0.7594
Val 0.7903
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265

skip saving model for perf <= 0.7930
Epoch: 14, Batch: 1000/9683, LR: 0.0500, Grad: 0.07/116.49, Loss: 0.5809, Acc: 0.7664, Speed: 149.6k, Time: 9.1607
Epoch: 14, Batch: 2000/9683, LR: 0.0500, Grad: 0.03/121.49, Loss: 0.5809, Acc: 0.7660, Speed: 149.8k, Time: 18.3325
Epoch: 14, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/123.37, Loss: 0.5803, Acc: 0.7659, Speed: 149.8k, Time: 27.4876
Epoch: 14, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/126.46, Loss: 0.5790, Acc: 0.7666, Speed: 150.3k, Time: 36.6069
Epoch: 14, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/126.46, Loss: 0.5773, Acc: 0.7676, Speed: 150.2k, Time: 45.7488
Epoch: 14, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/141.82, Loss: 0.5773, Acc: 0.7676, Speed: 149.8k, Time: 54.8999
Epoch: 14, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/153.24, Loss: 0.5760, Acc: 0.7684, Speed: 149.7k, Time: 64.0712
Epoch: 14, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/170.16, Loss: 0.5754, Acc: 0.7687, Speed: 150.3k, Time: 73.2123
Epoch: 14, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/170.16, Loss: 0.5751, Acc: 0.7689, Speed: 150.4k, Time: 82.3514
Train 0.7687
Val 0.8021
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053

saving model to local_300_parikh
Epoch: 15, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/135.97, Loss: 0.5528, Acc: 0.7802, Speed: 150.4k, Time: 9.1751
Epoch: 15, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/158.51, Loss: 0.5609, Acc: 0.7764, Speed: 149.6k, Time: 18.3164
Epoch: 15, Batch: 3000/9683, LR: 0.0500, Grad: 0.01/158.51, Loss: 0.5667, Acc: 0.7728, Speed: 150.8k, Time: 27.4290
Epoch: 15, Batch: 4000/9683, LR: 0.0500, Grad: 0.01/159.93, Loss: 0.5660, Acc: 0.7728, Speed: 151.4k, Time: 36.5504
Epoch: 15, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/159.93, Loss: 0.5662, Acc: 0.7728, Speed: 151.5k, Time: 45.7358
Epoch: 15, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/159.93, Loss: 0.5661, Acc: 0.7728, Speed: 151.0k, Time: 54.8769
Epoch: 15, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/159.93, Loss: 0.5656, Acc: 0.7730, Speed: 150.7k, Time: 63.9714
Epoch: 15, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/159.93, Loss: 0.5653, Acc: 0.7731, Speed: 150.6k, Time: 73.1971
Epoch: 15, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/159.93, Loss: 0.5649, Acc: 0.7732, Speed: 150.6k, Time: 82.3554
Train 0.7731
Val 0.8046
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593

saving model to local_300_parikh
Epoch: 16, Batch: 1000/9683, LR: 0.0500, Grad: 0.55/121.40, Loss: 0.5559, Acc: 0.7771, Speed: 151.6k, Time: 9.1127
Epoch: 16, Batch: 2000/9683, LR: 0.0500, Grad: 0.08/122.62, Loss: 0.5572, Acc: 0.7773, Speed: 150.4k, Time: 18.2163
Epoch: 16, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/122.62, Loss: 0.5531, Acc: 0.7789, Speed: 150.2k, Time: 27.3989
Epoch: 16, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/122.62, Loss: 0.5532, Acc: 0.7789, Speed: 150.6k, Time: 36.5503
Epoch: 16, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/144.41, Loss: 0.5531, Acc: 0.7792, Speed: 150.4k, Time: 45.6725
Epoch: 16, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/144.41, Loss: 0.5529, Acc: 0.7791, Speed: 151.2k, Time: 54.6562
Epoch: 16, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/149.83, Loss: 0.5525, Acc: 0.7793, Speed: 151.2k, Time: 63.7823
Epoch: 16, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/155.28, Loss: 0.5522, Acc: 0.7793, Speed: 151.1k, Time: 72.8941
Epoch: 16, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/165.61, Loss: 0.5522, Acc: 0.7794, Speed: 151.2k, Time: 81.9924
Train 0.7794
Val 0.8107
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690

saving model to local_300_parikh
Epoch: 17, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/148.17, Loss: 0.5431, Acc: 0.7832, Speed: 151.9k, Time: 9.1401
Epoch: 17, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/148.71, Loss: 0.5442, Acc: 0.7833, Speed: 150.3k, Time: 18.2821
Epoch: 17, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/148.71, Loss: 0.5456, Acc: 0.7819, Speed: 150.1k, Time: 27.4649
Epoch: 17, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/148.71, Loss: 0.5475, Acc: 0.7812, Speed: 150.7k, Time: 36.6412
Epoch: 17, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/148.71, Loss: 0.5479, Acc: 0.7807, Speed: 149.9k, Time: 45.8638
Epoch: 17, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/148.71, Loss: 0.5472, Acc: 0.7809, Speed: 149.9k, Time: 55.0183
Epoch: 17, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/148.71, Loss: 0.5466, Acc: 0.7812, Speed: 150.1k, Time: 64.1406
Epoch: 17, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/148.71, Loss: 0.5465, Acc: 0.7812, Speed: 150.2k, Time: 73.2728
Epoch: 17, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/148.71, Loss: 0.5462, Acc: 0.7813, Speed: 150.1k, Time: 82.5027
Train 0.7816
Val 0.8125
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519

saving model to local_300_parikh
Epoch: 18, Batch: 1000/9683, LR: 0.0500, Grad: 0.07/138.28, Loss: 0.5405, Acc: 0.7849, Speed: 148.7k, Time: 9.1559
Epoch: 18, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/138.28, Loss: 0.5428, Acc: 0.7834, Speed: 150.7k, Time: 18.1667
Epoch: 18, Batch: 3000/9683, LR: 0.0500, Grad: 0.01/138.28, Loss: 0.5419, Acc: 0.7835, Speed: 150.7k, Time: 27.2976
Epoch: 18, Batch: 4000/9683, LR: 0.0500, Grad: 0.01/138.28, Loss: 0.5412, Acc: 0.7842, Speed: 151.1k, Time: 36.4342
Epoch: 18, Batch: 5000/9683, LR: 0.0500, Grad: 0.01/138.28, Loss: 0.5404, Acc: 0.7848, Speed: 150.9k, Time: 45.5757
Epoch: 18, Batch: 6000/9683, LR: 0.0500, Grad: 0.01/138.28, Loss: 0.5396, Acc: 0.7851, Speed: 151.0k, Time: 54.7304
Epoch: 18, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/178.20, Loss: 0.5387, Acc: 0.7855, Speed: 151.4k, Time: 63.8392
Epoch: 18, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/178.20, Loss: 0.5380, Acc: 0.7858, Speed: 151.3k, Time: 72.9989
Epoch: 18, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/178.20, Loss: 0.5376, Acc: 0.7859, Speed: 151.0k, Time: 82.1541
Train 0.7859
Val 0.8114
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401

skip saving model for perf <= 0.8125
Epoch: 19, Batch: 1000/9683, LR: 0.0500, Grad: 0.12/134.49, Loss: 0.5317, Acc: 0.7870, Speed: 151.6k, Time: 9.1570
Epoch: 19, Batch: 2000/9683, LR: 0.0500, Grad: 0.07/140.50, Loss: 0.5349, Acc: 0.7855, Speed: 151.0k, Time: 18.3266
Epoch: 19, Batch: 3000/9683, LR: 0.0500, Grad: 0.07/146.16, Loss: 0.5351, Acc: 0.7862, Speed: 151.1k, Time: 27.4379
Epoch: 19, Batch: 4000/9683, LR: 0.0500, Grad: 0.07/146.16, Loss: 0.5332, Acc: 0.7868, Speed: 151.0k, Time: 36.5730
Epoch: 19, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/146.16, Loss: 0.5317, Acc: 0.7877, Speed: 151.0k, Time: 45.7259
Epoch: 19, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/146.16, Loss: 0.5315, Acc: 0.7882, Speed: 151.4k, Time: 54.8284
Epoch: 19, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/146.16, Loss: 0.5305, Acc: 0.7887, Speed: 151.4k, Time: 63.9956
Epoch: 19, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/148.83, Loss: 0.5305, Acc: 0.7884, Speed: 151.4k, Time: 72.9894
Epoch: 19, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/148.83, Loss: 0.5308, Acc: 0.7885, Speed: 151.0k, Time: 82.1229
Train 0.7881
Val 0.8128
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824

saving model to local_300_parikh
Epoch: 20, Batch: 1000/9683, LR: 0.0500, Grad: 0.11/136.92, Loss: 0.5284, Acc: 0.7902, Speed: 151.3k, Time: 9.1589
Epoch: 20, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/136.92, Loss: 0.5241, Acc: 0.7926, Speed: 152.1k, Time: 18.3080
Epoch: 20, Batch: 3000/9683, LR: 0.0500, Grad: 0.01/141.63, Loss: 0.5257, Acc: 0.7920, Speed: 150.5k, Time: 27.5036
Epoch: 20, Batch: 4000/9683, LR: 0.0500, Grad: 0.01/145.01, Loss: 0.5271, Acc: 0.7914, Speed: 150.2k, Time: 36.6752
Epoch: 20, Batch: 5000/9683, LR: 0.0500, Grad: 0.01/145.01, Loss: 0.5261, Acc: 0.7917, Speed: 149.7k, Time: 45.8694
Epoch: 20, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/145.01, Loss: 0.5255, Acc: 0.7919, Speed: 149.2k, Time: 55.0923
Epoch: 20, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/145.01, Loss: 0.5254, Acc: 0.7920, Speed: 149.9k, Time: 64.2346
Epoch: 20, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/145.01, Loss: 0.5250, Acc: 0.7925, Speed: 149.7k, Time: 73.4701
Epoch: 20, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/145.01, Loss: 0.5253, Acc: 0.7922, Speed: 150.0k, Time: 82.6571
Train 0.7922
Val 0.8195
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531

saving model to local_300_parikh
Epoch: 21, Batch: 1000/9683, LR: 0.0500, Grad: 0.07/131.52, Loss: 0.5161, Acc: 0.7965, Speed: 146.9k, Time: 9.1456
Epoch: 21, Batch: 2000/9683, LR: 0.0500, Grad: 0.05/164.33, Loss: 0.5184, Acc: 0.7955, Speed: 149.6k, Time: 18.2950
Epoch: 21, Batch: 3000/9683, LR: 0.0500, Grad: 0.05/164.33, Loss: 0.5219, Acc: 0.7934, Speed: 149.4k, Time: 27.4142
Epoch: 21, Batch: 4000/9683, LR: 0.0500, Grad: 0.03/164.33, Loss: 0.5214, Acc: 0.7936, Speed: 150.2k, Time: 36.3946
Epoch: 21, Batch: 5000/9683, LR: 0.0500, Grad: 0.02/164.33, Loss: 0.5199, Acc: 0.7943, Speed: 150.6k, Time: 45.5400
Epoch: 21, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/164.33, Loss: 0.5214, Acc: 0.7935, Speed: 151.1k, Time: 54.7269
Epoch: 21, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/164.33, Loss: 0.5217, Acc: 0.7932, Speed: 151.2k, Time: 63.8891
Epoch: 21, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/164.33, Loss: 0.5216, Acc: 0.7933, Speed: 151.0k, Time: 73.1554
Epoch: 21, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/164.33, Loss: 0.5220, Acc: 0.7930, Speed: 150.8k, Time: 82.3627
Train 0.7930
Val 0.8206
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648

saving model to local_300_parikh
Epoch: 22, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/135.30, Loss: 0.5142, Acc: 0.7974, Speed: 149.3k, Time: 9.1823
Epoch: 22, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/135.30, Loss: 0.5169, Acc: 0.7961, Speed: 148.6k, Time: 18.3519
Epoch: 22, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/135.30, Loss: 0.5162, Acc: 0.7964, Speed: 149.0k, Time: 27.5462
Epoch: 22, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/146.58, Loss: 0.5168, Acc: 0.7958, Speed: 149.8k, Time: 36.7089
Epoch: 22, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/146.58, Loss: 0.5164, Acc: 0.7958, Speed: 150.4k, Time: 45.8515
Epoch: 22, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/146.58, Loss: 0.5164, Acc: 0.7958, Speed: 150.6k, Time: 55.0092
Epoch: 22, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/146.58, Loss: 0.5158, Acc: 0.7964, Speed: 150.5k, Time: 64.1806
Epoch: 22, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/146.58, Loss: 0.5160, Acc: 0.7963, Speed: 150.4k, Time: 73.3237
Epoch: 22, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/146.58, Loss: 0.5157, Acc: 0.7965, Speed: 150.5k, Time: 82.3259
Train 0.7962
Val 0.8255
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526

saving model to local_300_parikh
Epoch: 23, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/135.57, Loss: 0.5076, Acc: 0.7997, Speed: 148.5k, Time: 9.1379
Epoch: 23, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/135.57, Loss: 0.5102, Acc: 0.7985, Speed: 151.1k, Time: 18.2448
Epoch: 23, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/148.73, Loss: 0.5120, Acc: 0.7974, Speed: 150.7k, Time: 27.3815
Epoch: 23, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/171.20, Loss: 0.5124, Acc: 0.7965, Speed: 150.4k, Time: 36.4781
Epoch: 23, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/171.20, Loss: 0.5127, Acc: 0.7969, Speed: 150.5k, Time: 45.6299
Epoch: 23, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/171.20, Loss: 0.5113, Acc: 0.7979, Speed: 150.3k, Time: 54.7779
Epoch: 23, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/171.20, Loss: 0.5120, Acc: 0.7979, Speed: 150.4k, Time: 63.9398
Epoch: 23, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/171.20, Loss: 0.5118, Acc: 0.7981, Speed: 150.4k, Time: 73.0873
Epoch: 23, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/171.20, Loss: 0.5125, Acc: 0.7977, Speed: 151.0k, Time: 82.1726
Train 0.7979
Val 0.8269
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948

saving model to local_300_parikh
Epoch: 24, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/153.32, Loss: 0.5044, Acc: 0.8039, Speed: 150.7k, Time: 9.1885
Epoch: 24, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/153.32, Loss: 0.5045, Acc: 0.8028, Speed: 149.8k, Time: 18.3612
Epoch: 24, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/153.32, Loss: 0.5056, Acc: 0.8019, Speed: 149.2k, Time: 27.5418
Epoch: 24, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/153.32, Loss: 0.5068, Acc: 0.8009, Speed: 149.3k, Time: 36.7433
Epoch: 24, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/154.79, Loss: 0.5070, Acc: 0.8004, Speed: 150.5k, Time: 45.7717
Epoch: 24, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/154.79, Loss: 0.5069, Acc: 0.8003, Speed: 150.3k, Time: 54.8937
Epoch: 24, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/154.79, Loss: 0.5066, Acc: 0.8003, Speed: 150.6k, Time: 64.0810
Epoch: 24, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/154.79, Loss: 0.5068, Acc: 0.8003, Speed: 150.6k, Time: 73.2536
Epoch: 24, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/154.79, Loss: 0.5071, Acc: 0.8002, Speed: 150.6k, Time: 82.4080
Train 0.8003
Val 0.8271
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050

saving model to local_300_parikh
Epoch: 25, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/126.59, Loss: 0.4957, Acc: 0.8049, Speed: 146.5k, Time: 9.1617
Epoch: 25, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/132.31, Loss: 0.4985, Acc: 0.8034, Speed: 149.0k, Time: 18.3398
Epoch: 25, Batch: 3000/9683, LR: 0.0500, Grad: 0.01/153.34, Loss: 0.4997, Acc: 0.8024, Speed: 148.7k, Time: 27.4873
Epoch: 25, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/153.34, Loss: 0.5012, Acc: 0.8021, Speed: 149.7k, Time: 36.6406
Epoch: 25, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/153.34, Loss: 0.5022, Acc: 0.8021, Speed: 150.1k, Time: 45.7839
Epoch: 25, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/153.34, Loss: 0.5018, Acc: 0.8027, Speed: 149.8k, Time: 54.9316
Epoch: 25, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/153.34, Loss: 0.5027, Acc: 0.8023, Speed: 149.5k, Time: 64.1137
Epoch: 25, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/153.34, Loss: 0.5033, Acc: 0.8019, Speed: 149.9k, Time: 73.3332
Epoch: 25, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/153.34, Loss: 0.5035, Acc: 0.8018, Speed: 150.2k, Time: 82.5263
Train 0.8015
Val 0.8259
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932

skip saving model for perf <= 0.8271
Epoch: 26, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/136.54, Loss: 0.4986, Acc: 0.8057, Speed: 151.8k, Time: 9.0162
Epoch: 26, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/151.83, Loss: 0.4973, Acc: 0.8044, Speed: 152.0k, Time: 18.1516
Epoch: 26, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/151.83, Loss: 0.4992, Acc: 0.8042, Speed: 152.3k, Time: 27.2838
Epoch: 26, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/151.83, Loss: 0.4995, Acc: 0.8041, Speed: 151.6k, Time: 36.4381
Epoch: 26, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/151.83, Loss: 0.5002, Acc: 0.8037, Speed: 151.6k, Time: 45.5845
Epoch: 26, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/192.88, Loss: 0.5010, Acc: 0.8032, Speed: 151.4k, Time: 54.7517
Epoch: 26, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/192.88, Loss: 0.5008, Acc: 0.8031, Speed: 151.1k, Time: 63.9017
Epoch: 26, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/192.88, Loss: 0.5009, Acc: 0.8030, Speed: 151.0k, Time: 73.0166
Epoch: 26, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/192.88, Loss: 0.5017, Acc: 0.8025, Speed: 151.0k, Time: 82.1401
Train 0.8025
Val 0.8261
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136

skip saving model for perf <= 0.8271
Epoch: 27, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/124.38, Loss: 0.4948, Acc: 0.8045, Speed: 149.9k, Time: 9.1525
Epoch: 27, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/143.80, Loss: 0.4969, Acc: 0.8043, Speed: 150.5k, Time: 18.3453
Epoch: 27, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/143.80, Loss: 0.4963, Acc: 0.8041, Speed: 150.2k, Time: 27.5140
Epoch: 27, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/162.50, Loss: 0.4969, Acc: 0.8041, Speed: 150.2k, Time: 36.6292
Epoch: 27, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/162.50, Loss: 0.4975, Acc: 0.8040, Speed: 150.5k, Time: 45.7622
Epoch: 27, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/162.50, Loss: 0.4975, Acc: 0.8044, Speed: 150.4k, Time: 54.9140
Epoch: 27, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/162.50, Loss: 0.4967, Acc: 0.8049, Speed: 151.0k, Time: 63.8802
Epoch: 27, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/162.50, Loss: 0.4966, Acc: 0.8047, Speed: 150.8k, Time: 73.0271
Epoch: 27, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/162.50, Loss: 0.4963, Acc: 0.8049, Speed: 150.7k, Time: 82.1282
Train 0.8048
Val 0.8296
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590

saving model to local_300_parikh
Epoch: 28, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/122.35, Loss: 0.4887, Acc: 0.8080, Speed: 148.0k, Time: 9.2062
Epoch: 28, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/133.71, Loss: 0.4897, Acc: 0.8068, Speed: 149.3k, Time: 18.3571
Epoch: 28, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/145.41, Loss: 0.4921, Acc: 0.8056, Speed: 149.6k, Time: 27.5030
Epoch: 28, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/156.61, Loss: 0.4939, Acc: 0.8049, Speed: 149.8k, Time: 36.7482
Epoch: 28, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/165.82, Loss: 0.4953, Acc: 0.8045, Speed: 150.1k, Time: 45.9710
Epoch: 28, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/165.82, Loss: 0.4960, Acc: 0.8044, Speed: 149.8k, Time: 55.2046
Epoch: 28, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/165.82, Loss: 0.4954, Acc: 0.8046, Speed: 149.7k, Time: 64.3605
Epoch: 28, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/165.82, Loss: 0.4950, Acc: 0.8048, Speed: 149.9k, Time: 73.5074
Epoch: 28, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/165.82, Loss: 0.4946, Acc: 0.8052, Speed: 150.3k, Time: 82.6224
Train 0.8056
Val 0.8308
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810

saving model to local_300_parikh
Epoch: 29, Batch: 1000/9683, LR: 0.0500, Grad: 0.06/153.54, Loss: 0.4887, Acc: 0.8088, Speed: 148.7k, Time: 9.1661
Epoch: 29, Batch: 2000/9683, LR: 0.0500, Grad: 0.06/153.54, Loss: 0.4928, Acc: 0.8068, Speed: 150.8k, Time: 18.3197
Epoch: 29, Batch: 3000/9683, LR: 0.0500, Grad: 0.05/153.54, Loss: 0.4936, Acc: 0.8069, Speed: 152.4k, Time: 27.3058
Epoch: 29, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/166.34, Loss: 0.4924, Acc: 0.8071, Speed: 151.1k, Time: 36.4391
Epoch: 29, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/166.34, Loss: 0.4922, Acc: 0.8070, Speed: 150.8k, Time: 45.5607
Epoch: 29, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/166.34, Loss: 0.4919, Acc: 0.8068, Speed: 150.8k, Time: 54.7059
Epoch: 29, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/166.34, Loss: 0.4916, Acc: 0.8068, Speed: 150.8k, Time: 63.8262
Epoch: 29, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/166.34, Loss: 0.4919, Acc: 0.8065, Speed: 150.9k, Time: 73.0051
Epoch: 29, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/166.34, Loss: 0.4916, Acc: 0.8067, Speed: 150.8k, Time: 82.1815
Train 0.8064
Val 0.8325
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537

saving model to local_300_parikh
Epoch: 30, Batch: 1000/9683, LR: 0.0500, Grad: 0.20/136.06, Loss: 0.4843, Acc: 0.8101, Speed: 149.5k, Time: 9.1648
Epoch: 30, Batch: 2000/9683, LR: 0.0500, Grad: 0.10/153.30, Loss: 0.4873, Acc: 0.8088, Speed: 148.9k, Time: 18.3355
Epoch: 30, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/153.30, Loss: 0.4881, Acc: 0.8087, Speed: 150.2k, Time: 27.4567
Epoch: 30, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/163.39, Loss: 0.4873, Acc: 0.8092, Speed: 150.2k, Time: 36.5875
Epoch: 30, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/163.39, Loss: 0.4878, Acc: 0.8090, Speed: 150.5k, Time: 45.7575
Epoch: 30, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/163.39, Loss: 0.4875, Acc: 0.8090, Speed: 150.4k, Time: 54.9349
Epoch: 30, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/163.39, Loss: 0.4879, Acc: 0.8087, Speed: 150.4k, Time: 64.0933
Epoch: 30, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/163.39, Loss: 0.4887, Acc: 0.8083, Speed: 150.6k, Time: 73.2676
Epoch: 30, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/168.53, Loss: 0.4886, Acc: 0.8082, Speed: 150.7k, Time: 82.2371
Train 0.8081
Val 0.8318
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826

skip saving model for perf <= 0.8325
Epoch: 31, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/130.65, Loss: 0.4855, Acc: 0.8110, Speed: 148.8k, Time: 9.2481
Epoch: 31, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/131.92, Loss: 0.4845, Acc: 0.8108, Speed: 150.4k, Time: 18.3759
Epoch: 31, Batch: 3000/9683, LR: 0.0500, Grad: 0.01/152.23, Loss: 0.4860, Acc: 0.8102, Speed: 150.2k, Time: 27.5339
Epoch: 31, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/152.23, Loss: 0.4855, Acc: 0.8105, Speed: 149.7k, Time: 36.8530
Epoch: 31, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/152.23, Loss: 0.4856, Acc: 0.8104, Speed: 142.3k, Time: 48.4025
Epoch: 31, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/152.23, Loss: 0.4859, Acc: 0.8103, Speed: 136.2k, Time: 60.6225
Epoch: 31, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/152.23, Loss: 0.4876, Acc: 0.8092, Speed: 132.2k, Time: 72.7420
Epoch: 31, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/152.23, Loss: 0.4871, Acc: 0.8093, Speed: 129.6k, Time: 84.9048
Epoch: 31, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/171.75, Loss: 0.4874, Acc: 0.8092, Speed: 127.7k, Time: 97.0999
Train 0.8090
Val 0.8337
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655

saving model to local_300_parikh
Epoch: 32, Batch: 1000/9683, LR: 0.0500, Grad: 0.02/133.80, Loss: 0.4816, Acc: 0.8122, Speed: 113.3k, Time: 12.1278
Epoch: 32, Batch: 2000/9683, LR: 0.0500, Grad: 0.02/136.30, Loss: 0.4850, Acc: 0.8097, Speed: 113.2k, Time: 24.2817
Epoch: 32, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/136.30, Loss: 0.4862, Acc: 0.8094, Speed: 113.2k, Time: 36.4252
Epoch: 32, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/143.71, Loss: 0.4856, Acc: 0.8096, Speed: 113.4k, Time: 48.2418
Epoch: 32, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/144.30, Loss: 0.4864, Acc: 0.8093, Speed: 114.0k, Time: 60.4335
Epoch: 32, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/144.30, Loss: 0.4863, Acc: 0.8095, Speed: 113.8k, Time: 72.5174
Epoch: 32, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/157.28, Loss: 0.4863, Acc: 0.8091, Speed: 114.0k, Time: 84.6199
Epoch: 32, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/157.28, Loss: 0.4856, Acc: 0.8095, Speed: 114.2k, Time: 96.6673
Epoch: 32, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/157.28, Loss: 0.4856, Acc: 0.8096, Speed: 114.2k, Time: 108.5776
Train 0.8095
Val 0.8317
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724

skip saving model for perf <= 0.8337
Epoch: 33, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/141.45, Loss: 0.4892, Acc: 0.8085, Speed: 113.5k, Time: 12.1902
Epoch: 33, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4858, Acc: 0.8089, Speed: 113.1k, Time: 24.4319
Epoch: 33, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4849, Acc: 0.8096, Speed: 113.2k, Time: 36.4984
Epoch: 33, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4852, Acc: 0.8097, Speed: 113.3k, Time: 48.6875
Epoch: 33, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4845, Acc: 0.8102, Speed: 113.0k, Time: 60.8960
Epoch: 33, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4834, Acc: 0.8107, Speed: 113.0k, Time: 73.0519
Epoch: 33, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4836, Acc: 0.8106, Speed: 113.2k, Time: 85.2028
Epoch: 33, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4828, Acc: 0.8110, Speed: 113.5k, Time: 97.3047
Epoch: 33, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/155.65, Loss: 0.4825, Acc: 0.8113, Speed: 113.7k, Time: 109.2264
Train 0.8114
Val 0.8349
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875

saving model to local_300_parikh
Epoch: 34, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/158.74, Loss: 0.4752, Acc: 0.8127, Speed: 114.0k, Time: 12.1831
Epoch: 34, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/158.74, Loss: 0.4797, Acc: 0.8123, Speed: 113.3k, Time: 24.4205
Epoch: 34, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4780, Acc: 0.8130, Speed: 113.1k, Time: 36.6009
Epoch: 34, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4782, Acc: 0.8131, Speed: 114.1k, Time: 48.5080
Epoch: 34, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4783, Acc: 0.8130, Speed: 113.9k, Time: 60.5650
Epoch: 34, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4799, Acc: 0.8122, Speed: 113.7k, Time: 72.6138
Epoch: 34, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4806, Acc: 0.8120, Speed: 113.6k, Time: 84.7805
Epoch: 34, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4808, Acc: 0.8120, Speed: 113.5k, Time: 97.0156
Epoch: 34, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4807, Acc: 0.8119, Speed: 113.5k, Time: 109.2024
Train 0.8119
Val 0.8369
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907

saving model to local_300_parikh
Epoch: 35, Batch: 1000/9683, LR: 0.0500, Grad: 0.02/140.79, Loss: 0.4762, Acc: 0.8134, Speed: 113.8k, Time: 12.2068
Epoch: 35, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/159.99, Loss: 0.4790, Acc: 0.8127, Speed: 114.1k, Time: 24.3899
Epoch: 35, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/159.99, Loss: 0.4785, Acc: 0.8128, Speed: 114.3k, Time: 36.5958
Epoch: 35, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/171.18, Loss: 0.4787, Acc: 0.8126, Speed: 114.6k, Time: 48.3941
Epoch: 35, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/171.18, Loss: 0.4792, Acc: 0.8125, Speed: 114.2k, Time: 60.4961
Epoch: 35, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/171.18, Loss: 0.4784, Acc: 0.8130, Speed: 113.7k, Time: 72.7141
Epoch: 35, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/171.18, Loss: 0.4782, Acc: 0.8131, Speed: 113.8k, Time: 84.7468
Epoch: 35, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/171.18, Loss: 0.4775, Acc: 0.8133, Speed: 113.7k, Time: 96.8845
Epoch: 35, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/171.18, Loss: 0.4777, Acc: 0.8131, Speed: 114.0k, Time: 108.6796
Train 0.8132
Val 0.8361
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094

skip saving model for perf <= 0.8369
Epoch: 36, Batch: 1000/9683, LR: 0.0500, Grad: 0.03/134.80, Loss: 0.4712, Acc: 0.8153, Speed: 115.8k, Time: 12.1433
Epoch: 36, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/146.65, Loss: 0.4723, Acc: 0.8154, Speed: 115.6k, Time: 24.2248
Epoch: 36, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/148.30, Loss: 0.4744, Acc: 0.8143, Speed: 114.6k, Time: 36.4740
Epoch: 36, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/155.48, Loss: 0.4757, Acc: 0.8142, Speed: 114.6k, Time: 48.5974
Epoch: 36, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/155.48, Loss: 0.4768, Acc: 0.8139, Speed: 114.5k, Time: 60.7781
Epoch: 36, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/155.48, Loss: 0.4759, Acc: 0.8143, Speed: 114.4k, Time: 72.9302
Epoch: 36, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/155.48, Loss: 0.4764, Acc: 0.8139, Speed: 114.0k, Time: 85.1051
Epoch: 36, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/180.86, Loss: 0.4767, Acc: 0.8135, Speed: 113.6k, Time: 97.1948
Epoch: 36, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/180.86, Loss: 0.4762, Acc: 0.8137, Speed: 113.7k, Time: 108.9721
Train 0.8139
Val 0.8380
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025

saving model to local_300_parikh
Epoch: 37, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/140.70, Loss: 0.4680, Acc: 0.8173, Speed: 114.6k, Time: 12.0583
Epoch: 37, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/158.09, Loss: 0.4682, Acc: 0.8173, Speed: 112.6k, Time: 24.3236
Epoch: 37, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/158.09, Loss: 0.4720, Acc: 0.8158, Speed: 113.5k, Time: 36.3940
Epoch: 37, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/158.09, Loss: 0.4732, Acc: 0.8155, Speed: 114.4k, Time: 48.0214
Epoch: 37, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/158.09, Loss: 0.4733, Acc: 0.8155, Speed: 114.8k, Time: 60.0138
Epoch: 37, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/158.09, Loss: 0.4734, Acc: 0.8153, Speed: 114.7k, Time: 72.1842
Epoch: 37, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/158.09, Loss: 0.4736, Acc: 0.8151, Speed: 114.6k, Time: 84.3518
Epoch: 37, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/158.09, Loss: 0.4733, Acc: 0.8152, Speed: 114.5k, Time: 96.4534
Epoch: 37, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/160.16, Loss: 0.4749, Acc: 0.8144, Speed: 114.3k, Time: 108.5719
Train 0.8145
Val 0.8328
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842

skip saving model for perf <= 0.8380
Epoch: 38, Batch: 1000/9683, LR: 0.0500, Grad: 0.03/134.05, Loss: 0.4721, Acc: 0.8147, Speed: 113.4k, Time: 12.1112
Epoch: 38, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4716, Acc: 0.8157, Speed: 113.7k, Time: 24.2290
Epoch: 38, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4707, Acc: 0.8156, Speed: 113.8k, Time: 36.3308
Epoch: 38, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4706, Acc: 0.8158, Speed: 114.4k, Time: 48.2723
Epoch: 38, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4716, Acc: 0.8154, Speed: 114.8k, Time: 60.2594
Epoch: 38, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4717, Acc: 0.8155, Speed: 114.1k, Time: 72.3753
Epoch: 38, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4717, Acc: 0.8157, Speed: 113.9k, Time: 84.5074
Epoch: 38, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4709, Acc: 0.8161, Speed: 113.7k, Time: 96.6827
Epoch: 38, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/167.46, Loss: 0.4713, Acc: 0.8160, Speed: 114.0k, Time: 108.4996
Train 0.8158
Val 0.8376
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618

skip saving model for perf <= 0.8380
Epoch: 39, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/127.77, Loss: 0.4738, Acc: 0.8143, Speed: 114.5k, Time: 12.2261
Epoch: 39, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/127.77, Loss: 0.4697, Acc: 0.8168, Speed: 113.5k, Time: 24.3634
Epoch: 39, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/175.97, Loss: 0.4705, Acc: 0.8163, Speed: 113.1k, Time: 36.4960
Epoch: 39, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/175.97, Loss: 0.4710, Acc: 0.8163, Speed: 113.3k, Time: 48.7132
Epoch: 39, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/175.97, Loss: 0.4721, Acc: 0.8160, Speed: 113.3k, Time: 60.8829
Epoch: 39, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/178.36, Loss: 0.4724, Acc: 0.8157, Speed: 112.9k, Time: 73.0310
Epoch: 39, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/178.36, Loss: 0.4712, Acc: 0.8161, Speed: 112.7k, Time: 85.2666
Epoch: 39, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/178.36, Loss: 0.4715, Acc: 0.8159, Speed: 113.0k, Time: 97.3337
Epoch: 39, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/178.36, Loss: 0.4727, Acc: 0.8154, Speed: 113.5k, Time: 109.2564
Train 0.8156
Val 0.8339
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858

skip saving model for perf <= 0.8380
Epoch: 40, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/159.38, Loss: 0.4690, Acc: 0.8159, Speed: 112.5k, Time: 12.1273
Epoch: 40, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/159.38, Loss: 0.4683, Acc: 0.8172, Speed: 112.4k, Time: 24.3046
Epoch: 40, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/159.38, Loss: 0.4697, Acc: 0.8166, Speed: 112.4k, Time: 36.5383
Epoch: 40, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/159.38, Loss: 0.4702, Acc: 0.8164, Speed: 113.0k, Time: 48.4665
Epoch: 40, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/159.38, Loss: 0.4706, Acc: 0.8163, Speed: 113.7k, Time: 60.4990
Epoch: 40, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/159.38, Loss: 0.4703, Acc: 0.8166, Speed: 113.8k, Time: 72.5678
Epoch: 40, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/173.03, Loss: 0.4696, Acc: 0.8169, Speed: 113.6k, Time: 84.8533
Epoch: 40, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/173.03, Loss: 0.4691, Acc: 0.8170, Speed: 113.7k, Time: 96.8445
Epoch: 40, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/173.03, Loss: 0.4695, Acc: 0.8168, Speed: 113.7k, Time: 109.0798
Train 0.8167
Val 0.8386
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634

saving model to local_300_parikh
Epoch: 41, Batch: 1000/9683, LR: 0.0500, Grad: 0.03/155.48, Loss: 0.4615, Acc: 0.8203, Speed: 114.2k, Time: 12.1552
Epoch: 41, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/155.48, Loss: 0.4684, Acc: 0.8183, Speed: 113.8k, Time: 24.3890
Epoch: 41, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/156.93, Loss: 0.4673, Acc: 0.8188, Speed: 112.9k, Time: 36.6617
Epoch: 41, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/156.93, Loss: 0.4663, Acc: 0.8192, Speed: 113.3k, Time: 48.6213
Epoch: 41, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/185.48, Loss: 0.4668, Acc: 0.8187, Speed: 113.6k, Time: 60.6145
Epoch: 41, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/185.48, Loss: 0.4672, Acc: 0.8184, Speed: 113.9k, Time: 72.8759
Epoch: 41, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/185.48, Loss: 0.4674, Acc: 0.8183, Speed: 113.5k, Time: 85.1257
Epoch: 41, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/185.48, Loss: 0.4678, Acc: 0.8180, Speed: 113.1k, Time: 97.3364
Epoch: 41, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/185.48, Loss: 0.4682, Acc: 0.8179, Speed: 113.6k, Time: 109.0453
Train 0.8177
Val 0.8376
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618

skip saving model for perf <= 0.8386
Epoch: 42, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/130.45, Loss: 0.4668, Acc: 0.8175, Speed: 114.3k, Time: 12.2172
Epoch: 42, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/157.14, Loss: 0.4662, Acc: 0.8186, Speed: 114.9k, Time: 24.3192
Epoch: 42, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/157.14, Loss: 0.4650, Acc: 0.8191, Speed: 113.8k, Time: 36.5277
Epoch: 42, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/157.14, Loss: 0.4649, Acc: 0.8193, Speed: 113.8k, Time: 48.7958
Epoch: 42, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/157.14, Loss: 0.4653, Acc: 0.8190, Speed: 113.2k, Time: 60.9725
Epoch: 42, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/157.14, Loss: 0.4660, Acc: 0.8186, Speed: 113.5k, Time: 72.9685
Epoch: 42, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/157.14, Loss: 0.4660, Acc: 0.8186, Speed: 113.5k, Time: 85.0824
Epoch: 42, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/161.29, Loss: 0.4659, Acc: 0.8187, Speed: 113.4k, Time: 97.2357
Epoch: 42, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/161.29, Loss: 0.4661, Acc: 0.8187, Speed: 113.7k, Time: 108.9161
Train 0.8184
Val 0.8400
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955

saving model to local_300_parikh
Epoch: 43, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/154.72, Loss: 0.4586, Acc: 0.8229, Speed: 116.9k, Time: 11.9895
Epoch: 43, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.32, Loss: 0.4598, Acc: 0.8222, Speed: 117.0k, Time: 23.9948
Epoch: 43, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.32, Loss: 0.4614, Acc: 0.8209, Speed: 115.9k, Time: 36.1247
Epoch: 43, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/179.32, Loss: 0.4632, Acc: 0.8199, Speed: 115.9k, Time: 47.9629
Epoch: 43, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/180.85, Loss: 0.4628, Acc: 0.8199, Speed: 115.8k, Time: 59.8801
Epoch: 43, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/180.85, Loss: 0.4628, Acc: 0.8195, Speed: 115.5k, Time: 72.0370
Epoch: 43, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/180.85, Loss: 0.4624, Acc: 0.8197, Speed: 115.1k, Time: 84.0876
Epoch: 43, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/191.83, Loss: 0.4631, Acc: 0.8192, Speed: 114.7k, Time: 96.2747
Epoch: 43, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/191.83, Loss: 0.4633, Acc: 0.8191, Speed: 114.5k, Time: 108.3391
Train 0.8191
Val 0.8434
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410

saving model to local_300_parikh
Epoch: 44, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/140.31, Loss: 0.4691, Acc: 0.8165, Speed: 115.9k, Time: 11.7991
Epoch: 44, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/149.51, Loss: 0.4669, Acc: 0.8182, Speed: 115.6k, Time: 23.6340
Epoch: 44, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/184.86, Loss: 0.4659, Acc: 0.8187, Speed: 115.5k, Time: 35.3821
Epoch: 44, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/184.86, Loss: 0.4653, Acc: 0.8187, Speed: 115.7k, Time: 47.2017
Epoch: 44, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/184.86, Loss: 0.4636, Acc: 0.8192, Speed: 116.6k, Time: 58.6493
Epoch: 44, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/184.86, Loss: 0.4637, Acc: 0.8191, Speed: 117.1k, Time: 70.4320
Epoch: 44, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/184.86, Loss: 0.4633, Acc: 0.8191, Speed: 117.0k, Time: 82.2875
Epoch: 44, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/184.86, Loss: 0.4626, Acc: 0.8192, Speed: 117.0k, Time: 94.0624
Epoch: 44, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/184.86, Loss: 0.4624, Acc: 0.8194, Speed: 116.9k, Time: 106.0428
Train 0.8193
Val 0.8416
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581

skip saving model for perf <= 0.8434
Epoch: 45, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/147.22, Loss: 0.4684, Acc: 0.8178, Speed: 114.4k, Time: 12.0511
Epoch: 45, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/174.59, Loss: 0.4669, Acc: 0.8185, Speed: 113.6k, Time: 24.1341
Epoch: 45, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/174.59, Loss: 0.4641, Acc: 0.8193, Speed: 113.6k, Time: 36.0723
Epoch: 45, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/174.59, Loss: 0.4620, Acc: 0.8201, Speed: 113.9k, Time: 48.0161
Epoch: 45, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/174.59, Loss: 0.4617, Acc: 0.8202, Speed: 114.1k, Time: 60.1906
Epoch: 45, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/174.59, Loss: 0.4608, Acc: 0.8205, Speed: 114.2k, Time: 72.1272
Epoch: 45, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/177.22, Loss: 0.4619, Acc: 0.8199, Speed: 114.2k, Time: 84.1743
Epoch: 45, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/177.22, Loss: 0.4611, Acc: 0.8202, Speed: 114.1k, Time: 96.1842
Epoch: 45, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/177.22, Loss: 0.4610, Acc: 0.8201, Speed: 114.3k, Time: 108.3019
Train 0.8200
Val 0.8408
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768

skip saving model for perf <= 0.8434
Epoch: 46, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/127.17, Loss: 0.4585, Acc: 0.8219, Speed: 115.0k, Time: 11.9942
Epoch: 46, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/154.89, Loss: 0.4593, Acc: 0.8211, Speed: 114.1k, Time: 24.0653
Epoch: 46, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/187.15, Loss: 0.4598, Acc: 0.8208, Speed: 114.5k, Time: 36.0314
Epoch: 46, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/187.15, Loss: 0.4605, Acc: 0.8207, Speed: 114.6k, Time: 48.0651
Epoch: 46, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/206.21, Loss: 0.4607, Acc: 0.8205, Speed: 115.1k, Time: 59.7000
Epoch: 46, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/206.21, Loss: 0.4602, Acc: 0.8206, Speed: 115.0k, Time: 71.7673
Epoch: 46, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/206.21, Loss: 0.4601, Acc: 0.8208, Speed: 115.0k, Time: 83.7474
Epoch: 46, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/206.21, Loss: 0.4599, Acc: 0.8209, Speed: 115.0k, Time: 95.6851
Epoch: 46, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/206.21, Loss: 0.4600, Acc: 0.8209, Speed: 114.9k, Time: 107.7648
Train 0.8208
Val 0.8405
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463

skip saving model for perf <= 0.8434
Epoch: 47, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/149.38, Loss: 0.4559, Acc: 0.8218, Speed: 115.4k, Time: 11.9877
Epoch: 47, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/153.64, Loss: 0.4564, Acc: 0.8227, Speed: 115.1k, Time: 23.9717
Epoch: 47, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/153.64, Loss: 0.4564, Acc: 0.8223, Speed: 114.4k, Time: 36.0095
Epoch: 47, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/170.51, Loss: 0.4573, Acc: 0.8220, Speed: 114.2k, Time: 48.2073
Epoch: 47, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/170.51, Loss: 0.4573, Acc: 0.8219, Speed: 115.5k, Time: 59.7660
Epoch: 47, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/170.51, Loss: 0.4585, Acc: 0.8215, Speed: 115.4k, Time: 71.7860
Epoch: 47, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/170.86, Loss: 0.4587, Acc: 0.8215, Speed: 115.4k, Time: 83.7964
Epoch: 47, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/170.86, Loss: 0.4588, Acc: 0.8214, Speed: 115.5k, Time: 95.8551
Epoch: 47, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/170.86, Loss: 0.4590, Acc: 0.8213, Speed: 115.0k, Time: 108.0581
Train 0.8213
Val 0.8388
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838

skip saving model for perf <= 0.8434
Epoch: 48, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4579, Acc: 0.8229, Speed: 112.6k, Time: 12.1994
Epoch: 48, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4562, Acc: 0.8229, Speed: 114.3k, Time: 24.2100
Epoch: 48, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4576, Acc: 0.8219, Speed: 114.4k, Time: 36.2657
Epoch: 48, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4576, Acc: 0.8217, Speed: 113.7k, Time: 48.4787
Epoch: 48, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4575, Acc: 0.8219, Speed: 113.7k, Time: 60.4400
Epoch: 48, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4583, Acc: 0.8218, Speed: 113.9k, Time: 72.5275
Epoch: 48, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4587, Acc: 0.8216, Speed: 113.7k, Time: 84.5877
Epoch: 48, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4587, Acc: 0.8214, Speed: 113.7k, Time: 96.6624
Epoch: 48, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/201.67, Loss: 0.4586, Acc: 0.8215, Speed: 114.0k, Time: 108.7354
Train 0.8214
Val 0.8413
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276

skip saving model for perf <= 0.8434
Epoch: 49, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.81, Loss: 0.4577, Acc: 0.8216, Speed: 115.2k, Time: 11.9858
Epoch: 49, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/168.85, Loss: 0.4547, Acc: 0.8231, Speed: 114.8k, Time: 24.0533
Epoch: 49, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/168.85, Loss: 0.4571, Acc: 0.8220, Speed: 114.3k, Time: 36.1028
Epoch: 49, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/168.85, Loss: 0.4565, Acc: 0.8227, Speed: 113.7k, Time: 48.0616
Epoch: 49, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/168.85, Loss: 0.4576, Acc: 0.8221, Speed: 114.5k, Time: 59.8649
Epoch: 49, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/168.85, Loss: 0.4571, Acc: 0.8224, Speed: 114.5k, Time: 71.9441
Epoch: 49, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/168.85, Loss: 0.4571, Acc: 0.8223, Speed: 114.9k, Time: 83.9413
Epoch: 49, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/185.22, Loss: 0.4572, Acc: 0.8223, Speed: 115.0k, Time: 95.8996
Epoch: 49, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/185.22, Loss: 0.4571, Acc: 0.8223, Speed: 114.7k, Time: 107.9541
Train 0.8220
Val 0.8421
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089

skip saving model for perf <= 0.8434
Epoch: 50, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/150.13, Loss: 0.4570, Acc: 0.8215, Speed: 115.1k, Time: 12.0819
Epoch: 50, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4560, Acc: 0.8217, Speed: 114.9k, Time: 24.1062
Epoch: 50, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4556, Acc: 0.8223, Speed: 115.0k, Time: 36.0569
Epoch: 50, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4556, Acc: 0.8228, Speed: 115.2k, Time: 48.1348
Epoch: 50, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4569, Acc: 0.8222, Speed: 115.4k, Time: 60.0434
Epoch: 50, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4561, Acc: 0.8227, Speed: 115.6k, Time: 71.7945
Epoch: 50, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4565, Acc: 0.8226, Speed: 115.5k, Time: 83.8695
Epoch: 50, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4565, Acc: 0.8226, Speed: 115.3k, Time: 95.7890
Epoch: 50, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/163.73, Loss: 0.4564, Acc: 0.8226, Speed: 115.2k, Time: 107.8512
Train 0.8227
Val 0.8411
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073

skip saving model for perf <= 0.8434
Epoch: 51, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/157.61, Loss: 0.4529, Acc: 0.8232, Speed: 118.9k, Time: 11.6924
Epoch: 51, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/157.61, Loss: 0.4537, Acc: 0.8240, Speed: 116.7k, Time: 23.7317
Epoch: 51, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/157.61, Loss: 0.4537, Acc: 0.8239, Speed: 116.1k, Time: 35.8288
Epoch: 51, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/157.61, Loss: 0.4547, Acc: 0.8234, Speed: 115.7k, Time: 47.8165
Epoch: 51, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/169.31, Loss: 0.4543, Acc: 0.8234, Speed: 115.7k, Time: 59.7858
Epoch: 51, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/169.31, Loss: 0.4543, Acc: 0.8233, Speed: 115.4k, Time: 71.8077
Epoch: 51, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/169.31, Loss: 0.4538, Acc: 0.8235, Speed: 115.2k, Time: 83.8687
Epoch: 51, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/169.31, Loss: 0.4545, Acc: 0.8230, Speed: 115.2k, Time: 95.8866
Epoch: 51, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/169.31, Loss: 0.4545, Acc: 0.8232, Speed: 115.0k, Time: 107.9278
Train 0.8230
Val 0.8423
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292

skip saving model for perf <= 0.8434
Epoch: 52, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/135.18, Loss: 0.4533, Acc: 0.8244, Speed: 118.1k, Time: 11.6487
Epoch: 52, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/151.25, Loss: 0.4517, Acc: 0.8238, Speed: 118.2k, Time: 23.5591
Epoch: 52, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/162.39, Loss: 0.4511, Acc: 0.8237, Speed: 117.0k, Time: 35.5868
Epoch: 52, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/162.39, Loss: 0.4525, Acc: 0.8230, Speed: 116.5k, Time: 47.5156
Epoch: 52, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/162.39, Loss: 0.4536, Acc: 0.8226, Speed: 115.8k, Time: 59.5432
Epoch: 52, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/181.47, Loss: 0.4540, Acc: 0.8226, Speed: 115.9k, Time: 71.1793
Epoch: 52, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/181.47, Loss: 0.4548, Acc: 0.8224, Speed: 116.1k, Time: 83.2947
Epoch: 52, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/181.47, Loss: 0.4541, Acc: 0.8227, Speed: 115.8k, Time: 95.2389
Epoch: 52, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/181.47, Loss: 0.4539, Acc: 0.8228, Speed: 115.7k, Time: 107.2301
Train 0.8229
Val 0.8446
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630

saving model to local_300_parikh
Epoch: 53, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4565, Acc: 0.8223, Speed: 112.2k, Time: 12.0449
Epoch: 53, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4559, Acc: 0.8231, Speed: 114.0k, Time: 23.9990
Epoch: 53, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4557, Acc: 0.8235, Speed: 115.0k, Time: 35.9664
Epoch: 53, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4537, Acc: 0.8245, Speed: 114.8k, Time: 48.0152
Epoch: 53, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4544, Acc: 0.8239, Speed: 115.1k, Time: 60.0089
Epoch: 53, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4536, Acc: 0.8239, Speed: 115.3k, Time: 71.9974
Epoch: 53, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4527, Acc: 0.8244, Speed: 114.0k, Time: 84.6430
Epoch: 53, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4526, Acc: 0.8244, Speed: 113.3k, Time: 97.3501
Epoch: 53, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/192.04, Loss: 0.4530, Acc: 0.8242, Speed: 112.8k, Time: 109.9515
Train 0.8241
Val 0.8418
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784

skip saving model for perf <= 0.8446
Epoch: 54, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/160.03, Loss: 0.4478, Acc: 0.8277, Speed: 112.5k, Time: 12.3082
Epoch: 54, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/160.03, Loss: 0.4473, Acc: 0.8270, Speed: 110.1k, Time: 24.9542
Epoch: 54, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/160.03, Loss: 0.4490, Acc: 0.8261, Speed: 110.4k, Time: 37.5763
Epoch: 54, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/160.03, Loss: 0.4496, Acc: 0.8256, Speed: 110.2k, Time: 50.2324
Epoch: 54, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/160.03, Loss: 0.4508, Acc: 0.8248, Speed: 110.2k, Time: 62.8300
Epoch: 54, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/160.03, Loss: 0.4514, Acc: 0.8245, Speed: 109.9k, Time: 75.4808
Epoch: 54, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/160.03, Loss: 0.4515, Acc: 0.8244, Speed: 109.9k, Time: 88.0252
Epoch: 54, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/180.62, Loss: 0.4518, Acc: 0.8242, Speed: 109.8k, Time: 100.6639
Epoch: 54, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/180.62, Loss: 0.4515, Acc: 0.8243, Speed: 109.5k, Time: 113.3993
Train 0.8245
Val 0.8440
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020

skip saving model for perf <= 0.8446
Epoch: 55, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4508, Acc: 0.8268, Speed: 106.3k, Time: 12.6793
Epoch: 55, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4490, Acc: 0.8267, Speed: 108.1k, Time: 25.3178
Epoch: 55, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4511, Acc: 0.8257, Speed: 109.0k, Time: 37.9416
Epoch: 55, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4519, Acc: 0.8250, Speed: 109.5k, Time: 50.5862
Epoch: 55, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4515, Acc: 0.8248, Speed: 110.6k, Time: 62.5878
Epoch: 55, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4513, Acc: 0.8245, Speed: 111.2k, Time: 74.5670
Epoch: 55, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4507, Acc: 0.8249, Speed: 111.1k, Time: 86.6329
Epoch: 55, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/163.75, Loss: 0.4503, Acc: 0.8251, Speed: 111.6k, Time: 98.7566
Epoch: 55, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/176.32, Loss: 0.4501, Acc: 0.8253, Speed: 112.0k, Time: 110.7902
Train 0.8251
Val 0.8432
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207

skip saving model for perf <= 0.8446
Epoch: 56, Batch: 1000/9683, LR: 0.0500, Grad: 0.02/146.54, Loss: 0.4511, Acc: 0.8249, Speed: 116.3k, Time: 12.0616
Epoch: 56, Batch: 2000/9683, LR: 0.0500, Grad: 0.02/179.83, Loss: 0.4507, Acc: 0.8255, Speed: 115.0k, Time: 24.0928
Epoch: 56, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.83, Loss: 0.4509, Acc: 0.8253, Speed: 114.7k, Time: 36.1499
Epoch: 56, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/179.83, Loss: 0.4491, Acc: 0.8258, Speed: 114.7k, Time: 48.0679
Epoch: 56, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/179.83, Loss: 0.4494, Acc: 0.8255, Speed: 115.4k, Time: 59.7617
Epoch: 56, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/179.83, Loss: 0.4496, Acc: 0.8256, Speed: 115.2k, Time: 71.7641
Epoch: 56, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/179.83, Loss: 0.4501, Acc: 0.8252, Speed: 115.2k, Time: 83.8122
Epoch: 56, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/179.83, Loss: 0.4501, Acc: 0.8252, Speed: 115.1k, Time: 95.8439
Epoch: 56, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/179.83, Loss: 0.4507, Acc: 0.8249, Speed: 115.0k, Time: 107.8707
Train 0.8247
Val 0.8440
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020

skip saving model for perf <= 0.8446
Epoch: 57, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/149.16, Loss: 0.4471, Acc: 0.8264, Speed: 113.7k, Time: 12.0140
Epoch: 57, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/151.98, Loss: 0.4461, Acc: 0.8266, Speed: 113.5k, Time: 24.0765
Epoch: 57, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/151.98, Loss: 0.4477, Acc: 0.8255, Speed: 114.2k, Time: 36.2001
Epoch: 57, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/152.89, Loss: 0.4492, Acc: 0.8249, Speed: 114.1k, Time: 48.3065
Epoch: 57, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/171.00, Loss: 0.4485, Acc: 0.8252, Speed: 115.1k, Time: 60.2808
Epoch: 57, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/171.00, Loss: 0.4485, Acc: 0.8253, Speed: 114.7k, Time: 72.2980
Epoch: 57, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.58, Loss: 0.4483, Acc: 0.8255, Speed: 114.3k, Time: 84.3692
Epoch: 57, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/194.58, Loss: 0.4493, Acc: 0.8253, Speed: 114.5k, Time: 96.5239
Epoch: 57, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/196.61, Loss: 0.4496, Acc: 0.8251, Speed: 114.2k, Time: 108.6486
Train 0.8251
Val 0.8436
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613

skip saving model for perf <= 0.8446
Epoch: 58, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/164.50, Loss: 0.4503, Acc: 0.8250, Speed: 114.6k, Time: 12.0156
Epoch: 58, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/171.79, Loss: 0.4463, Acc: 0.8266, Speed: 114.2k, Time: 24.0210
Epoch: 58, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/171.79, Loss: 0.4447, Acc: 0.8267, Speed: 113.6k, Time: 36.0447
Epoch: 58, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/171.79, Loss: 0.4454, Acc: 0.8266, Speed: 114.0k, Time: 48.1227
Epoch: 58, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/171.79, Loss: 0.4459, Acc: 0.8265, Speed: 114.9k, Time: 59.7313
Epoch: 58, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/171.79, Loss: 0.4462, Acc: 0.8265, Speed: 114.9k, Time: 71.8995
Epoch: 58, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/198.70, Loss: 0.4463, Acc: 0.8266, Speed: 115.1k, Time: 84.0200
Epoch: 58, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/198.70, Loss: 0.4481, Acc: 0.8260, Speed: 114.8k, Time: 96.1738
Epoch: 58, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/198.70, Loss: 0.4487, Acc: 0.8259, Speed: 114.5k, Time: 108.2619
Train 0.8258
Val 0.8474
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373

saving model to local_300_parikh
Epoch: 59, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/155.11, Loss: 0.4454, Acc: 0.8270, Speed: 113.0k, Time: 12.0239
Epoch: 59, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/155.11, Loss: 0.4417, Acc: 0.8283, Speed: 114.4k, Time: 24.0695
Epoch: 59, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/155.11, Loss: 0.4434, Acc: 0.8278, Speed: 114.4k, Time: 36.1277
Epoch: 59, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/155.11, Loss: 0.4433, Acc: 0.8279, Speed: 114.3k, Time: 48.1565
Epoch: 59, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/156.63, Loss: 0.4442, Acc: 0.8274, Speed: 114.8k, Time: 59.8260
Epoch: 59, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/172.43, Loss: 0.4448, Acc: 0.8269, Speed: 114.7k, Time: 71.8785
Epoch: 59, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/172.43, Loss: 0.4465, Acc: 0.8263, Speed: 114.8k, Time: 84.0173
Epoch: 59, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/172.43, Loss: 0.4470, Acc: 0.8261, Speed: 114.7k, Time: 96.0681
Epoch: 59, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/172.43, Loss: 0.4469, Acc: 0.8262, Speed: 114.8k, Time: 108.0836
Train 0.8259
Val 0.8458
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849

skip saving model for perf <= 0.8474
Epoch: 60, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/162.08, Loss: 0.4409, Acc: 0.8285, Speed: 116.7k, Time: 12.0280
Epoch: 60, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/162.08, Loss: 0.4421, Acc: 0.8279, Speed: 115.8k, Time: 24.1974
Epoch: 60, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/162.08, Loss: 0.4438, Acc: 0.8276, Speed: 115.5k, Time: 36.1675
Epoch: 60, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/185.47, Loss: 0.4439, Acc: 0.8271, Speed: 115.8k, Time: 48.1071
Epoch: 60, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/185.47, Loss: 0.4449, Acc: 0.8268, Speed: 115.6k, Time: 60.1758
Epoch: 60, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/185.47, Loss: 0.4452, Acc: 0.8267, Speed: 114.9k, Time: 72.3383
Epoch: 60, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/185.47, Loss: 0.4455, Acc: 0.8268, Speed: 114.8k, Time: 84.3915
Epoch: 60, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/185.47, Loss: 0.4457, Acc: 0.8268, Speed: 114.5k, Time: 96.3970
Epoch: 60, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/185.47, Loss: 0.4467, Acc: 0.8264, Speed: 114.4k, Time: 108.3928
Train 0.8263
Val 0.8446
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630

skip saving model for perf <= 0.8474
Epoch: 61, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/158.74, Loss: 0.4494, Acc: 0.8249, Speed: 116.6k, Time: 11.6784
Epoch: 61, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/158.74, Loss: 0.4457, Acc: 0.8268, Speed: 115.7k, Time: 23.5923
Epoch: 61, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/158.74, Loss: 0.4436, Acc: 0.8282, Speed: 114.4k, Time: 35.6566
Epoch: 61, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/166.72, Loss: 0.4435, Acc: 0.8280, Speed: 114.5k, Time: 47.7364
Epoch: 61, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/166.72, Loss: 0.4438, Acc: 0.8277, Speed: 115.3k, Time: 59.4307
Epoch: 61, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/169.05, Loss: 0.4442, Acc: 0.8274, Speed: 115.0k, Time: 71.5032
Epoch: 61, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/169.05, Loss: 0.4442, Acc: 0.8271, Speed: 114.8k, Time: 83.5954
Epoch: 61, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/169.05, Loss: 0.4449, Acc: 0.8269, Speed: 115.0k, Time: 95.6089
Epoch: 61, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/169.05, Loss: 0.4458, Acc: 0.8267, Speed: 115.1k, Time: 107.6139
Train 0.8265
Val 0.8436
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613

skip saving model for perf <= 0.8474
Epoch: 62, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/179.01, Loss: 0.4444, Acc: 0.8281, Speed: 115.5k, Time: 12.1241
Epoch: 62, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.01, Loss: 0.4430, Acc: 0.8284, Speed: 114.5k, Time: 24.1747
Epoch: 62, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.01, Loss: 0.4440, Acc: 0.8283, Speed: 114.1k, Time: 36.3350
Epoch: 62, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/210.61, Loss: 0.4452, Acc: 0.8275, Speed: 114.4k, Time: 48.3294
Epoch: 62, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/210.61, Loss: 0.4443, Acc: 0.8277, Speed: 114.0k, Time: 60.3677
Epoch: 62, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/210.61, Loss: 0.4449, Acc: 0.8273, Speed: 114.7k, Time: 72.1454
Epoch: 62, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/210.61, Loss: 0.4457, Acc: 0.8269, Speed: 114.5k, Time: 84.2655
Epoch: 62, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/210.61, Loss: 0.4457, Acc: 0.8269, Speed: 114.4k, Time: 96.4516
Epoch: 62, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/210.61, Loss: 0.4456, Acc: 0.8270, Speed: 114.3k, Time: 108.5290
Train 0.8269
Val 0.8467
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662

skip saving model for perf <= 0.8474
Epoch: 63, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/155.97, Loss: 0.4417, Acc: 0.8301, Speed: 114.2k, Time: 12.0744
Epoch: 63, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/160.72, Loss: 0.4451, Acc: 0.8270, Speed: 113.3k, Time: 24.0926
Epoch: 63, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/160.72, Loss: 0.4418, Acc: 0.8280, Speed: 112.9k, Time: 36.1983
Epoch: 63, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/160.72, Loss: 0.4430, Acc: 0.8277, Speed: 113.1k, Time: 48.3699
Epoch: 63, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/166.56, Loss: 0.4437, Acc: 0.8273, Speed: 113.1k, Time: 60.5177
Epoch: 63, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/166.56, Loss: 0.4445, Acc: 0.8270, Speed: 113.3k, Time: 72.7391
Epoch: 63, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/166.56, Loss: 0.4445, Acc: 0.8268, Speed: 113.2k, Time: 84.7098
Epoch: 63, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/166.56, Loss: 0.4445, Acc: 0.8268, Speed: 113.4k, Time: 96.7904
Epoch: 63, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/166.56, Loss: 0.4442, Acc: 0.8270, Speed: 113.6k, Time: 108.8922
Train 0.8270
Val 0.8472
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170

skip saving model for perf <= 0.8474
Epoch: 64, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/162.89, Loss: 0.4404, Acc: 0.8293, Speed: 116.7k, Time: 11.7281
Epoch: 64, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/175.66, Loss: 0.4383, Acc: 0.8302, Speed: 114.6k, Time: 23.7896
Epoch: 64, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/175.66, Loss: 0.4396, Acc: 0.8298, Speed: 114.4k, Time: 35.9720
Epoch: 64, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/175.66, Loss: 0.4408, Acc: 0.8292, Speed: 114.3k, Time: 48.0015
Epoch: 64, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/175.66, Loss: 0.4414, Acc: 0.8286, Speed: 114.9k, Time: 59.7614
Epoch: 64, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/175.66, Loss: 0.4408, Acc: 0.8288, Speed: 114.7k, Time: 71.8699
Epoch: 64, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/175.66, Loss: 0.4413, Acc: 0.8287, Speed: 114.5k, Time: 84.0879
Epoch: 64, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/189.41, Loss: 0.4415, Acc: 0.8287, Speed: 114.4k, Time: 96.2010
Epoch: 64, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/189.41, Loss: 0.4421, Acc: 0.8285, Speed: 114.5k, Time: 108.2999
Train 0.8285
Val 0.8461
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052

skip saving model for perf <= 0.8474
Epoch: 65, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/152.23, Loss: 0.4378, Acc: 0.8307, Speed: 116.1k, Time: 12.1042
Epoch: 65, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/152.23, Loss: 0.4401, Acc: 0.8290, Speed: 115.6k, Time: 24.1676
Epoch: 65, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/172.20, Loss: 0.4400, Acc: 0.8293, Speed: 115.0k, Time: 36.2925
Epoch: 65, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/172.20, Loss: 0.4400, Acc: 0.8294, Speed: 114.5k, Time: 48.4721
Epoch: 65, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/172.20, Loss: 0.4399, Acc: 0.8297, Speed: 114.2k, Time: 60.5398
Epoch: 65, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/172.20, Loss: 0.4402, Acc: 0.8293, Speed: 114.5k, Time: 72.3284
Epoch: 65, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/172.20, Loss: 0.4409, Acc: 0.8289, Speed: 114.4k, Time: 84.3777
Epoch: 65, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/172.20, Loss: 0.4413, Acc: 0.8287, Speed: 114.6k, Time: 96.4699
Epoch: 65, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/172.20, Loss: 0.4415, Acc: 0.8286, Speed: 114.2k, Time: 108.5876
Train 0.8282
Val 0.8478
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780

saving model to local_300_parikh
Epoch: 66, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/144.47, Loss: 0.4396, Acc: 0.8290, Speed: 116.0k, Time: 11.9193
Epoch: 66, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/150.11, Loss: 0.4405, Acc: 0.8287, Speed: 115.5k, Time: 24.1026
Epoch: 66, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/150.11, Loss: 0.4397, Acc: 0.8294, Speed: 114.4k, Time: 36.3630
Epoch: 66, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/186.81, Loss: 0.4419, Acc: 0.8283, Speed: 113.6k, Time: 48.4945
Epoch: 66, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/186.81, Loss: 0.4429, Acc: 0.8280, Speed: 114.0k, Time: 60.4672
Epoch: 66, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/186.81, Loss: 0.4417, Acc: 0.8286, Speed: 113.5k, Time: 72.6704
Epoch: 66, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/186.81, Loss: 0.4415, Acc: 0.8290, Speed: 113.2k, Time: 84.8213
Epoch: 66, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/186.81, Loss: 0.4418, Acc: 0.8287, Speed: 113.5k, Time: 96.9878
Epoch: 66, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/186.81, Loss: 0.4420, Acc: 0.8287, Speed: 113.8k, Time: 109.1418
Train 0.8287
Val 0.8472
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170

skip saving model for perf <= 0.8478
Epoch: 67, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/177.80, Loss: 0.4391, Acc: 0.8294, Speed: 119.1k, Time: 11.8526
Epoch: 67, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/177.80, Loss: 0.4382, Acc: 0.8297, Speed: 116.1k, Time: 24.0604
Epoch: 67, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/177.80, Loss: 0.4389, Acc: 0.8303, Speed: 115.7k, Time: 36.2475
Epoch: 67, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/177.80, Loss: 0.4387, Acc: 0.8302, Speed: 114.2k, Time: 48.3402
Epoch: 67, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/180.37, Loss: 0.4391, Acc: 0.8303, Speed: 115.1k, Time: 60.1153
Epoch: 67, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/207.11, Loss: 0.4388, Acc: 0.8304, Speed: 114.8k, Time: 72.2288
Epoch: 67, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/207.11, Loss: 0.4396, Acc: 0.8298, Speed: 114.4k, Time: 84.2918
Epoch: 67, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/207.11, Loss: 0.4406, Acc: 0.8292, Speed: 114.4k, Time: 96.4798
Epoch: 67, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/207.11, Loss: 0.4404, Acc: 0.8294, Speed: 114.2k, Time: 108.6137
Train 0.8293
Val 0.8471
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068

skip saving model for perf <= 0.8478
Epoch: 68, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/152.72, Loss: 0.4382, Acc: 0.8296, Speed: 114.9k, Time: 12.1514
Epoch: 68, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/174.22, Loss: 0.4386, Acc: 0.8295, Speed: 113.3k, Time: 24.2988
Epoch: 68, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/174.22, Loss: 0.4405, Acc: 0.8289, Speed: 113.6k, Time: 36.4505
Epoch: 68, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/174.22, Loss: 0.4418, Acc: 0.8287, Speed: 114.1k, Time: 48.5369
Epoch: 68, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/174.22, Loss: 0.4423, Acc: 0.8287, Speed: 113.8k, Time: 60.6582
Epoch: 68, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/174.22, Loss: 0.4416, Acc: 0.8288, Speed: 114.2k, Time: 72.3906
Epoch: 68, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/198.19, Loss: 0.4419, Acc: 0.8287, Speed: 114.5k, Time: 84.4736
Epoch: 68, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/198.19, Loss: 0.4411, Acc: 0.8290, Speed: 114.2k, Time: 96.5248
Epoch: 68, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/198.19, Loss: 0.4410, Acc: 0.8292, Speed: 114.1k, Time: 108.6131
Train 0.8294
Val 0.8441
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122

skip saving model for perf <= 0.8478
Epoch: 69, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/155.15, Loss: 0.4308, Acc: 0.8338, Speed: 115.8k, Time: 11.8638
Epoch: 69, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/155.15, Loss: 0.4359, Acc: 0.8317, Speed: 114.0k, Time: 23.9572
Epoch: 69, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/162.96, Loss: 0.4363, Acc: 0.8315, Speed: 113.9k, Time: 36.1247
Epoch: 69, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/162.96, Loss: 0.4356, Acc: 0.8315, Speed: 113.4k, Time: 48.3011
Epoch: 69, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/185.96, Loss: 0.4363, Acc: 0.8312, Speed: 113.7k, Time: 60.4143
Epoch: 69, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/185.96, Loss: 0.4374, Acc: 0.8305, Speed: 113.8k, Time: 72.5171
Epoch: 69, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/185.96, Loss: 0.4373, Acc: 0.8307, Speed: 113.9k, Time: 84.5643
Epoch: 69, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/185.96, Loss: 0.4367, Acc: 0.8307, Speed: 113.9k, Time: 96.6393
Epoch: 69, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/185.96, Loss: 0.4372, Acc: 0.8305, Speed: 114.2k, Time: 108.6135
Train 0.8304
Val 0.8492
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202

saving model to local_300_parikh
Epoch: 70, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/145.53, Loss: 0.4339, Acc: 0.8319, Speed: 118.4k, Time: 11.7148
Epoch: 70, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/181.12, Loss: 0.4352, Acc: 0.8320, Speed: 115.7k, Time: 23.8703
Epoch: 70, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/184.06, Loss: 0.4349, Acc: 0.8323, Speed: 115.3k, Time: 35.9997
Epoch: 70, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/186.86, Loss: 0.4358, Acc: 0.8319, Speed: 114.3k, Time: 48.1125
Epoch: 70, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/186.86, Loss: 0.4350, Acc: 0.8322, Speed: 114.1k, Time: 59.8887
Epoch: 70, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/186.86, Loss: 0.4356, Acc: 0.8318, Speed: 114.4k, Time: 71.7936
Epoch: 70, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/186.86, Loss: 0.4358, Acc: 0.8317, Speed: 114.5k, Time: 83.9698
Epoch: 70, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/186.86, Loss: 0.4368, Acc: 0.8311, Speed: 114.3k, Time: 96.1260
Epoch: 70, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/186.86, Loss: 0.4367, Acc: 0.8311, Speed: 114.2k, Time: 108.2957
Train 0.8309
Val 0.8519
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946

saving model to local_300_parikh
Epoch: 71, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/177.19, Loss: 0.4346, Acc: 0.8322, Speed: 111.9k, Time: 12.0587
Epoch: 71, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/177.19, Loss: 0.4351, Acc: 0.8324, Speed: 112.5k, Time: 24.1720
Epoch: 71, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/177.19, Loss: 0.4337, Acc: 0.8331, Speed: 112.6k, Time: 36.2858
Epoch: 71, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/177.19, Loss: 0.4341, Acc: 0.8331, Speed: 113.3k, Time: 48.3552
Epoch: 71, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/177.19, Loss: 0.4345, Acc: 0.8330, Speed: 113.3k, Time: 60.4933
Epoch: 71, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/189.84, Loss: 0.4346, Acc: 0.8326, Speed: 114.4k, Time: 72.1466
Epoch: 71, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/189.84, Loss: 0.4346, Acc: 0.8324, Speed: 114.4k, Time: 84.2621
Epoch: 71, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/189.84, Loss: 0.4351, Acc: 0.8323, Speed: 114.3k, Time: 96.3796
Epoch: 71, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/189.84, Loss: 0.4356, Acc: 0.8320, Speed: 114.3k, Time: 108.3320
Train 0.8316
Val 0.8491
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101

skip saving model for perf <= 0.8519
Epoch: 72, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/168.35, Loss: 0.4388, Acc: 0.8307, Speed: 116.8k, Time: 11.7706
Epoch: 72, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/168.35, Loss: 0.4366, Acc: 0.8307, Speed: 116.1k, Time: 23.8025
Epoch: 72, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/168.73, Loss: 0.4376, Acc: 0.8305, Speed: 115.8k, Time: 35.8374
Epoch: 72, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/168.73, Loss: 0.4375, Acc: 0.8303, Speed: 114.9k, Time: 47.9345
Epoch: 72, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4373, Acc: 0.8302, Speed: 115.1k, Time: 59.9341
Epoch: 72, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4381, Acc: 0.8298, Speed: 115.2k, Time: 71.9594
Epoch: 72, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4378, Acc: 0.8302, Speed: 114.9k, Time: 84.1613
Epoch: 72, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4370, Acc: 0.8308, Speed: 114.4k, Time: 96.2724
Epoch: 72, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4368, Acc: 0.8308, Speed: 114.3k, Time: 108.4651
Train 0.8308
Val 0.8496
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609

skip saving model for perf <= 0.8519
Epoch: 73, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/144.24, Loss: 0.4347, Acc: 0.8316, Speed: 118.6k, Time: 11.6915
Epoch: 73, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/161.08, Loss: 0.4347, Acc: 0.8323, Speed: 116.3k, Time: 23.7388
Epoch: 73, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/164.05, Loss: 0.4334, Acc: 0.8322, Speed: 115.6k, Time: 35.7218
Epoch: 73, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/164.55, Loss: 0.4360, Acc: 0.8311, Speed: 115.9k, Time: 47.8286
Epoch: 73, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/164.55, Loss: 0.4347, Acc: 0.8317, Speed: 115.2k, Time: 59.8227
Epoch: 73, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/164.55, Loss: 0.4347, Acc: 0.8318, Speed: 115.3k, Time: 71.6379
Epoch: 73, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/178.83, Loss: 0.4359, Acc: 0.8310, Speed: 115.2k, Time: 83.7855
Epoch: 73, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/178.83, Loss: 0.4360, Acc: 0.8310, Speed: 115.0k, Time: 95.7846
Epoch: 73, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/178.83, Loss: 0.4354, Acc: 0.8311, Speed: 114.9k, Time: 107.8050
Train 0.8312
Val 0.8490
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999

skip saving model for perf <= 0.8519
Epoch: 74, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4377, Acc: 0.8297, Speed: 114.4k, Time: 12.0613
Epoch: 74, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4353, Acc: 0.8313, Speed: 113.6k, Time: 24.1821
Epoch: 74, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4352, Acc: 0.8313, Speed: 114.3k, Time: 36.2154
Epoch: 74, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4359, Acc: 0.8310, Speed: 114.0k, Time: 48.3264
Epoch: 74, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4356, Acc: 0.8311, Speed: 114.0k, Time: 60.3869
Epoch: 74, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4355, Acc: 0.8312, Speed: 114.8k, Time: 72.1107
Epoch: 74, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4355, Acc: 0.8312, Speed: 115.0k, Time: 84.1419
Epoch: 74, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4359, Acc: 0.8311, Speed: 114.9k, Time: 96.2257
Epoch: 74, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/241.88, Loss: 0.4359, Acc: 0.8311, Speed: 114.3k, Time: 108.4517
Train 0.8311
Val 0.8511
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133

skip saving model for perf <= 0.8519
Epoch: 75, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4323, Acc: 0.8317, Speed: 116.4k, Time: 11.7434
Epoch: 75, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4319, Acc: 0.8336, Speed: 114.9k, Time: 23.8923
Epoch: 75, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4319, Acc: 0.8333, Speed: 114.3k, Time: 35.9631
Epoch: 75, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4325, Acc: 0.8329, Speed: 114.1k, Time: 47.9997
Epoch: 75, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4348, Acc: 0.8317, Speed: 114.5k, Time: 59.9929
Epoch: 75, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4351, Acc: 0.8316, Speed: 114.2k, Time: 72.0886
Epoch: 75, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4352, Acc: 0.8315, Speed: 114.4k, Time: 84.1826
Epoch: 75, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4351, Acc: 0.8314, Speed: 114.5k, Time: 96.2900
Epoch: 75, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/200.01, Loss: 0.4348, Acc: 0.8315, Speed: 114.5k, Time: 108.3018
Train 0.8315
Val 0.8512
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235

skip saving model for perf <= 0.8519
Epoch: 76, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/164.00, Loss: 0.4293, Acc: 0.8326, Speed: 116.8k, Time: 11.7869
Epoch: 76, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/168.72, Loss: 0.4308, Acc: 0.8336, Speed: 116.3k, Time: 23.8971
Epoch: 76, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/168.72, Loss: 0.4322, Acc: 0.8328, Speed: 115.0k, Time: 35.9170
Epoch: 76, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/168.72, Loss: 0.4318, Acc: 0.8332, Speed: 114.3k, Time: 48.0515
Epoch: 76, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/168.72, Loss: 0.4317, Acc: 0.8330, Speed: 113.9k, Time: 60.1148
Epoch: 76, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/168.72, Loss: 0.4310, Acc: 0.8331, Speed: 114.5k, Time: 71.8341
Epoch: 76, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/168.72, Loss: 0.4323, Acc: 0.8325, Speed: 114.1k, Time: 83.9100
Epoch: 76, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/168.72, Loss: 0.4323, Acc: 0.8324, Speed: 114.0k, Time: 96.0803
Epoch: 76, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/178.54, Loss: 0.4328, Acc: 0.8322, Speed: 114.5k, Time: 108.0879
Train 0.8321
Val 0.8508
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828

skip saving model for perf <= 0.8519
Epoch: 77, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/165.18, Loss: 0.4372, Acc: 0.8307, Speed: 113.3k, Time: 12.0843
Epoch: 77, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/165.18, Loss: 0.4351, Acc: 0.8322, Speed: 112.9k, Time: 24.1380
Epoch: 77, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/165.18, Loss: 0.4335, Acc: 0.8327, Speed: 113.2k, Time: 36.2098
Epoch: 77, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/165.18, Loss: 0.4346, Acc: 0.8325, Speed: 113.8k, Time: 48.2790
Epoch: 77, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/165.18, Loss: 0.4339, Acc: 0.8323, Speed: 114.1k, Time: 60.3389
Epoch: 77, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/175.81, Loss: 0.4335, Acc: 0.8323, Speed: 114.6k, Time: 72.0376
Epoch: 77, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/175.81, Loss: 0.4327, Acc: 0.8326, Speed: 114.6k, Time: 84.1860
Epoch: 77, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/175.81, Loss: 0.4326, Acc: 0.8326, Speed: 114.3k, Time: 96.2426
Epoch: 77, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/175.81, Loss: 0.4329, Acc: 0.8323, Speed: 114.3k, Time: 108.4123
Train 0.8320
Val 0.8487
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694

skip saving model for perf <= 0.8519
Epoch: 78, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/154.87, Loss: 0.4329, Acc: 0.8311, Speed: 116.7k, Time: 11.8154
Epoch: 78, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/171.66, Loss: 0.4332, Acc: 0.8316, Speed: 114.6k, Time: 23.9479
Epoch: 78, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/178.07, Loss: 0.4319, Acc: 0.8320, Speed: 114.4k, Time: 35.9626
Epoch: 78, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/178.07, Loss: 0.4318, Acc: 0.8320, Speed: 114.2k, Time: 48.0660
Epoch: 78, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/178.07, Loss: 0.4320, Acc: 0.8320, Speed: 114.3k, Time: 60.0806
Epoch: 78, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/178.07, Loss: 0.4347, Acc: 0.8308, Speed: 113.9k, Time: 72.1151
Epoch: 78, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/178.07, Loss: 0.4349, Acc: 0.8308, Speed: 114.2k, Time: 84.1220
Epoch: 78, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/178.07, Loss: 0.4355, Acc: 0.8305, Speed: 114.5k, Time: 96.1194
Epoch: 78, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/178.07, Loss: 0.4352, Acc: 0.8307, Speed: 114.6k, Time: 108.2462
Train 0.8309
Val 0.8510
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031

skip saving model for perf <= 0.8519
Epoch: 79, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/151.43, Loss: 0.4326, Acc: 0.8316, Speed: 116.5k, Time: 11.8442
Epoch: 79, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/190.77, Loss: 0.4293, Acc: 0.8335, Speed: 113.9k, Time: 23.8271
Epoch: 79, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/190.77, Loss: 0.4313, Acc: 0.8331, Speed: 114.1k, Time: 35.8268
Epoch: 79, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/190.77, Loss: 0.4323, Acc: 0.8325, Speed: 114.9k, Time: 47.9738
Epoch: 79, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/210.13, Loss: 0.4315, Acc: 0.8327, Speed: 114.5k, Time: 60.1201
Epoch: 79, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/210.13, Loss: 0.4309, Acc: 0.8330, Speed: 115.3k, Time: 71.8515
Epoch: 79, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/210.13, Loss: 0.4311, Acc: 0.8329, Speed: 115.2k, Time: 83.9161
Epoch: 79, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/210.13, Loss: 0.4309, Acc: 0.8329, Speed: 115.0k, Time: 96.0000
Epoch: 79, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/210.13, Loss: 0.4311, Acc: 0.8329, Speed: 114.8k, Time: 108.0900
Train 0.8327
Val 0.8499
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914

skip saving model for perf <= 0.8519
Epoch: 80, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/157.57, Loss: 0.4348, Acc: 0.8310, Speed: 113.1k, Time: 12.0882
Epoch: 80, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/157.57, Loss: 0.4286, Acc: 0.8342, Speed: 112.8k, Time: 24.2027
Epoch: 80, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/182.95, Loss: 0.4293, Acc: 0.8345, Speed: 113.0k, Time: 36.3722
Epoch: 80, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.38, Loss: 0.4299, Acc: 0.8338, Speed: 113.2k, Time: 48.5378
Epoch: 80, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.38, Loss: 0.4303, Acc: 0.8337, Speed: 113.5k, Time: 60.6600
Epoch: 80, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/194.38, Loss: 0.4308, Acc: 0.8334, Speed: 114.5k, Time: 72.3588
Epoch: 80, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.38, Loss: 0.4315, Acc: 0.8329, Speed: 114.1k, Time: 84.5609
Epoch: 80, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/194.38, Loss: 0.4314, Acc: 0.8329, Speed: 114.3k, Time: 96.5841
Epoch: 80, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/194.38, Loss: 0.4318, Acc: 0.8327, Speed: 114.2k, Time: 108.6845
Train 0.8329
Val 0.8497
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710

skip saving model for perf <= 0.8519
Epoch: 81, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4267, Acc: 0.8355, Speed: 118.9k, Time: 11.7241
Epoch: 81, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4316, Acc: 0.8324, Speed: 115.7k, Time: 23.8786
Epoch: 81, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4314, Acc: 0.8332, Speed: 116.0k, Time: 35.9307
Epoch: 81, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4316, Acc: 0.8330, Speed: 115.2k, Time: 48.0178
Epoch: 81, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4301, Acc: 0.8337, Speed: 114.2k, Time: 60.0577
Epoch: 81, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4310, Acc: 0.8333, Speed: 114.5k, Time: 72.1146
Epoch: 81, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4314, Acc: 0.8330, Speed: 114.5k, Time: 84.2543
Epoch: 81, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4312, Acc: 0.8330, Speed: 114.7k, Time: 96.3036
Epoch: 81, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/201.54, Loss: 0.4313, Acc: 0.8330, Speed: 114.4k, Time: 108.3779
Train 0.8331
Val 0.8502
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218

skip saving model for perf <= 0.8519
Epoch: 82, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/154.40, Loss: 0.4272, Acc: 0.8346, Speed: 116.3k, Time: 11.9741
Epoch: 82, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/175.98, Loss: 0.4307, Acc: 0.8330, Speed: 114.1k, Time: 23.7117
Epoch: 82, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/175.98, Loss: 0.4293, Acc: 0.8338, Speed: 114.3k, Time: 35.7768
Epoch: 82, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/175.98, Loss: 0.4291, Acc: 0.8338, Speed: 114.7k, Time: 47.8732
Epoch: 82, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/175.98, Loss: 0.4300, Acc: 0.8336, Speed: 114.5k, Time: 59.9643
Epoch: 82, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/181.44, Loss: 0.4301, Acc: 0.8335, Speed: 115.0k, Time: 71.8015
Epoch: 82, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/181.44, Loss: 0.4297, Acc: 0.8337, Speed: 115.0k, Time: 83.8469
Epoch: 82, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/181.44, Loss: 0.4304, Acc: 0.8333, Speed: 114.8k, Time: 95.9513
Epoch: 82, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/203.38, Loss: 0.4304, Acc: 0.8335, Speed: 114.7k, Time: 107.9856
Train 0.8335
Val 0.8539
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877

saving model to local_300_parikh
Epoch: 83, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/138.57, Loss: 0.4284, Acc: 0.8338, Speed: 111.7k, Time: 12.1401
Epoch: 83, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/172.00, Loss: 0.4298, Acc: 0.8336, Speed: 114.1k, Time: 24.2461
Epoch: 83, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/172.00, Loss: 0.4272, Acc: 0.8346, Speed: 114.0k, Time: 36.3931
Epoch: 83, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/172.00, Loss: 0.4293, Acc: 0.8343, Speed: 114.0k, Time: 48.3936
Epoch: 83, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/180.26, Loss: 0.4292, Acc: 0.8343, Speed: 114.1k, Time: 60.4799
Epoch: 83, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/180.26, Loss: 0.4291, Acc: 0.8345, Speed: 114.0k, Time: 72.4671
Epoch: 83, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/189.50, Loss: 0.4287, Acc: 0.8344, Speed: 114.5k, Time: 84.2750
Epoch: 83, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/189.50, Loss: 0.4287, Acc: 0.8344, Speed: 114.5k, Time: 96.2727
Epoch: 83, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/189.50, Loss: 0.4292, Acc: 0.8340, Speed: 114.3k, Time: 108.3491
Train 0.8342
Val 0.8497
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710

skip saving model for perf <= 0.8539
Epoch: 84, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.67, Loss: 0.4301, Acc: 0.8317, Speed: 118.5k, Time: 11.5531
Epoch: 84, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/200.67, Loss: 0.4296, Acc: 0.8327, Speed: 117.2k, Time: 23.7118
Epoch: 84, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/226.07, Loss: 0.4300, Acc: 0.8333, Speed: 116.0k, Time: 35.8245
Epoch: 84, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/226.07, Loss: 0.4291, Acc: 0.8338, Speed: 115.5k, Time: 47.8265
Epoch: 84, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/226.07, Loss: 0.4286, Acc: 0.8340, Speed: 115.1k, Time: 59.9530
Epoch: 84, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/226.07, Loss: 0.4283, Acc: 0.8344, Speed: 114.7k, Time: 72.0419
Epoch: 84, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/226.07, Loss: 0.4287, Acc: 0.8340, Speed: 114.2k, Time: 84.0896
Epoch: 84, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/226.07, Loss: 0.4293, Acc: 0.8339, Speed: 114.3k, Time: 96.2747
Epoch: 84, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/226.07, Loss: 0.4287, Acc: 0.8341, Speed: 114.4k, Time: 108.4122
Train 0.8338
Val 0.8504
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422

skip saving model for perf <= 0.8539
Epoch: 85, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/165.46, Loss: 0.4282, Acc: 0.8348, Speed: 113.3k, Time: 12.0026
Epoch: 85, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4262, Acc: 0.8354, Speed: 115.1k, Time: 23.7453
Epoch: 85, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4264, Acc: 0.8352, Speed: 114.6k, Time: 35.7821
Epoch: 85, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4278, Acc: 0.8341, Speed: 114.4k, Time: 47.8881
Epoch: 85, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/192.06, Loss: 0.4271, Acc: 0.8344, Speed: 114.4k, Time: 60.0275
Epoch: 85, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/192.06, Loss: 0.4278, Acc: 0.8344, Speed: 115.1k, Time: 71.6781
Epoch: 85, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/213.43, Loss: 0.4281, Acc: 0.8342, Speed: 114.7k, Time: 83.7773
Epoch: 85, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/213.43, Loss: 0.4284, Acc: 0.8342, Speed: 114.6k, Time: 95.8783
Epoch: 85, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/213.43, Loss: 0.4285, Acc: 0.8342, Speed: 114.7k, Time: 107.9476
Train 0.8340
Val 0.8534
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369

skip saving model for perf <= 0.8539
Epoch: 86, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/156.70, Loss: 0.4280, Acc: 0.8334, Speed: 116.7k, Time: 12.0275
Epoch: 86, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/156.70, Loss: 0.4265, Acc: 0.8354, Speed: 114.3k, Time: 24.2200
Epoch: 86, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/163.96, Loss: 0.4285, Acc: 0.8344, Speed: 114.2k, Time: 36.3643
Epoch: 86, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/170.03, Loss: 0.4270, Acc: 0.8350, Speed: 114.0k, Time: 48.4919
Epoch: 86, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/191.16, Loss: 0.4274, Acc: 0.8346, Speed: 114.0k, Time: 60.6200
Epoch: 86, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/194.58, Loss: 0.4271, Acc: 0.8347, Speed: 114.3k, Time: 72.7586
Epoch: 86, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.58, Loss: 0.4269, Acc: 0.8349, Speed: 114.7k, Time: 84.4166
Epoch: 86, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/194.58, Loss: 0.4264, Acc: 0.8350, Speed: 114.3k, Time: 96.5594
Epoch: 86, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/194.58, Loss: 0.4270, Acc: 0.8347, Speed: 114.3k, Time: 108.5626
Train 0.8344
Val 0.8542
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181

saving model to local_300_parikh
Epoch: 87, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/164.54, Loss: 0.4233, Acc: 0.8375, Speed: 116.5k, Time: 11.7058
Epoch: 87, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/173.70, Loss: 0.4289, Acc: 0.8346, Speed: 115.0k, Time: 23.7587
Epoch: 87, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/227.30, Loss: 0.4313, Acc: 0.8335, Speed: 115.2k, Time: 35.7352
Epoch: 87, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/227.30, Loss: 0.4305, Acc: 0.8335, Speed: 115.1k, Time: 47.7909
Epoch: 87, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/227.30, Loss: 0.4306, Acc: 0.8336, Speed: 114.5k, Time: 60.0420
Epoch: 87, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/227.30, Loss: 0.4304, Acc: 0.8336, Speed: 114.7k, Time: 72.1470
Epoch: 87, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/227.30, Loss: 0.4305, Acc: 0.8335, Speed: 114.5k, Time: 84.2735
Epoch: 87, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/227.30, Loss: 0.4300, Acc: 0.8336, Speed: 114.3k, Time: 96.4655
Epoch: 87, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/227.30, Loss: 0.4298, Acc: 0.8335, Speed: 114.3k, Time: 108.5509
Train 0.8337
Val 0.8549
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893

saving model to local_300_parikh
Epoch: 88, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/147.50, Loss: 0.4275, Acc: 0.8348, Speed: 115.4k, Time: 12.0308
Epoch: 88, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/169.42, Loss: 0.4283, Acc: 0.8345, Speed: 117.3k, Time: 23.7449
Epoch: 88, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/169.42, Loss: 0.4276, Acc: 0.8349, Speed: 115.6k, Time: 35.8380
Epoch: 88, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/169.42, Loss: 0.4270, Acc: 0.8352, Speed: 114.9k, Time: 47.9036
Epoch: 88, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/169.42, Loss: 0.4278, Acc: 0.8348, Speed: 114.5k, Time: 59.9974
Epoch: 88, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/169.42, Loss: 0.4278, Acc: 0.8349, Speed: 115.1k, Time: 71.5465
Epoch: 88, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/188.74, Loss: 0.4274, Acc: 0.8352, Speed: 114.9k, Time: 83.6681
Epoch: 88, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/188.74, Loss: 0.4276, Acc: 0.8351, Speed: 115.0k, Time: 95.7827
Epoch: 88, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/188.74, Loss: 0.4273, Acc: 0.8354, Speed: 114.9k, Time: 107.8587
Train 0.8353
Val 0.8535
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470

skip saving model for perf <= 0.8549
Epoch: 89, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.68, Loss: 0.4310, Acc: 0.8335, Speed: 113.3k, Time: 12.1073
Epoch: 89, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/172.21, Loss: 0.4275, Acc: 0.8349, Speed: 114.1k, Time: 24.2042
Epoch: 89, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/172.21, Loss: 0.4250, Acc: 0.8363, Speed: 113.5k, Time: 36.3419
Epoch: 89, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/172.21, Loss: 0.4243, Acc: 0.8364, Speed: 113.3k, Time: 48.4615
Epoch: 89, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/172.21, Loss: 0.4236, Acc: 0.8370, Speed: 113.4k, Time: 60.5016
Epoch: 89, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/172.21, Loss: 0.4234, Acc: 0.8369, Speed: 113.6k, Time: 72.5479
Epoch: 89, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/172.21, Loss: 0.4248, Acc: 0.8361, Speed: 114.2k, Time: 84.2510
Epoch: 89, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/195.42, Loss: 0.4251, Acc: 0.8358, Speed: 114.4k, Time: 96.3390
Epoch: 89, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/195.42, Loss: 0.4259, Acc: 0.8354, Speed: 114.3k, Time: 108.4458
Train 0.8351
Val 0.8565
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519

saving model to local_300_parikh
Epoch: 90, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/152.35, Loss: 0.4263, Acc: 0.8341, Speed: 116.0k, Time: 11.7720
Epoch: 90, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/162.18, Loss: 0.4254, Acc: 0.8348, Speed: 115.8k, Time: 23.8256
Epoch: 90, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/177.89, Loss: 0.4248, Acc: 0.8351, Speed: 115.4k, Time: 35.8864
Epoch: 90, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/177.89, Loss: 0.4262, Acc: 0.8348, Speed: 114.4k, Time: 48.0321
Epoch: 90, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/177.89, Loss: 0.4265, Acc: 0.8347, Speed: 114.1k, Time: 60.1814
Epoch: 90, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/177.89, Loss: 0.4271, Acc: 0.8347, Speed: 114.1k, Time: 72.2817
Epoch: 90, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/177.89, Loss: 0.4270, Acc: 0.8351, Speed: 114.2k, Time: 84.2664
Epoch: 90, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/177.89, Loss: 0.4268, Acc: 0.8352, Speed: 114.3k, Time: 96.3348
Epoch: 90, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/177.89, Loss: 0.4270, Acc: 0.8352, Speed: 114.3k, Time: 108.4738
Train 0.8351
Val 0.8534
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369

skip saving model for perf <= 0.8565
Epoch: 91, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/157.57, Loss: 0.4279, Acc: 0.8349, Speed: 114.2k, Time: 12.1095
Epoch: 91, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/207.81, Loss: 0.4278, Acc: 0.8361, Speed: 115.7k, Time: 23.7621
Epoch: 91, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/236.22, Loss: 0.4273, Acc: 0.8358, Speed: 114.7k, Time: 35.8614
Epoch: 91, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/236.22, Loss: 0.4270, Acc: 0.8357, Speed: 114.6k, Time: 47.8702
Epoch: 91, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/236.22, Loss: 0.4260, Acc: 0.8360, Speed: 114.2k, Time: 59.9644
Epoch: 91, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/236.22, Loss: 0.4262, Acc: 0.8359, Speed: 114.7k, Time: 71.7064
Epoch: 91, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/236.22, Loss: 0.4266, Acc: 0.8355, Speed: 114.8k, Time: 83.8594
Epoch: 91, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/236.22, Loss: 0.4265, Acc: 0.8355, Speed: 114.7k, Time: 96.0460
Epoch: 91, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/236.22, Loss: 0.4267, Acc: 0.8353, Speed: 114.7k, Time: 108.1311
Train 0.8354
Val 0.8533
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267

skip saving model for perf <= 0.8565
Epoch: 92, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/162.80, Loss: 0.4267, Acc: 0.8336, Speed: 115.4k, Time: 12.0979
Epoch: 92, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4252, Acc: 0.8344, Speed: 115.5k, Time: 24.2128
Epoch: 92, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4245, Acc: 0.8352, Speed: 114.6k, Time: 36.3176
Epoch: 92, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4240, Acc: 0.8353, Speed: 114.8k, Time: 48.5027
Epoch: 92, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4238, Acc: 0.8353, Speed: 114.8k, Time: 60.5943
Epoch: 92, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4244, Acc: 0.8352, Speed: 113.9k, Time: 72.6977
Epoch: 92, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4245, Acc: 0.8353, Speed: 114.5k, Time: 84.4445
Epoch: 92, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4246, Acc: 0.8353, Speed: 114.3k, Time: 96.4425
Epoch: 92, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/177.36, Loss: 0.4247, Acc: 0.8353, Speed: 114.4k, Time: 108.4904
Train 0.8354
Val 0.8539
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877

skip saving model for perf <= 0.8565
Epoch: 93, Batch: 1000/9683, LR: 0.0500, Grad: 0.01/153.23, Loss: 0.4261, Acc: 0.8338, Speed: 115.9k, Time: 11.7615
Epoch: 93, Batch: 2000/9683, LR: 0.0500, Grad: 0.01/167.55, Loss: 0.4270, Acc: 0.8338, Speed: 114.2k, Time: 23.9709
Epoch: 93, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/195.16, Loss: 0.4242, Acc: 0.8355, Speed: 114.4k, Time: 36.0600
Epoch: 93, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/204.05, Loss: 0.4236, Acc: 0.8357, Speed: 114.7k, Time: 48.1590
Epoch: 93, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/204.05, Loss: 0.4250, Acc: 0.8352, Speed: 114.8k, Time: 60.2336
Epoch: 93, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/204.05, Loss: 0.4250, Acc: 0.8354, Speed: 114.4k, Time: 72.3333
Epoch: 93, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/204.05, Loss: 0.4250, Acc: 0.8354, Speed: 114.3k, Time: 84.4035
Epoch: 93, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/204.05, Loss: 0.4253, Acc: 0.8353, Speed: 114.3k, Time: 96.5500
Epoch: 93, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/204.05, Loss: 0.4249, Acc: 0.8355, Speed: 114.1k, Time: 108.6817
Train 0.8357
Val 0.8524
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352

skip saving model for perf <= 0.8565
Epoch: 94, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/186.93, Loss: 0.4232, Acc: 0.8367, Speed: 115.8k, Time: 12.1600
Epoch: 94, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/186.93, Loss: 0.4242, Acc: 0.8362, Speed: 115.8k, Time: 23.9439
Epoch: 94, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/186.93, Loss: 0.4243, Acc: 0.8359, Speed: 114.9k, Time: 35.9688
Epoch: 94, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/186.93, Loss: 0.4236, Acc: 0.8363, Speed: 114.6k, Time: 48.1998
Epoch: 94, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/189.96, Loss: 0.4240, Acc: 0.8360, Speed: 114.5k, Time: 60.3218
Epoch: 94, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/189.96, Loss: 0.4237, Acc: 0.8363, Speed: 114.9k, Time: 72.0778
Epoch: 94, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/189.96, Loss: 0.4232, Acc: 0.8368, Speed: 114.6k, Time: 84.2044
Epoch: 94, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/189.96, Loss: 0.4239, Acc: 0.8364, Speed: 114.8k, Time: 96.2470
Epoch: 94, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/189.96, Loss: 0.4247, Acc: 0.8360, Speed: 114.4k, Time: 108.3816
Train 0.8359
Val 0.8533
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267

skip saving model for perf <= 0.8565
Epoch: 95, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/176.18, Loss: 0.4271, Acc: 0.8350, Speed: 114.4k, Time: 12.0729
Epoch: 95, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4256, Acc: 0.8357, Speed: 114.8k, Time: 24.1819
Epoch: 95, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4232, Acc: 0.8363, Speed: 113.8k, Time: 36.3814
Epoch: 95, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4231, Acc: 0.8363, Speed: 113.1k, Time: 48.5631
Epoch: 95, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4228, Acc: 0.8365, Speed: 113.0k, Time: 60.7764
Epoch: 95, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4242, Acc: 0.8359, Speed: 113.4k, Time: 72.8941
Epoch: 95, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4237, Acc: 0.8363, Speed: 113.8k, Time: 84.7390
Epoch: 95, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4244, Acc: 0.8360, Speed: 113.7k, Time: 96.9018
Epoch: 95, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/217.05, Loss: 0.4253, Acc: 0.8356, Speed: 113.7k, Time: 109.1186
Train 0.8352
Val 0.8541
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080

skip saving model for perf <= 0.8565
Epoch: 96, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/152.93, Loss: 0.4320, Acc: 0.8325, Speed: 118.7k, Time: 11.7036
Epoch: 96, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/152.93, Loss: 0.4272, Acc: 0.8340, Speed: 115.9k, Time: 23.8403
Epoch: 96, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/160.64, Loss: 0.4255, Acc: 0.8350, Speed: 115.6k, Time: 35.9329
Epoch: 96, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.4249, Acc: 0.8355, Speed: 114.9k, Time: 48.1752
Epoch: 96, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.4250, Acc: 0.8352, Speed: 114.7k, Time: 60.3984
Epoch: 96, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.4244, Acc: 0.8357, Speed: 114.5k, Time: 72.5692
Epoch: 96, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.4249, Acc: 0.8356, Speed: 114.4k, Time: 84.5543
Epoch: 96, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.4255, Acc: 0.8354, Speed: 114.4k, Time: 96.5712
Epoch: 96, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.4249, Acc: 0.8357, Speed: 114.6k, Time: 108.2559
Train 0.8356
Val 0.8530
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962

skip saving model for perf <= 0.8565
Epoch: 97, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/170.11, Loss: 0.4232, Acc: 0.8360, Speed: 119.7k, Time: 11.6640
Epoch: 97, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/170.11, Loss: 0.4239, Acc: 0.8362, Speed: 119.2k, Time: 23.1556
Epoch: 97, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/170.11, Loss: 0.4218, Acc: 0.8374, Speed: 117.4k, Time: 35.0958
Epoch: 97, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/170.11, Loss: 0.4220, Acc: 0.8372, Speed: 116.7k, Time: 47.2480
Epoch: 97, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/180.60, Loss: 0.4254, Acc: 0.8356, Speed: 116.3k, Time: 59.3812
Epoch: 97, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/187.64, Loss: 0.4247, Acc: 0.8357, Speed: 116.2k, Time: 71.1052
Epoch: 97, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/187.64, Loss: 0.4258, Acc: 0.8352, Speed: 116.5k, Time: 82.9393
Epoch: 97, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/187.82, Loss: 0.4264, Acc: 0.8348, Speed: 116.2k, Time: 95.1358
Epoch: 97, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/200.65, Loss: 0.4265, Acc: 0.8346, Speed: 115.7k, Time: 107.3036
Train 0.8347
Val 0.8546
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588

skip saving model for perf <= 0.8565
Epoch: 98, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/192.80, Loss: 0.4287, Acc: 0.8334, Speed: 111.7k, Time: 12.2399
Epoch: 98, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/192.80, Loss: 0.4258, Acc: 0.8349, Speed: 112.7k, Time: 24.4741
Epoch: 98, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/224.68, Loss: 0.4264, Acc: 0.8349, Speed: 112.8k, Time: 36.7014
Epoch: 98, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/224.68, Loss: 0.4273, Acc: 0.8344, Speed: 112.8k, Time: 48.8870
Epoch: 98, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/224.68, Loss: 0.4278, Acc: 0.8345, Speed: 112.8k, Time: 61.0638
Epoch: 98, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/224.68, Loss: 0.4276, Acc: 0.8346, Speed: 113.0k, Time: 73.0516
Epoch: 98, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/224.68, Loss: 0.4275, Acc: 0.8346, Speed: 113.2k, Time: 84.9980
Epoch: 98, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/224.68, Loss: 0.4271, Acc: 0.8347, Speed: 113.3k, Time: 97.0876
Epoch: 98, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/224.68, Loss: 0.4280, Acc: 0.8343, Speed: 113.5k, Time: 109.2853
Train 0.8344
Val 0.8533
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267

skip saving model for perf <= 0.8565
Epoch: 99, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.4181, Acc: 0.8395, Speed: 111.2k, Time: 12.0424
Epoch: 99, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.4224, Acc: 0.8376, Speed: 114.1k, Time: 23.8793
Epoch: 99, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.4240, Acc: 0.8367, Speed: 114.7k, Time: 35.9273
Epoch: 99, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.4257, Acc: 0.8358, Speed: 114.8k, Time: 48.0047
Epoch: 99, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.4256, Acc: 0.8361, Speed: 114.7k, Time: 60.0553
Epoch: 99, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/187.52, Loss: 0.4255, Acc: 0.8361, Speed: 114.5k, Time: 72.1620
Epoch: 99, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/206.65, Loss: 0.4250, Acc: 0.8363, Speed: 114.6k, Time: 84.2391
Epoch: 99, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/206.65, Loss: 0.4247, Acc: 0.8363, Speed: 114.1k, Time: 96.4834
Epoch: 99, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/206.65, Loss: 0.4251, Acc: 0.8361, Speed: 113.8k, Time: 108.6517
Train 0.8358
Val 0.8530
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962

skip saving model for perf <= 0.8565
Epoch: 100, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/159.78, Loss: 0.4191, Acc: 0.8400, Speed: 114.8k, Time: 11.9495
Epoch: 100, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/159.78, Loss: 0.4197, Acc: 0.8383, Speed: 115.1k, Time: 24.0543
Epoch: 100, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/159.78, Loss: 0.4205, Acc: 0.8385, Speed: 116.4k, Time: 35.7793
Epoch: 100, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/167.20, Loss: 0.4206, Acc: 0.8382, Speed: 115.8k, Time: 47.9245
Epoch: 100, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/167.20, Loss: 0.4225, Acc: 0.8374, Speed: 114.8k, Time: 60.0135
Epoch: 100, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/167.20, Loss: 0.4230, Acc: 0.8369, Speed: 114.8k, Time: 71.9487
Epoch: 100, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/167.20, Loss: 0.4233, Acc: 0.8367, Speed: 115.1k, Time: 83.6447
Epoch: 100, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/197.97, Loss: 0.4236, Acc: 0.8364, Speed: 115.0k, Time: 95.8618
Epoch: 100, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/197.97, Loss: 0.4240, Acc: 0.8363, Speed: 114.9k, Time: 107.8316
Train 0.8363
Val 0.8559
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909

skip saving model for perf <= 0.8565
Epoch: 101, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/153.56, Loss: 0.4245, Acc: 0.8372, Speed: 115.8k, Time: 12.1451
Epoch: 101, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/192.20, Loss: 0.4241, Acc: 0.8373, Speed: 114.5k, Time: 24.2547
Epoch: 101, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/192.20, Loss: 0.4244, Acc: 0.8371, Speed: 114.0k, Time: 36.3829
Epoch: 101, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/192.20, Loss: 0.4255, Acc: 0.8362, Speed: 113.9k, Time: 48.4701
Epoch: 101, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/221.37, Loss: 0.4244, Acc: 0.8363, Speed: 114.3k, Time: 60.5190
Epoch: 101, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/221.37, Loss: 0.4233, Acc: 0.8371, Speed: 114.0k, Time: 72.4478
Epoch: 101, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/221.37, Loss: 0.4229, Acc: 0.8372, Speed: 114.1k, Time: 84.4751
Epoch: 101, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/221.37, Loss: 0.4216, Acc: 0.8377, Speed: 114.2k, Time: 96.3394
Epoch: 101, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/221.37, Loss: 0.4219, Acc: 0.8375, Speed: 114.1k, Time: 108.4499
Train 0.8374
Val 0.8537
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673

skip saving model for perf <= 0.8565
Epoch: 102, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/175.48, Loss: 0.4231, Acc: 0.8364, Speed: 111.1k, Time: 12.2146
Epoch: 102, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4232, Acc: 0.8365, Speed: 114.5k, Time: 23.9527
Epoch: 102, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4228, Acc: 0.8364, Speed: 115.0k, Time: 36.0109
Epoch: 102, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4229, Acc: 0.8364, Speed: 114.6k, Time: 48.0502
Epoch: 102, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4224, Acc: 0.8367, Speed: 114.5k, Time: 60.1189
Epoch: 102, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4216, Acc: 0.8372, Speed: 114.4k, Time: 72.1693
Epoch: 102, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4230, Acc: 0.8365, Speed: 114.5k, Time: 84.2189
Epoch: 102, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4238, Acc: 0.8363, Speed: 114.4k, Time: 96.3316
Epoch: 102, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/252.90, Loss: 0.4237, Acc: 0.8364, Speed: 114.2k, Time: 108.4963
Train 0.8364
Val 0.8567
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722

saving model to local_300_parikh
Epoch: 103, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/153.65, Loss: 0.4110, Acc: 0.8413, Speed: 118.0k, Time: 11.4758
Epoch: 103, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.67, Loss: 0.4156, Acc: 0.8393, Speed: 118.2k, Time: 22.9310
Epoch: 103, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/194.21, Loss: 0.4170, Acc: 0.8388, Speed: 120.7k, Time: 33.7810
Epoch: 103, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.21, Loss: 0.4192, Acc: 0.8378, Speed: 121.5k, Time: 45.1303
Epoch: 103, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.21, Loss: 0.4196, Acc: 0.8377, Speed: 121.6k, Time: 56.6039
Epoch: 103, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/220.54, Loss: 0.4196, Acc: 0.8378, Speed: 121.9k, Time: 67.9267
Epoch: 103, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/220.54, Loss: 0.4205, Acc: 0.8376, Speed: 122.8k, Time: 78.7415
Epoch: 103, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/220.54, Loss: 0.4212, Acc: 0.8373, Speed: 122.6k, Time: 90.0352
Epoch: 103, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/220.54, Loss: 0.4211, Acc: 0.8371, Speed: 122.2k, Time: 101.3364
Train 0.8371
Val 0.8531
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064

skip saving model for perf <= 0.8567
Epoch: 104, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/157.62, Loss: 0.4216, Acc: 0.8366, Speed: 120.2k, Time: 11.5437
Epoch: 104, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/169.18, Loss: 0.4221, Acc: 0.8371, Speed: 119.8k, Time: 22.9166
Epoch: 104, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/169.18, Loss: 0.4225, Acc: 0.8365, Speed: 120.4k, Time: 34.2640
Epoch: 104, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/169.44, Loss: 0.4228, Acc: 0.8365, Speed: 120.2k, Time: 45.6355
Epoch: 104, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/180.84, Loss: 0.4222, Acc: 0.8367, Speed: 120.2k, Time: 56.9861
Epoch: 104, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/180.84, Loss: 0.4220, Acc: 0.8368, Speed: 120.8k, Time: 68.3246
Epoch: 104, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/180.84, Loss: 0.4223, Acc: 0.8366, Speed: 120.9k, Time: 79.6283
Epoch: 104, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/180.84, Loss: 0.4228, Acc: 0.8363, Speed: 121.0k, Time: 91.0883
Epoch: 104, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/180.84, Loss: 0.4227, Acc: 0.8365, Speed: 121.7k, Time: 101.8836
Train 0.8366
Val 0.8540
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978

skip saving model for perf <= 0.8567
Epoch: 105, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/161.59, Loss: 0.4234, Acc: 0.8356, Speed: 122.7k, Time: 11.3450
Epoch: 105, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/172.65, Loss: 0.4233, Acc: 0.8353, Speed: 120.1k, Time: 22.9487
Epoch: 105, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/172.65, Loss: 0.4235, Acc: 0.8354, Speed: 119.2k, Time: 34.7554
Epoch: 105, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/173.63, Loss: 0.4223, Acc: 0.8363, Speed: 117.6k, Time: 46.9528
Epoch: 105, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/192.42, Loss: 0.4230, Acc: 0.8363, Speed: 117.1k, Time: 59.1687
Epoch: 105, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/192.42, Loss: 0.4220, Acc: 0.8363, Speed: 116.5k, Time: 71.3811
Epoch: 105, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/192.42, Loss: 0.4211, Acc: 0.8370, Speed: 115.5k, Time: 83.6037
Epoch: 105, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/192.42, Loss: 0.4207, Acc: 0.8371, Speed: 114.8k, Time: 95.8411
Epoch: 105, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/192.42, Loss: 0.4209, Acc: 0.8371, Speed: 114.6k, Time: 108.0261
Train 0.8369
Val 0.8542
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181

skip saving model for perf <= 0.8567
Epoch: 106, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4178, Acc: 0.8382, Speed: 112.2k, Time: 12.2197
Epoch: 106, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4187, Acc: 0.8384, Speed: 111.7k, Time: 24.4569
Epoch: 106, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4195, Acc: 0.8377, Speed: 112.1k, Time: 36.7813
Epoch: 106, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4219, Acc: 0.8368, Speed: 113.3k, Time: 48.6209
Epoch: 106, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4195, Acc: 0.8376, Speed: 113.6k, Time: 60.6648
Epoch: 106, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4191, Acc: 0.8379, Speed: 114.0k, Time: 72.5996
Epoch: 106, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4192, Acc: 0.8379, Speed: 114.1k, Time: 84.5606
Epoch: 106, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4192, Acc: 0.8380, Speed: 114.7k, Time: 96.1588
Epoch: 106, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/185.98, Loss: 0.4194, Acc: 0.8381, Speed: 114.8k, Time: 108.1146
Train 0.8379
Val 0.8519
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946

skip saving model for perf <= 0.8567
Epoch: 107, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/159.98, Loss: 0.4156, Acc: 0.8402, Speed: 116.3k, Time: 11.8402
Epoch: 107, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/181.07, Loss: 0.4148, Acc: 0.8410, Speed: 115.8k, Time: 23.8092
Epoch: 107, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/181.07, Loss: 0.4164, Acc: 0.8400, Speed: 115.9k, Time: 35.6846
Epoch: 107, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/181.43, Loss: 0.4172, Acc: 0.8397, Speed: 116.2k, Time: 47.4938
Epoch: 107, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/181.43, Loss: 0.4174, Acc: 0.8397, Speed: 116.4k, Time: 59.2431
Epoch: 107, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/264.84, Loss: 0.4172, Acc: 0.8396, Speed: 116.3k, Time: 71.0789
Epoch: 107, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/264.84, Loss: 0.4173, Acc: 0.8395, Speed: 116.2k, Time: 82.9802
Epoch: 107, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/264.84, Loss: 0.4190, Acc: 0.8386, Speed: 116.5k, Time: 94.7830
Epoch: 107, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/264.84, Loss: 0.4188, Acc: 0.8385, Speed: 116.3k, Time: 106.6662
Train 0.8384
Val 0.8554
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401

skip saving model for perf <= 0.8567
Epoch: 108, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4190, Acc: 0.8380, Speed: 112.8k, Time: 12.2947
Epoch: 108, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4199, Acc: 0.8381, Speed: 111.5k, Time: 24.6813
Epoch: 108, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4208, Acc: 0.8370, Speed: 111.3k, Time: 37.0041
Epoch: 108, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4208, Acc: 0.8369, Speed: 112.6k, Time: 48.9292
Epoch: 108, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4200, Acc: 0.8372, Speed: 112.6k, Time: 61.1844
Epoch: 108, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4191, Acc: 0.8380, Speed: 112.3k, Time: 73.4880
Epoch: 108, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4199, Acc: 0.8375, Speed: 112.7k, Time: 85.7850
Epoch: 108, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4191, Acc: 0.8379, Speed: 112.5k, Time: 98.0361
Epoch: 108, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/198.23, Loss: 0.4193, Acc: 0.8378, Speed: 112.6k, Time: 110.2831
Train 0.8377
Val 0.8568
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823

saving model to local_300_parikh
Epoch: 109, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/161.96, Loss: 0.4190, Acc: 0.8392, Speed: 110.3k, Time: 12.4402
Epoch: 109, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/167.44, Loss: 0.4197, Acc: 0.8386, Speed: 110.9k, Time: 24.7481
Epoch: 109, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/168.66, Loss: 0.4211, Acc: 0.8378, Speed: 111.1k, Time: 37.1548
Epoch: 109, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/168.66, Loss: 0.4212, Acc: 0.8380, Speed: 110.4k, Time: 49.4251
Epoch: 109, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/182.17, Loss: 0.4214, Acc: 0.8376, Speed: 112.1k, Time: 61.3387
Epoch: 109, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/205.17, Loss: 0.4216, Acc: 0.8375, Speed: 112.4k, Time: 73.6648
Epoch: 109, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/205.17, Loss: 0.4209, Acc: 0.8377, Speed: 112.2k, Time: 85.9871
Epoch: 109, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/205.17, Loss: 0.4203, Acc: 0.8379, Speed: 112.6k, Time: 97.9482
Epoch: 109, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/205.17, Loss: 0.4197, Acc: 0.8379, Speed: 112.5k, Time: 110.3194
Train 0.8381
Val 0.8553
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299

skip saving model for perf <= 0.8568
Epoch: 110, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/193.37, Loss: 0.4218, Acc: 0.8383, Speed: 113.6k, Time: 12.3569
Epoch: 110, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/193.37, Loss: 0.4232, Acc: 0.8375, Speed: 112.4k, Time: 24.7953
Epoch: 110, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/193.37, Loss: 0.4209, Acc: 0.8379, Speed: 111.8k, Time: 37.1695
Epoch: 110, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/193.37, Loss: 0.4205, Acc: 0.8385, Speed: 111.7k, Time: 49.4824
Epoch: 110, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/193.37, Loss: 0.4201, Acc: 0.8384, Speed: 111.8k, Time: 61.7479
Epoch: 110, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/193.37, Loss: 0.4199, Acc: 0.8383, Speed: 111.9k, Time: 73.8872
Epoch: 110, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/195.96, Loss: 0.4194, Acc: 0.8382, Speed: 111.7k, Time: 86.4611
Epoch: 110, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/195.96, Loss: 0.4197, Acc: 0.8379, Speed: 111.8k, Time: 98.7036
Epoch: 110, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/195.96, Loss: 0.4193, Acc: 0.8381, Speed: 112.2k, Time: 110.5853
Train 0.8379
Val 0.8553
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299

skip saving model for perf <= 0.8568
Epoch: 111, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.46, Loss: 0.4108, Acc: 0.8423, Speed: 112.4k, Time: 12.2738
Epoch: 111, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/185.06, Loss: 0.4126, Acc: 0.8409, Speed: 112.7k, Time: 24.6048
Epoch: 111, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/185.06, Loss: 0.4137, Acc: 0.8399, Speed: 113.6k, Time: 36.4982
Epoch: 111, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/185.06, Loss: 0.4153, Acc: 0.8394, Speed: 112.8k, Time: 48.9543
Epoch: 111, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/185.06, Loss: 0.4168, Acc: 0.8391, Speed: 112.5k, Time: 61.2272
Epoch: 111, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/185.06, Loss: 0.4165, Acc: 0.8390, Speed: 113.2k, Time: 73.3769
Epoch: 111, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/188.19, Loss: 0.4165, Acc: 0.8392, Speed: 112.7k, Time: 85.9022
Epoch: 111, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/188.19, Loss: 0.4169, Acc: 0.8390, Speed: 112.7k, Time: 98.2592
Epoch: 111, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/188.19, Loss: 0.4174, Acc: 0.8390, Speed: 112.4k, Time: 110.3448
Train 0.8389
Val 0.8532
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165

skip saving model for perf <= 0.8568
Epoch: 112, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/184.75, Loss: 0.4136, Acc: 0.8405, Speed: 112.2k, Time: 12.3579
Epoch: 112, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/184.75, Loss: 0.4174, Acc: 0.8393, Speed: 112.8k, Time: 24.6467
Epoch: 112, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/184.75, Loss: 0.4147, Acc: 0.8398, Speed: 112.6k, Time: 36.9181
Epoch: 112, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/184.75, Loss: 0.4167, Acc: 0.8389, Speed: 112.1k, Time: 48.9912
Epoch: 112, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/184.75, Loss: 0.4173, Acc: 0.8386, Speed: 112.2k, Time: 61.1789
Epoch: 112, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/184.75, Loss: 0.4173, Acc: 0.8385, Speed: 112.4k, Time: 73.3884
Epoch: 112, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/184.75, Loss: 0.4175, Acc: 0.8385, Speed: 112.0k, Time: 85.9498
Epoch: 112, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/188.88, Loss: 0.4174, Acc: 0.8385, Speed: 112.6k, Time: 97.9396
Epoch: 112, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/188.88, Loss: 0.4182, Acc: 0.8381, Speed: 112.5k, Time: 110.1856
Train 0.8382
Val 0.8571
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128

saving model to local_300_parikh
Epoch: 113, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/151.42, Loss: 0.4128, Acc: 0.8414, Speed: 114.4k, Time: 12.2907
Epoch: 113, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/162.16, Loss: 0.4146, Acc: 0.8400, Speed: 113.1k, Time: 24.6810
Epoch: 113, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/183.53, Loss: 0.4165, Acc: 0.8390, Speed: 113.4k, Time: 36.9007
Epoch: 113, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/183.53, Loss: 0.4165, Acc: 0.8394, Speed: 112.1k, Time: 49.3478
Epoch: 113, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/183.53, Loss: 0.4171, Acc: 0.8393, Speed: 112.1k, Time: 61.6031
Epoch: 113, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/184.53, Loss: 0.4177, Acc: 0.8391, Speed: 111.9k, Time: 74.1584
Epoch: 113, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/184.53, Loss: 0.4174, Acc: 0.8393, Speed: 111.7k, Time: 86.5609
Epoch: 113, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/238.96, Loss: 0.4174, Acc: 0.8393, Speed: 111.7k, Time: 98.8501
Epoch: 113, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/238.96, Loss: 0.4177, Acc: 0.8391, Speed: 112.2k, Time: 110.7947
Train 0.8390
Val 0.8543
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283

skip saving model for perf <= 0.8571
Epoch: 114, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/186.48, Loss: 0.4203, Acc: 0.8375, Speed: 111.4k, Time: 12.3239
Epoch: 114, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4178, Acc: 0.8383, Speed: 113.2k, Time: 24.3869
Epoch: 114, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4157, Acc: 0.8398, Speed: 112.9k, Time: 36.6093
Epoch: 114, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4156, Acc: 0.8398, Speed: 113.2k, Time: 48.9536
Epoch: 114, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4168, Acc: 0.8391, Speed: 113.3k, Time: 61.1997
Epoch: 114, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4173, Acc: 0.8389, Speed: 112.9k, Time: 73.4829
Epoch: 114, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4169, Acc: 0.8389, Speed: 112.5k, Time: 85.8016
Epoch: 114, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4164, Acc: 0.8391, Speed: 112.3k, Time: 98.2038
Epoch: 114, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/206.75, Loss: 0.4164, Acc: 0.8392, Speed: 112.3k, Time: 110.5528
Train 0.8388
Val 0.8566
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620

skip saving model for perf <= 0.8571
Epoch: 115, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/169.13, Loss: 0.4160, Acc: 0.8388, Speed: 110.5k, Time: 12.2436
Epoch: 115, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/169.13, Loss: 0.4168, Acc: 0.8394, Speed: 111.3k, Time: 24.5678
Epoch: 115, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/178.04, Loss: 0.4163, Acc: 0.8397, Speed: 111.9k, Time: 36.8139
Epoch: 115, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/178.04, Loss: 0.4148, Acc: 0.8403, Speed: 112.3k, Time: 48.7860
Epoch: 115, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/215.51, Loss: 0.4152, Acc: 0.8401, Speed: 112.0k, Time: 61.0689
Epoch: 115, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/215.51, Loss: 0.4155, Acc: 0.8399, Speed: 112.0k, Time: 73.4206
Epoch: 115, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/215.51, Loss: 0.4159, Acc: 0.8394, Speed: 112.9k, Time: 85.4125
Epoch: 115, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/215.51, Loss: 0.4159, Acc: 0.8395, Speed: 112.7k, Time: 97.8625
Epoch: 115, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/215.51, Loss: 0.4163, Acc: 0.8392, Speed: 112.6k, Time: 110.1284
Train 0.8394
Val 0.8549
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893

skip saving model for perf <= 0.8571
Epoch: 116, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/168.97, Loss: 0.4136, Acc: 0.8417, Speed: 110.3k, Time: 12.3270
Epoch: 116, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/173.77, Loss: 0.4111, Acc: 0.8428, Speed: 111.7k, Time: 24.5805
Epoch: 116, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/178.16, Loss: 0.4122, Acc: 0.8418, Speed: 111.4k, Time: 36.8300
Epoch: 116, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/178.16, Loss: 0.4143, Acc: 0.8408, Speed: 111.8k, Time: 49.1282
Epoch: 116, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/178.16, Loss: 0.4144, Acc: 0.8405, Speed: 112.1k, Time: 61.4737
Epoch: 116, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/184.00, Loss: 0.4148, Acc: 0.8405, Speed: 112.4k, Time: 73.7563
Epoch: 116, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/196.18, Loss: 0.4142, Acc: 0.8407, Speed: 112.6k, Time: 85.8534
Epoch: 116, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/196.18, Loss: 0.4146, Acc: 0.8405, Speed: 112.7k, Time: 97.8070
Epoch: 116, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/196.18, Loss: 0.4146, Acc: 0.8402, Speed: 112.3k, Time: 110.1399
Train 0.8399
Val 0.8551
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096

skip saving model for perf <= 0.8571
Epoch: 117, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/159.84, Loss: 0.4067, Acc: 0.8415, Speed: 109.4k, Time: 12.2318
Epoch: 117, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/159.84, Loss: 0.4103, Acc: 0.8412, Speed: 112.5k, Time: 24.0656
Epoch: 117, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/185.46, Loss: 0.4095, Acc: 0.8417, Speed: 112.3k, Time: 36.2962
Epoch: 117, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.23, Loss: 0.4108, Acc: 0.8414, Speed: 111.8k, Time: 48.6489
Epoch: 117, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.23, Loss: 0.4120, Acc: 0.8409, Speed: 111.8k, Time: 60.9202
Epoch: 117, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.03, Loss: 0.4129, Acc: 0.8406, Speed: 112.2k, Time: 73.1021
Epoch: 117, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/197.03, Loss: 0.4138, Acc: 0.8402, Speed: 112.5k, Time: 85.3910
Epoch: 117, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/197.03, Loss: 0.4141, Acc: 0.8400, Speed: 112.3k, Time: 97.7811
Epoch: 117, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/197.03, Loss: 0.4144, Acc: 0.8400, Speed: 112.5k, Time: 110.0438
Train 0.8396
Val 0.8555
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502

skip saving model for perf <= 0.8571
Epoch: 118, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/156.01, Loss: 0.4108, Acc: 0.8440, Speed: 114.7k, Time: 12.2707
Epoch: 118, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/171.37, Loss: 0.4138, Acc: 0.8415, Speed: 114.0k, Time: 24.6561
Epoch: 118, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/171.37, Loss: 0.4136, Acc: 0.8414, Speed: 113.8k, Time: 36.6404
Epoch: 118, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/171.37, Loss: 0.4141, Acc: 0.8414, Speed: 112.4k, Time: 48.9528
Epoch: 118, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/171.37, Loss: 0.4149, Acc: 0.8410, Speed: 111.9k, Time: 61.2462
Epoch: 118, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/171.37, Loss: 0.4150, Acc: 0.8406, Speed: 112.3k, Time: 73.4709
Epoch: 118, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/171.37, Loss: 0.4158, Acc: 0.8400, Speed: 113.1k, Time: 85.4224
Epoch: 118, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/178.55, Loss: 0.4160, Acc: 0.8398, Speed: 112.9k, Time: 97.7778
Epoch: 118, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/178.55, Loss: 0.4160, Acc: 0.8398, Speed: 112.6k, Time: 110.0444
Train 0.8397
Val 0.8572
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230

saving model to local_300_parikh
Epoch: 119, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/166.94, Loss: 0.4167, Acc: 0.8400, Speed: 112.0k, Time: 12.3272
Epoch: 119, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/173.27, Loss: 0.4165, Acc: 0.8392, Speed: 111.1k, Time: 24.6353
Epoch: 119, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/198.52, Loss: 0.4175, Acc: 0.8391, Speed: 111.0k, Time: 36.9878
Epoch: 119, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/221.78, Loss: 0.4178, Acc: 0.8386, Speed: 110.9k, Time: 49.3719
Epoch: 119, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/221.78, Loss: 0.4175, Acc: 0.8391, Speed: 111.3k, Time: 61.5965
Epoch: 119, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/221.78, Loss: 0.4167, Acc: 0.8393, Speed: 111.5k, Time: 73.8506
Epoch: 119, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/221.78, Loss: 0.4162, Acc: 0.8395, Speed: 111.6k, Time: 86.2044
Epoch: 119, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/221.78, Loss: 0.4161, Acc: 0.8395, Speed: 112.4k, Time: 98.1736
Epoch: 119, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/221.78, Loss: 0.4158, Acc: 0.8397, Speed: 112.2k, Time: 110.4764
Train 0.8399
Val 0.8566
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620

skip saving model for perf <= 0.8572
Epoch: 120, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/153.03, Loss: 0.4146, Acc: 0.8412, Speed: 117.1k, Time: 11.9264
Epoch: 120, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/167.86, Loss: 0.4120, Acc: 0.8415, Speed: 114.2k, Time: 24.1680
Epoch: 120, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/167.86, Loss: 0.4136, Acc: 0.8405, Speed: 113.3k, Time: 36.4171
Epoch: 120, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/169.75, Loss: 0.4128, Acc: 0.8410, Speed: 113.1k, Time: 48.7385
Epoch: 120, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/173.97, Loss: 0.4110, Acc: 0.8421, Speed: 113.0k, Time: 60.9584
Epoch: 120, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/173.97, Loss: 0.4121, Acc: 0.8413, Speed: 112.6k, Time: 73.3064
Epoch: 120, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/173.97, Loss: 0.4127, Acc: 0.8411, Speed: 112.5k, Time: 85.6841
Epoch: 120, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/173.97, Loss: 0.4130, Acc: 0.8410, Speed: 112.4k, Time: 97.9819
Epoch: 120, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/207.87, Loss: 0.4129, Acc: 0.8411, Speed: 112.6k, Time: 110.2755
Train 0.8410
Val 0.8580
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043

saving model to local_300_parikh
Epoch: 121, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/174.52, Loss: 0.4092, Acc: 0.8424, Speed: 114.0k, Time: 12.2995
Epoch: 121, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/174.52, Loss: 0.4118, Acc: 0.8413, Speed: 113.1k, Time: 24.6761
Epoch: 121, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/205.60, Loss: 0.4111, Acc: 0.8414, Speed: 113.5k, Time: 36.7234
Epoch: 121, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/205.60, Loss: 0.4139, Acc: 0.8403, Speed: 113.3k, Time: 49.0376
Epoch: 121, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/205.60, Loss: 0.4131, Acc: 0.8410, Speed: 113.1k, Time: 61.1768
Epoch: 121, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/205.60, Loss: 0.4134, Acc: 0.8409, Speed: 113.4k, Time: 73.0327
Epoch: 121, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/205.60, Loss: 0.4129, Acc: 0.8412, Speed: 113.2k, Time: 85.3230
Epoch: 121, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/205.60, Loss: 0.4133, Acc: 0.8409, Speed: 113.5k, Time: 97.5892
Epoch: 121, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/205.60, Loss: 0.4133, Acc: 0.8409, Speed: 113.1k, Time: 109.8157
Train 0.8411
Val 0.8583
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348

saving model to local_300_parikh
Epoch: 122, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4172, Acc: 0.8398, Speed: 113.1k, Time: 12.2576
Epoch: 122, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4146, Acc: 0.8398, Speed: 113.2k, Time: 24.4236
Epoch: 122, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4149, Acc: 0.8401, Speed: 112.9k, Time: 36.7605
Epoch: 122, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4158, Acc: 0.8400, Speed: 112.7k, Time: 49.0706
Epoch: 122, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4158, Acc: 0.8396, Speed: 112.4k, Time: 61.2987
Epoch: 122, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4155, Acc: 0.8399, Speed: 112.3k, Time: 73.6137
Epoch: 122, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4156, Acc: 0.8398, Speed: 112.6k, Time: 85.4994
Epoch: 122, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4160, Acc: 0.8396, Speed: 112.5k, Time: 97.8602
Epoch: 122, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/194.36, Loss: 0.4158, Acc: 0.8394, Speed: 112.6k, Time: 110.0875
Train 0.8394
Val 0.8561
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112

skip saving model for perf <= 0.8583
Epoch: 123, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/167.49, Loss: 0.4141, Acc: 0.8402, Speed: 118.2k, Time: 11.8922
Epoch: 123, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/173.30, Loss: 0.4110, Acc: 0.8413, Speed: 116.0k, Time: 24.1571
Epoch: 123, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/173.30, Loss: 0.4103, Acc: 0.8415, Speed: 114.1k, Time: 36.3464
Epoch: 123, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/173.30, Loss: 0.4107, Acc: 0.8411, Speed: 113.6k, Time: 48.7000
Epoch: 123, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/173.30, Loss: 0.4118, Acc: 0.8411, Speed: 113.3k, Time: 60.9170
Epoch: 123, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/207.54, Loss: 0.4125, Acc: 0.8407, Speed: 113.0k, Time: 73.2572
Epoch: 123, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/207.54, Loss: 0.4125, Acc: 0.8409, Speed: 113.1k, Time: 85.5264
Epoch: 123, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/207.54, Loss: 0.4127, Acc: 0.8409, Speed: 112.8k, Time: 97.7865
Epoch: 123, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/207.54, Loss: 0.4137, Acc: 0.8404, Speed: 112.7k, Time: 110.1083
Train 0.8402
Val 0.8570
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027

skip saving model for perf <= 0.8583
Epoch: 124, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4080, Acc: 0.8417, Speed: 114.1k, Time: 12.2345
Epoch: 124, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4131, Acc: 0.8397, Speed: 114.5k, Time: 24.1725
Epoch: 124, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4140, Acc: 0.8393, Speed: 113.7k, Time: 36.5416
Epoch: 124, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4149, Acc: 0.8393, Speed: 112.8k, Time: 48.9381
Epoch: 124, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4152, Acc: 0.8393, Speed: 112.5k, Time: 61.1328
Epoch: 124, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4160, Acc: 0.8388, Speed: 112.8k, Time: 73.1816
Epoch: 124, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4162, Acc: 0.8388, Speed: 112.5k, Time: 85.5153
Epoch: 124, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4159, Acc: 0.8390, Speed: 112.5k, Time: 97.8232
Epoch: 124, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/189.35, Loss: 0.4160, Acc: 0.8390, Speed: 112.4k, Time: 110.1064
Train 0.8391
Val 0.8569
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925

skip saving model for perf <= 0.8583
Epoch: 125, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.81, Loss: 0.4138, Acc: 0.8409, Speed: 113.3k, Time: 12.1851
Epoch: 125, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/158.81, Loss: 0.4132, Acc: 0.8417, Speed: 112.1k, Time: 24.4719
Epoch: 125, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/198.17, Loss: 0.4125, Acc: 0.8412, Speed: 111.8k, Time: 36.8851
Epoch: 125, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/198.17, Loss: 0.4130, Acc: 0.8409, Speed: 111.8k, Time: 49.2775
Epoch: 125, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/198.17, Loss: 0.4131, Acc: 0.8409, Speed: 111.5k, Time: 61.6665
Epoch: 125, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/198.17, Loss: 0.4135, Acc: 0.8409, Speed: 111.6k, Time: 74.0247
Epoch: 125, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/198.17, Loss: 0.4143, Acc: 0.8404, Speed: 112.2k, Time: 86.0178
Epoch: 125, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/198.17, Loss: 0.4144, Acc: 0.8403, Speed: 111.9k, Time: 98.2983
Epoch: 125, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/213.24, Loss: 0.4144, Acc: 0.8403, Speed: 112.0k, Time: 110.6376
Train 0.8403
Val 0.8551
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096

skip saving model for perf <= 0.8583
Epoch: 126, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/156.12, Loss: 0.4133, Acc: 0.8393, Speed: 111.0k, Time: 12.2536
Epoch: 126, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.35, Loss: 0.4143, Acc: 0.8388, Speed: 112.3k, Time: 24.6311
Epoch: 126, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/207.91, Loss: 0.4153, Acc: 0.8393, Speed: 112.5k, Time: 36.9584
Epoch: 126, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/207.91, Loss: 0.4151, Acc: 0.8393, Speed: 112.4k, Time: 49.3443
Epoch: 126, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/207.91, Loss: 0.4148, Acc: 0.8395, Speed: 111.9k, Time: 61.7024
Epoch: 126, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.63, Loss: 0.4140, Acc: 0.8399, Speed: 111.7k, Time: 74.0167
Epoch: 126, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.63, Loss: 0.4143, Acc: 0.8400, Speed: 111.7k, Time: 86.3620
Epoch: 126, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.63, Loss: 0.4144, Acc: 0.8401, Speed: 111.8k, Time: 98.6473
Epoch: 126, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.63, Loss: 0.4145, Acc: 0.8401, Speed: 111.8k, Time: 111.0697
Train 0.8402
Val 0.8566
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620

skip saving model for perf <= 0.8583
Epoch: 127, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/180.62, Loss: 0.4124, Acc: 0.8417, Speed: 110.8k, Time: 12.1526
Epoch: 127, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/180.62, Loss: 0.4116, Acc: 0.8415, Speed: 110.5k, Time: 24.2863
Epoch: 127, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/180.62, Loss: 0.4110, Acc: 0.8413, Speed: 110.6k, Time: 36.4842
Epoch: 127, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.73, Loss: 0.4103, Acc: 0.8419, Speed: 110.9k, Time: 48.8056
Epoch: 127, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.73, Loss: 0.4106, Acc: 0.8417, Speed: 112.1k, Time: 60.8205
Epoch: 127, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.73, Loss: 0.4110, Acc: 0.8413, Speed: 111.9k, Time: 73.2248
Epoch: 127, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/200.73, Loss: 0.4115, Acc: 0.8412, Speed: 112.1k, Time: 85.5820
Epoch: 127, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/212.68, Loss: 0.4125, Acc: 0.8408, Speed: 112.2k, Time: 98.0080
Epoch: 127, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/212.68, Loss: 0.4130, Acc: 0.8408, Speed: 112.2k, Time: 110.3484
Train 0.8406
Val 0.8550
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994

skip saving model for perf <= 0.8583
Epoch: 128, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/165.47, Loss: 0.4060, Acc: 0.8442, Speed: 111.7k, Time: 12.3389
Epoch: 128, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4124, Acc: 0.8415, Speed: 112.3k, Time: 24.6169
Epoch: 128, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4114, Acc: 0.8418, Speed: 111.7k, Time: 36.8950
Epoch: 128, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/179.69, Loss: 0.4127, Acc: 0.8414, Speed: 112.4k, Time: 48.9322
Epoch: 128, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/190.79, Loss: 0.4130, Acc: 0.8410, Speed: 112.6k, Time: 60.9747
Epoch: 128, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/190.79, Loss: 0.4134, Acc: 0.8408, Speed: 113.6k, Time: 72.6250
Epoch: 128, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/190.79, Loss: 0.4134, Acc: 0.8408, Speed: 114.2k, Time: 84.6192
Epoch: 128, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/190.79, Loss: 0.4135, Acc: 0.8407, Speed: 114.4k, Time: 96.5324
Epoch: 128, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/190.79, Loss: 0.4133, Acc: 0.8409, Speed: 114.2k, Time: 108.5704
Train 0.8409
Val 0.8568
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823

skip saving model for perf <= 0.8583
Epoch: 129, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/177.90, Loss: 0.4097, Acc: 0.8424, Speed: 111.8k, Time: 12.3443
Epoch: 129, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/177.90, Loss: 0.4099, Acc: 0.8417, Speed: 110.7k, Time: 24.6913
Epoch: 129, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/197.75, Loss: 0.4114, Acc: 0.8410, Speed: 110.2k, Time: 37.1193
Epoch: 129, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.75, Loss: 0.4122, Acc: 0.8408, Speed: 110.2k, Time: 49.4378
Epoch: 129, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/241.46, Loss: 0.4115, Acc: 0.8410, Speed: 110.3k, Time: 61.8986
Epoch: 129, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/241.46, Loss: 0.4117, Acc: 0.8409, Speed: 110.7k, Time: 74.2514
Epoch: 129, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/241.46, Loss: 0.4112, Acc: 0.8413, Speed: 111.0k, Time: 86.6454
Epoch: 129, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/241.46, Loss: 0.4118, Acc: 0.8410, Speed: 111.3k, Time: 98.9532
Epoch: 129, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/241.46, Loss: 0.4124, Acc: 0.8407, Speed: 111.3k, Time: 111.3151
Train 0.8407
Val 0.8562
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214

skip saving model for perf <= 0.8583
Epoch: 130, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/156.06, Loss: 0.4129, Acc: 0.8409, Speed: 115.5k, Time: 11.9281
Epoch: 130, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.96, Loss: 0.4120, Acc: 0.8418, Speed: 114.4k, Time: 24.2315
Epoch: 130, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.96, Loss: 0.4110, Acc: 0.8420, Speed: 114.0k, Time: 36.5150
Epoch: 130, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.64, Loss: 0.4105, Acc: 0.8423, Speed: 113.4k, Time: 48.7473
Epoch: 130, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.64, Loss: 0.4111, Acc: 0.8422, Speed: 113.6k, Time: 60.8603
Epoch: 130, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.64, Loss: 0.4117, Acc: 0.8419, Speed: 113.1k, Time: 73.2005
Epoch: 130, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/211.26, Loss: 0.4121, Acc: 0.8416, Speed: 112.7k, Time: 85.5345
Epoch: 130, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/211.26, Loss: 0.4128, Acc: 0.8412, Speed: 112.7k, Time: 97.8633
Epoch: 130, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/211.26, Loss: 0.4127, Acc: 0.8413, Speed: 112.4k, Time: 110.2832
Train 0.8411
Val 0.8556
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604

skip saving model for perf <= 0.8583
Epoch: 131, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/165.99, Loss: 0.4066, Acc: 0.8403, Speed: 109.8k, Time: 12.3385
Epoch: 131, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4081, Acc: 0.8415, Speed: 110.1k, Time: 24.5817
Epoch: 131, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4103, Acc: 0.8414, Speed: 110.7k, Time: 36.8186
Epoch: 131, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4116, Acc: 0.8407, Speed: 111.0k, Time: 49.1950
Epoch: 131, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4108, Acc: 0.8412, Speed: 111.0k, Time: 61.6794
Epoch: 131, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4109, Acc: 0.8411, Speed: 111.8k, Time: 73.6460
Epoch: 131, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4107, Acc: 0.8411, Speed: 111.4k, Time: 86.1076
Epoch: 131, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4115, Acc: 0.8407, Speed: 111.6k, Time: 98.4928
Epoch: 131, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/175.56, Loss: 0.4117, Acc: 0.8408, Speed: 112.3k, Time: 110.4960
Train 0.8406
Val 0.8572
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230

skip saving model for perf <= 0.8583
Epoch: 132, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/166.59, Loss: 0.4084, Acc: 0.8428, Speed: 112.0k, Time: 12.2924
Epoch: 132, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/183.33, Loss: 0.4103, Acc: 0.8417, Speed: 112.5k, Time: 24.6426
Epoch: 132, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/187.25, Loss: 0.4097, Acc: 0.8417, Speed: 111.6k, Time: 36.8958
Epoch: 132, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/187.25, Loss: 0.4105, Acc: 0.8417, Speed: 111.7k, Time: 49.2560
Epoch: 132, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/187.25, Loss: 0.4112, Acc: 0.8416, Speed: 111.7k, Time: 61.5408
Epoch: 132, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/187.25, Loss: 0.4112, Acc: 0.8415, Speed: 111.5k, Time: 73.9881
Epoch: 132, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/187.25, Loss: 0.4113, Acc: 0.8414, Speed: 111.5k, Time: 86.3245
Epoch: 132, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/187.25, Loss: 0.4119, Acc: 0.8413, Speed: 111.7k, Time: 98.5674
Epoch: 132, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/187.25, Loss: 0.4117, Acc: 0.8415, Speed: 111.9k, Time: 110.8260
Train 0.8415
Val 0.8550
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994

skip saving model for perf <= 0.8583
Epoch: 133, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4063, Acc: 0.8445, Speed: 110.1k, Time: 12.1863
Epoch: 133, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4094, Acc: 0.8422, Speed: 111.6k, Time: 24.6411
Epoch: 133, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4095, Acc: 0.8423, Speed: 111.5k, Time: 37.0673
Epoch: 133, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4099, Acc: 0.8417, Speed: 113.0k, Time: 48.9138
Epoch: 133, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4110, Acc: 0.8410, Speed: 112.9k, Time: 61.1070
Epoch: 133, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4106, Acc: 0.8413, Speed: 113.0k, Time: 73.2995
Epoch: 133, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4106, Acc: 0.8414, Speed: 112.6k, Time: 85.5437
Epoch: 133, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4108, Acc: 0.8414, Speed: 113.0k, Time: 97.6761
Epoch: 133, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4114, Acc: 0.8412, Speed: 112.8k, Time: 109.9496
Train 0.8413
Val 0.8586
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551

saving model to local_300_parikh
Epoch: 134, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/176.76, Loss: 0.4054, Acc: 0.8435, Speed: 112.4k, Time: 12.1815
Epoch: 134, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/189.61, Loss: 0.4085, Acc: 0.8426, Speed: 111.3k, Time: 24.3792
Epoch: 134, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/219.48, Loss: 0.4100, Acc: 0.8417, Speed: 112.0k, Time: 36.6460
Epoch: 134, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/219.48, Loss: 0.4104, Acc: 0.8416, Speed: 112.4k, Time: 48.7240
Epoch: 134, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/219.48, Loss: 0.4101, Acc: 0.8421, Speed: 113.5k, Time: 60.6060
Epoch: 134, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/219.48, Loss: 0.4099, Acc: 0.8421, Speed: 113.1k, Time: 72.8132
Epoch: 134, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/219.48, Loss: 0.4105, Acc: 0.8419, Speed: 113.4k, Time: 85.0185
Epoch: 134, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/219.48, Loss: 0.4106, Acc: 0.8420, Speed: 113.4k, Time: 97.2514
Epoch: 134, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/219.48, Loss: 0.4109, Acc: 0.8416, Speed: 113.7k, Time: 109.0547
Train 0.8413
Val 0.8551
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096

skip saving model for perf <= 0.8586
Epoch: 135, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/181.93, Loss: 0.4134, Acc: 0.8393, Speed: 113.0k, Time: 12.2758
Epoch: 135, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/181.93, Loss: 0.4135, Acc: 0.8400, Speed: 113.1k, Time: 24.5600
Epoch: 135, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/181.93, Loss: 0.4114, Acc: 0.8408, Speed: 112.9k, Time: 36.8222
Epoch: 135, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/181.93, Loss: 0.4111, Acc: 0.8411, Speed: 112.7k, Time: 49.0780
Epoch: 135, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/181.93, Loss: 0.4110, Acc: 0.8414, Speed: 112.8k, Time: 61.2765
Epoch: 135, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/185.86, Loss: 0.4107, Acc: 0.8416, Speed: 112.3k, Time: 73.4294
Epoch: 135, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/235.26, Loss: 0.4114, Acc: 0.8414, Speed: 112.6k, Time: 85.7379
Epoch: 135, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/235.26, Loss: 0.4116, Acc: 0.8414, Speed: 112.7k, Time: 97.8112
Epoch: 135, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/235.26, Loss: 0.4115, Acc: 0.8415, Speed: 112.7k, Time: 109.9548
Train 0.8413
Val 0.8586
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551

skip saving model for perf <= 0.8586
Epoch: 136, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/155.89, Loss: 0.4113, Acc: 0.8424, Speed: 113.9k, Time: 12.1854
Epoch: 136, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/158.67, Loss: 0.4114, Acc: 0.8422, Speed: 113.0k, Time: 24.4969
Epoch: 136, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/158.67, Loss: 0.4115, Acc: 0.8418, Speed: 112.9k, Time: 36.6986
Epoch: 136, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/163.48, Loss: 0.4092, Acc: 0.8426, Speed: 113.8k, Time: 48.5084
Epoch: 136, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/186.07, Loss: 0.4094, Acc: 0.8423, Speed: 114.0k, Time: 60.6723
Epoch: 136, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/186.07, Loss: 0.4089, Acc: 0.8428, Speed: 113.6k, Time: 72.8707
Epoch: 136, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/186.07, Loss: 0.4090, Acc: 0.8424, Speed: 113.4k, Time: 85.1492
Epoch: 136, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/186.07, Loss: 0.4083, Acc: 0.8428, Speed: 112.9k, Time: 97.4316
Epoch: 136, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/193.92, Loss: 0.4092, Acc: 0.8423, Speed: 113.0k, Time: 109.5918
Train 0.8421
Val 0.8556
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604

skip saving model for perf <= 0.8586
Epoch: 137, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/170.89, Loss: 0.4103, Acc: 0.8429, Speed: 114.9k, Time: 12.2113
Epoch: 137, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/170.89, Loss: 0.4111, Acc: 0.8420, Speed: 113.8k, Time: 24.4320
Epoch: 137, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/243.34, Loss: 0.4107, Acc: 0.8418, Speed: 113.0k, Time: 36.6528
Epoch: 137, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/243.34, Loss: 0.4104, Acc: 0.8420, Speed: 112.7k, Time: 48.8282
Epoch: 137, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/243.34, Loss: 0.4116, Acc: 0.8416, Speed: 113.3k, Time: 60.7143
Epoch: 137, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/243.34, Loss: 0.4113, Acc: 0.8417, Speed: 113.2k, Time: 72.9318
Epoch: 137, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/243.34, Loss: 0.4110, Acc: 0.8415, Speed: 113.1k, Time: 85.2002
Epoch: 137, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/243.34, Loss: 0.4108, Acc: 0.8417, Speed: 113.3k, Time: 97.2694
Epoch: 137, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/243.34, Loss: 0.4106, Acc: 0.8418, Speed: 113.6k, Time: 109.2590
Train 0.8420
Val 0.8569
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925

skip saving model for perf <= 0.8586
Epoch: 138, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.27, Loss: 0.4095, Acc: 0.8427, Speed: 114.0k, Time: 12.2408
Epoch: 138, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/158.27, Loss: 0.4049, Acc: 0.8448, Speed: 112.8k, Time: 24.4874
Epoch: 138, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/196.30, Loss: 0.4068, Acc: 0.8437, Speed: 113.0k, Time: 36.7259
Epoch: 138, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/196.30, Loss: 0.4074, Acc: 0.8434, Speed: 112.8k, Time: 48.9077
Epoch: 138, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/196.30, Loss: 0.4066, Acc: 0.8436, Speed: 112.7k, Time: 61.1025
Epoch: 138, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/224.85, Loss: 0.4075, Acc: 0.8433, Speed: 112.8k, Time: 73.2836
Epoch: 138, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/224.85, Loss: 0.4086, Acc: 0.8427, Speed: 112.9k, Time: 85.5022
Epoch: 138, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/224.85, Loss: 0.4092, Acc: 0.8424, Speed: 112.6k, Time: 97.6923
Epoch: 138, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/224.85, Loss: 0.4089, Acc: 0.8426, Speed: 112.7k, Time: 109.8470
Train 0.8424
Val 0.8566
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620

skip saving model for perf <= 0.8586
Epoch: 139, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/165.69, Loss: 0.4119, Acc: 0.8419, Speed: 113.3k, Time: 12.2790
Epoch: 139, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/194.72, Loss: 0.4126, Acc: 0.8406, Speed: 114.9k, Time: 24.3791
Epoch: 139, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/211.66, Loss: 0.4090, Acc: 0.8413, Speed: 115.2k, Time: 36.5047
Epoch: 139, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/211.66, Loss: 0.4082, Acc: 0.8422, Speed: 114.9k, Time: 48.4196
Epoch: 139, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/211.66, Loss: 0.4078, Acc: 0.8424, Speed: 114.4k, Time: 60.5585
Epoch: 139, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/211.66, Loss: 0.4078, Acc: 0.8426, Speed: 114.0k, Time: 72.7783
Epoch: 139, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/234.46, Loss: 0.4074, Acc: 0.8426, Speed: 113.5k, Time: 84.9781
Epoch: 139, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/234.46, Loss: 0.4074, Acc: 0.8428, Speed: 113.3k, Time: 97.1991
Epoch: 139, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/234.46, Loss: 0.4078, Acc: 0.8424, Speed: 113.5k, Time: 109.3696
Train 0.8422
Val 0.8552
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198

skip saving model for perf <= 0.8586
Epoch: 140, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/190.86, Loss: 0.4061, Acc: 0.8446, Speed: 111.1k, Time: 12.1775
Epoch: 140, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4105, Acc: 0.8421, Speed: 113.2k, Time: 24.3759
Epoch: 140, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4096, Acc: 0.8423, Speed: 113.5k, Time: 36.5329
Epoch: 140, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4097, Acc: 0.8420, Speed: 113.0k, Time: 48.8332
Epoch: 140, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4095, Acc: 0.8421, Speed: 113.5k, Time: 60.7287
Epoch: 140, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4104, Acc: 0.8420, Speed: 113.6k, Time: 72.9102
Epoch: 140, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4106, Acc: 0.8416, Speed: 113.4k, Time: 85.0946
Epoch: 140, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4106, Acc: 0.8416, Speed: 113.6k, Time: 97.0756
Epoch: 140, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/215.60, Loss: 0.4103, Acc: 0.8417, Speed: 113.5k, Time: 109.2904
Train 0.8418
Val 0.8565
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519

skip saving model for perf <= 0.8586
Epoch: 141, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/166.30, Loss: 0.4117, Acc: 0.8428, Speed: 113.1k, Time: 12.3075
Epoch: 141, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/207.13, Loss: 0.4094, Acc: 0.8430, Speed: 112.9k, Time: 24.5741
Epoch: 141, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/207.13, Loss: 0.4096, Acc: 0.8427, Speed: 113.2k, Time: 36.7657
Epoch: 141, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/207.13, Loss: 0.4095, Acc: 0.8423, Speed: 113.0k, Time: 48.9023
Epoch: 141, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/207.13, Loss: 0.4090, Acc: 0.8423, Speed: 112.7k, Time: 61.0765
Epoch: 141, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/207.13, Loss: 0.4090, Acc: 0.8427, Speed: 113.3k, Time: 73.1848
Epoch: 141, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/291.05, Loss: 0.4087, Acc: 0.8427, Speed: 113.2k, Time: 85.2975
Epoch: 141, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/291.05, Loss: 0.4091, Acc: 0.8424, Speed: 113.1k, Time: 97.3907
Epoch: 141, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/291.05, Loss: 0.4108, Acc: 0.8416, Speed: 113.2k, Time: 109.5425
Train 0.8412
Val 0.8550
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994

skip saving model for perf <= 0.8586
Epoch: 142, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/187.23, Loss: 0.4148, Acc: 0.8389, Speed: 109.5k, Time: 12.1248
Epoch: 142, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/241.10, Loss: 0.4166, Acc: 0.8377, Speed: 111.6k, Time: 24.3594
Epoch: 142, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/253.07, Loss: 0.4175, Acc: 0.8379, Speed: 112.5k, Time: 36.3310
Epoch: 142, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/253.07, Loss: 0.4162, Acc: 0.8387, Speed: 112.9k, Time: 48.3319
Epoch: 142, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/253.07, Loss: 0.4158, Acc: 0.8386, Speed: 113.0k, Time: 60.6120
Epoch: 142, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/253.07, Loss: 0.4160, Acc: 0.8389, Speed: 113.1k, Time: 72.7726
Epoch: 142, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/253.07, Loss: 0.4150, Acc: 0.8392, Speed: 113.0k, Time: 84.9016
Epoch: 142, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/253.07, Loss: 0.4145, Acc: 0.8395, Speed: 113.1k, Time: 97.1917
Epoch: 142, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/253.07, Loss: 0.4145, Acc: 0.8395, Speed: 113.5k, Time: 109.3608
Train 0.8397
Val 0.8574
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433

skip saving model for perf <= 0.8586
Epoch: 143, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/157.76, Loss: 0.4094, Acc: 0.8422, Speed: 111.9k, Time: 12.1078
Epoch: 143, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/199.55, Loss: 0.4101, Acc: 0.8417, Speed: 113.0k, Time: 24.2060
Epoch: 143, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/199.55, Loss: 0.4106, Acc: 0.8412, Speed: 113.6k, Time: 36.3725
Epoch: 143, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/258.44, Loss: 0.4102, Acc: 0.8421, Speed: 113.2k, Time: 48.5004
Epoch: 143, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/258.44, Loss: 0.4110, Acc: 0.8418, Speed: 113.9k, Time: 60.2370
Epoch: 143, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/258.44, Loss: 0.4101, Acc: 0.8422, Speed: 113.8k, Time: 72.4580
Epoch: 143, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/276.42, Loss: 0.4109, Acc: 0.8418, Speed: 113.6k, Time: 84.6230
Epoch: 143, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/276.42, Loss: 0.4104, Acc: 0.8420, Speed: 114.0k, Time: 96.3728
Epoch: 143, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/276.42, Loss: 0.4101, Acc: 0.8421, Speed: 114.2k, Time: 108.3932
Train 0.8420
Val 0.8555
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502

skip saving model for perf <= 0.8586
Epoch: 144, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/204.88, Loss: 0.4083, Acc: 0.8423, Speed: 115.0k, Time: 12.1334
Epoch: 144, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/204.88, Loss: 0.4066, Acc: 0.8439, Speed: 113.8k, Time: 24.3488
Epoch: 144, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/204.88, Loss: 0.4101, Acc: 0.8418, Speed: 113.7k, Time: 36.5312
Epoch: 144, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/204.88, Loss: 0.4103, Acc: 0.8415, Speed: 113.0k, Time: 48.7590
Epoch: 144, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/204.88, Loss: 0.4097, Acc: 0.8420, Speed: 112.8k, Time: 60.9850
Epoch: 144, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/204.88, Loss: 0.4105, Acc: 0.8418, Speed: 112.8k, Time: 73.3781
Epoch: 144, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/228.38, Loss: 0.4107, Acc: 0.8417, Speed: 113.0k, Time: 85.4451
Epoch: 144, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/228.38, Loss: 0.4109, Acc: 0.8415, Speed: 112.8k, Time: 97.7059
Epoch: 144, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/228.38, Loss: 0.4108, Acc: 0.8415, Speed: 113.0k, Time: 109.9188
Train 0.8415
Val 0.8572
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230

skip saving model for perf <= 0.8586
Epoch: 145, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/167.66, Loss: 0.4083, Acc: 0.8425, Speed: 113.2k, Time: 12.1941
Epoch: 145, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/167.66, Loss: 0.4103, Acc: 0.8406, Speed: 113.0k, Time: 24.3835
Epoch: 145, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/172.07, Loss: 0.4112, Acc: 0.8411, Speed: 113.9k, Time: 36.4155
Epoch: 145, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/172.07, Loss: 0.4114, Acc: 0.8407, Speed: 114.3k, Time: 48.4662
Epoch: 145, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/172.07, Loss: 0.4109, Acc: 0.8411, Speed: 114.1k, Time: 60.5350
Epoch: 145, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/172.07, Loss: 0.4094, Acc: 0.8415, Speed: 114.0k, Time: 72.7731
Epoch: 145, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/172.07, Loss: 0.4091, Acc: 0.8416, Speed: 114.0k, Time: 84.9173
Epoch: 145, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/176.29, Loss: 0.4089, Acc: 0.8418, Speed: 113.8k, Time: 97.1665
Epoch: 145, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/177.50, Loss: 0.4091, Acc: 0.8416, Speed: 113.6k, Time: 109.3229
Train 0.8415
Val 0.8560
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011

skip saving model for perf <= 0.8586
Epoch: 146, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.11, Loss: 0.4104, Acc: 0.8410, Speed: 113.4k, Time: 11.9716
Epoch: 146, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/197.11, Loss: 0.4065, Acc: 0.8429, Speed: 114.1k, Time: 23.9780
Epoch: 146, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/197.11, Loss: 0.4064, Acc: 0.8431, Speed: 114.2k, Time: 35.9417
Epoch: 146, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.11, Loss: 0.4076, Acc: 0.8430, Speed: 115.0k, Time: 47.8461
Epoch: 146, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/197.11, Loss: 0.4072, Acc: 0.8430, Speed: 115.7k, Time: 59.4249
Epoch: 146, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.11, Loss: 0.4078, Acc: 0.8427, Speed: 115.9k, Time: 71.2489
Epoch: 146, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/200.75, Loss: 0.4083, Acc: 0.8426, Speed: 115.7k, Time: 83.2365
Epoch: 146, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/200.75, Loss: 0.4086, Acc: 0.8425, Speed: 115.7k, Time: 95.1144
Epoch: 146, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/200.75, Loss: 0.4090, Acc: 0.8422, Speed: 116.0k, Time: 106.8937
Train 0.8421
Val 0.8555
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502

skip saving model for perf <= 0.8586
Epoch: 147, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/172.96, Loss: 0.4129, Acc: 0.8398, Speed: 112.1k, Time: 12.1576
Epoch: 147, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/188.75, Loss: 0.4093, Acc: 0.8419, Speed: 113.1k, Time: 24.3567
Epoch: 147, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/188.75, Loss: 0.4094, Acc: 0.8421, Speed: 112.4k, Time: 36.5042
Epoch: 147, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/188.75, Loss: 0.4088, Acc: 0.8419, Speed: 112.5k, Time: 48.6374
Epoch: 147, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/188.75, Loss: 0.4081, Acc: 0.8424, Speed: 112.5k, Time: 60.8762
Epoch: 147, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/188.75, Loss: 0.4084, Acc: 0.8424, Speed: 113.0k, Time: 73.0044
Epoch: 147, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/188.75, Loss: 0.4086, Acc: 0.8424, Speed: 113.2k, Time: 85.1689
Epoch: 147, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/190.01, Loss: 0.4088, Acc: 0.8422, Speed: 113.4k, Time: 97.3907
Epoch: 147, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/190.01, Loss: 0.4082, Acc: 0.8427, Speed: 113.3k, Time: 109.5557
Train 0.8426
Val 0.8538
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775

skip saving model for perf <= 0.8586
Epoch: 148, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/178.53, Loss: 0.4081, Acc: 0.8431, Speed: 116.1k, Time: 11.9351
Epoch: 148, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4081, Acc: 0.8428, Speed: 114.4k, Time: 24.1284
Epoch: 148, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4079, Acc: 0.8431, Speed: 114.4k, Time: 36.2415
Epoch: 148, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4090, Acc: 0.8425, Speed: 115.5k, Time: 48.0627
Epoch: 148, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4091, Acc: 0.8422, Speed: 115.0k, Time: 60.1457
Epoch: 148, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4088, Acc: 0.8425, Speed: 115.0k, Time: 72.2823
Epoch: 148, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4088, Acc: 0.8423, Speed: 114.5k, Time: 84.4720
Epoch: 148, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4091, Acc: 0.8422, Speed: 114.1k, Time: 96.6602
Epoch: 148, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/194.44, Loss: 0.4095, Acc: 0.8421, Speed: 114.1k, Time: 108.7259
Train 0.8421
Val 0.8565
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519

skip saving model for perf <= 0.8586
Epoch: 149, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/170.91, Loss: 0.4049, Acc: 0.8437, Speed: 113.2k, Time: 12.1086
Epoch: 149, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/175.11, Loss: 0.4061, Acc: 0.8435, Speed: 113.6k, Time: 24.2573
Epoch: 149, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/189.47, Loss: 0.4055, Acc: 0.8437, Speed: 113.0k, Time: 36.5062
Epoch: 149, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/189.47, Loss: 0.4062, Acc: 0.8438, Speed: 112.7k, Time: 48.6766
Epoch: 149, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.90, Loss: 0.4061, Acc: 0.8435, Speed: 113.2k, Time: 60.6505
Epoch: 149, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/194.90, Loss: 0.4069, Acc: 0.8433, Speed: 113.6k, Time: 72.6526
Epoch: 149, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.90, Loss: 0.4069, Acc: 0.8434, Speed: 113.8k, Time: 84.8140
Epoch: 149, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/194.90, Loss: 0.4069, Acc: 0.8433, Speed: 113.6k, Time: 97.0519
Epoch: 149, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/194.90, Loss: 0.4068, Acc: 0.8431, Speed: 113.8k, Time: 108.8452
Train 0.8427
Val 0.8567
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722

skip saving model for perf <= 0.8586
Epoch: 150, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/169.57, Loss: 0.4075, Acc: 0.8423, Speed: 112.8k, Time: 12.0836
Epoch: 150, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4048, Acc: 0.8433, Speed: 112.3k, Time: 24.2790
Epoch: 150, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4075, Acc: 0.8429, Speed: 111.8k, Time: 36.5156
Epoch: 150, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4071, Acc: 0.8431, Speed: 112.5k, Time: 48.6468
Epoch: 150, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4071, Acc: 0.8431, Speed: 112.8k, Time: 60.8210
Epoch: 150, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4074, Acc: 0.8427, Speed: 113.2k, Time: 72.9448
Epoch: 150, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4080, Acc: 0.8424, Speed: 113.4k, Time: 85.0949
Epoch: 150, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4077, Acc: 0.8428, Speed: 113.5k, Time: 97.1688
Epoch: 150, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/293.95, Loss: 0.4092, Acc: 0.8421, Speed: 113.4k, Time: 109.3721
Train 0.8421
Val 0.8575
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535

skip saving model for perf <= 0.8586
Epoch: 151, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/154.98, Loss: 0.4078, Acc: 0.8442, Speed: 118.1k, Time: 11.6367
Epoch: 151, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/172.18, Loss: 0.4058, Acc: 0.8446, Speed: 116.1k, Time: 23.6680
Epoch: 151, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/194.40, Loss: 0.4066, Acc: 0.8440, Speed: 115.0k, Time: 35.6315
Epoch: 151, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.40, Loss: 0.4059, Acc: 0.8441, Speed: 116.0k, Time: 47.3408
Epoch: 151, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.71, Loss: 0.4059, Acc: 0.8440, Speed: 115.6k, Time: 59.4960
Epoch: 151, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.75, Loss: 0.4067, Acc: 0.8435, Speed: 115.5k, Time: 71.6164
Epoch: 151, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/197.75, Loss: 0.4073, Acc: 0.8429, Speed: 115.4k, Time: 83.6996
Epoch: 151, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/197.75, Loss: 0.4075, Acc: 0.8428, Speed: 115.2k, Time: 95.8942
Epoch: 151, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/197.75, Loss: 0.4077, Acc: 0.8427, Speed: 114.9k, Time: 107.9736
Train 0.8427
Val 0.8575
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535

skip saving model for perf <= 0.8586
Epoch: 152, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/151.79, Loss: 0.4027, Acc: 0.8448, Speed: 110.9k, Time: 12.1080
Epoch: 152, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/176.47, Loss: 0.4043, Acc: 0.8447, Speed: 112.9k, Time: 24.1687
Epoch: 152, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/176.47, Loss: 0.4045, Acc: 0.8444, Speed: 113.4k, Time: 36.3329
Epoch: 152, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/184.26, Loss: 0.4070, Acc: 0.8428, Speed: 113.6k, Time: 48.4632
Epoch: 152, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/184.26, Loss: 0.4069, Acc: 0.8428, Speed: 113.7k, Time: 60.6445
Epoch: 152, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/184.26, Loss: 0.4061, Acc: 0.8434, Speed: 113.9k, Time: 72.3746
Epoch: 152, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/184.26, Loss: 0.4062, Acc: 0.8434, Speed: 113.8k, Time: 84.4790
Epoch: 152, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/184.26, Loss: 0.4057, Acc: 0.8439, Speed: 113.9k, Time: 96.5922
Epoch: 152, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/184.26, Loss: 0.4064, Acc: 0.8435, Speed: 114.4k, Time: 108.3973
Train 0.8433
Val 0.8567
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722

skip saving model for perf <= 0.8586
Epoch: 153, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/180.58, Loss: 0.4017, Acc: 0.8459, Speed: 117.6k, Time: 12.1212
Epoch: 153, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/201.34, Loss: 0.4034, Acc: 0.8446, Speed: 114.7k, Time: 24.2579
Epoch: 153, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/268.09, Loss: 0.4042, Acc: 0.8442, Speed: 114.1k, Time: 36.3969
Epoch: 153, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/268.09, Loss: 0.4029, Acc: 0.8447, Speed: 114.6k, Time: 48.4680
Epoch: 153, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/268.09, Loss: 0.4034, Acc: 0.8446, Speed: 113.8k, Time: 60.6712
Epoch: 153, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/268.09, Loss: 0.4040, Acc: 0.8444, Speed: 113.9k, Time: 72.8407
Epoch: 153, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/268.09, Loss: 0.4049, Acc: 0.8441, Speed: 113.6k, Time: 84.9897
Epoch: 153, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/268.09, Loss: 0.4057, Acc: 0.8437, Speed: 113.7k, Time: 97.1073
Epoch: 153, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/268.09, Loss: 0.4059, Acc: 0.8436, Speed: 113.6k, Time: 109.1708
Train 0.8436
Val 0.8559
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909

skip saving model for perf <= 0.8586
Epoch: 154, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/167.81, Loss: 0.4071, Acc: 0.8432, Speed: 116.4k, Time: 11.6925
Epoch: 154, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.54, Loss: 0.4061, Acc: 0.8430, Speed: 114.6k, Time: 23.7977
Epoch: 154, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/183.02, Loss: 0.4066, Acc: 0.8428, Speed: 114.2k, Time: 35.8859
Epoch: 154, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.24, Loss: 0.4067, Acc: 0.8431, Speed: 115.4k, Time: 47.6261
Epoch: 154, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/197.24, Loss: 0.4072, Acc: 0.8431, Speed: 115.1k, Time: 59.7113
Epoch: 154, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.24, Loss: 0.4075, Acc: 0.8431, Speed: 114.8k, Time: 71.8996
Epoch: 154, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/197.24, Loss: 0.4067, Acc: 0.8436, Speed: 114.7k, Time: 84.0218
Epoch: 154, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/197.24, Loss: 0.4072, Acc: 0.8435, Speed: 114.5k, Time: 96.1722
Epoch: 154, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/201.01, Loss: 0.4069, Acc: 0.8436, Speed: 114.4k, Time: 108.2091
Train 0.8436
Val 0.8570
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027

skip saving model for perf <= 0.8586
Epoch: 155, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/175.93, Loss: 0.4086, Acc: 0.8417, Speed: 113.8k, Time: 12.1477
Epoch: 155, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/175.93, Loss: 0.4048, Acc: 0.8436, Speed: 114.1k, Time: 24.2975
Epoch: 155, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/196.92, Loss: 0.4031, Acc: 0.8440, Speed: 112.7k, Time: 36.4794
Epoch: 155, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/196.92, Loss: 0.4045, Acc: 0.8438, Speed: 113.3k, Time: 48.6144
Epoch: 155, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/196.92, Loss: 0.4048, Acc: 0.8435, Speed: 113.5k, Time: 60.7517
Epoch: 155, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/196.92, Loss: 0.4048, Acc: 0.8434, Speed: 114.0k, Time: 72.4990
Epoch: 155, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/196.92, Loss: 0.4050, Acc: 0.8434, Speed: 113.9k, Time: 84.7443
Epoch: 155, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/232.97, Loss: 0.4052, Acc: 0.8434, Speed: 113.7k, Time: 96.9028
Epoch: 155, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/232.97, Loss: 0.4057, Acc: 0.8432, Speed: 114.2k, Time: 108.5963
Train 0.8433
Val 0.8568
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823

skip saving model for perf <= 0.8586
Epoch: 156, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/189.34, Loss: 0.4027, Acc: 0.8445, Speed: 112.4k, Time: 12.0990
Epoch: 156, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/189.34, Loss: 0.4045, Acc: 0.8443, Speed: 114.0k, Time: 24.2913
Epoch: 156, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/189.34, Loss: 0.4040, Acc: 0.8438, Speed: 114.1k, Time: 36.4964
Epoch: 156, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/201.62, Loss: 0.4045, Acc: 0.8437, Speed: 114.0k, Time: 48.6458
Epoch: 156, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/201.62, Loss: 0.4047, Acc: 0.8434, Speed: 113.8k, Time: 60.7770
Epoch: 156, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/202.90, Loss: 0.4054, Acc: 0.8430, Speed: 114.1k, Time: 72.9311
Epoch: 156, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/202.90, Loss: 0.4062, Acc: 0.8430, Speed: 113.7k, Time: 85.0514
Epoch: 156, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/202.90, Loss: 0.4064, Acc: 0.8428, Speed: 113.7k, Time: 97.0744
Epoch: 156, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/202.90, Loss: 0.4058, Acc: 0.8431, Speed: 113.6k, Time: 109.1787
Train 0.8434
Val 0.8568
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823

skip saving model for perf <= 0.8586
Epoch: 157, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/181.30, Loss: 0.4040, Acc: 0.8444, Speed: 118.2k, Time: 11.7427
Epoch: 157, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/181.30, Loss: 0.4031, Acc: 0.8445, Speed: 114.5k, Time: 23.9581
Epoch: 157, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/210.29, Loss: 0.4054, Acc: 0.8434, Speed: 114.9k, Time: 36.0996
Epoch: 157, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/210.29, Loss: 0.4054, Acc: 0.8432, Speed: 115.5k, Time: 47.8201
Epoch: 157, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/210.29, Loss: 0.4047, Acc: 0.8436, Speed: 115.1k, Time: 59.9347
Epoch: 157, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/210.29, Loss: 0.4044, Acc: 0.8439, Speed: 115.0k, Time: 71.9923
Epoch: 157, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/210.29, Loss: 0.4044, Acc: 0.8440, Speed: 114.4k, Time: 84.1865
Epoch: 157, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/210.29, Loss: 0.4037, Acc: 0.8442, Speed: 114.3k, Time: 96.3626
Epoch: 157, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/210.29, Loss: 0.4041, Acc: 0.8441, Speed: 114.1k, Time: 108.5247
Train 0.8439
Val 0.8571
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128

skip saving model for perf <= 0.8586
Epoch: 158, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4075, Acc: 0.8419, Speed: 111.8k, Time: 12.2508
Epoch: 158, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4075, Acc: 0.8424, Speed: 112.4k, Time: 24.3255
Epoch: 158, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4075, Acc: 0.8422, Speed: 112.3k, Time: 36.5564
Epoch: 158, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4072, Acc: 0.8425, Speed: 112.8k, Time: 48.7009
Epoch: 158, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4059, Acc: 0.8431, Speed: 113.4k, Time: 60.7730
Epoch: 158, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4061, Acc: 0.8434, Speed: 114.1k, Time: 72.4797
Epoch: 158, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4063, Acc: 0.8432, Speed: 113.9k, Time: 84.5842
Epoch: 158, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4061, Acc: 0.8433, Speed: 114.0k, Time: 96.6883
Epoch: 158, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/278.76, Loss: 0.4057, Acc: 0.8435, Speed: 114.4k, Time: 108.3881
Train 0.8438
Val 0.8568
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823

skip saving model for perf <= 0.8586
Epoch: 159, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/173.63, Loss: 0.4054, Acc: 0.8432, Speed: 113.9k, Time: 12.1768
Epoch: 159, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/173.63, Loss: 0.4035, Acc: 0.8449, Speed: 113.0k, Time: 24.3271
Epoch: 159, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.57, Loss: 0.4036, Acc: 0.8450, Speed: 113.0k, Time: 36.4338
Epoch: 159, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4047, Acc: 0.8447, Speed: 112.9k, Time: 48.5810
Epoch: 159, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4055, Acc: 0.8442, Speed: 113.3k, Time: 60.6140
Epoch: 159, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4057, Acc: 0.8438, Speed: 113.8k, Time: 72.7617
Epoch: 159, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4053, Acc: 0.8440, Speed: 113.8k, Time: 84.8170
Epoch: 159, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4050, Acc: 0.8441, Speed: 114.1k, Time: 96.9880
Epoch: 159, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/180.90, Loss: 0.4050, Acc: 0.8440, Speed: 113.6k, Time: 109.1201
Train 0.8440
Val 0.8572
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230

skip saving model for perf <= 0.8586
Epoch: 160, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/165.27, Loss: 0.3992, Acc: 0.8471, Speed: 115.8k, Time: 11.6978
Epoch: 160, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/183.96, Loss: 0.4013, Acc: 0.8460, Speed: 115.0k, Time: 23.7091
Epoch: 160, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/183.96, Loss: 0.4013, Acc: 0.8460, Speed: 114.6k, Time: 36.0183
Epoch: 160, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.46, Loss: 0.4031, Acc: 0.8449, Speed: 114.5k, Time: 48.0775
Epoch: 160, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/233.58, Loss: 0.4032, Acc: 0.8451, Speed: 114.4k, Time: 60.0323
Epoch: 160, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/233.58, Loss: 0.4037, Acc: 0.8450, Speed: 114.4k, Time: 72.1678
Epoch: 160, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/233.58, Loss: 0.4036, Acc: 0.8450, Speed: 114.1k, Time: 84.3786
Epoch: 160, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/233.58, Loss: 0.4033, Acc: 0.8451, Speed: 113.9k, Time: 96.4869
Epoch: 160, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/233.58, Loss: 0.4033, Acc: 0.8450, Speed: 114.0k, Time: 108.5702
Train 0.8449
Val 0.8574
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433

skip saving model for perf <= 0.8586
Epoch: 161, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/164.62, Loss: 0.4012, Acc: 0.8452, Speed: 112.3k, Time: 12.1274
Epoch: 161, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/209.44, Loss: 0.4034, Acc: 0.8441, Speed: 113.5k, Time: 24.2529
Epoch: 161, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/209.44, Loss: 0.4042, Acc: 0.8437, Speed: 113.9k, Time: 36.3822
Epoch: 161, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/209.44, Loss: 0.4014, Acc: 0.8449, Speed: 113.7k, Time: 48.4512
Epoch: 161, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/209.44, Loss: 0.4018, Acc: 0.8445, Speed: 113.9k, Time: 60.4780
Epoch: 161, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/209.44, Loss: 0.4028, Acc: 0.8443, Speed: 114.1k, Time: 72.4988
Epoch: 161, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/209.44, Loss: 0.4026, Acc: 0.8445, Speed: 114.1k, Time: 84.5136
Epoch: 161, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/209.44, Loss: 0.4028, Acc: 0.8445, Speed: 114.1k, Time: 96.5875
Epoch: 161, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.49, Loss: 0.4028, Acc: 0.8446, Speed: 114.2k, Time: 108.5802
Train 0.8446
Val 0.8569
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925

skip saving model for perf <= 0.8586
Epoch: 162, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/166.09, Loss: 0.4052, Acc: 0.8426, Speed: 115.6k, Time: 12.1592
Epoch: 162, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/175.54, Loss: 0.4016, Acc: 0.8443, Speed: 114.8k, Time: 24.3269
Epoch: 162, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/175.55, Loss: 0.4008, Acc: 0.8450, Speed: 114.0k, Time: 36.4003
Epoch: 162, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/209.00, Loss: 0.4025, Acc: 0.8443, Speed: 113.7k, Time: 48.5507
Epoch: 162, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/209.00, Loss: 0.4020, Acc: 0.8446, Speed: 114.0k, Time: 60.5680
Epoch: 162, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/209.00, Loss: 0.4026, Acc: 0.8443, Speed: 113.7k, Time: 72.7532
Epoch: 162, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/209.00, Loss: 0.4024, Acc: 0.8449, Speed: 113.7k, Time: 84.8339
Epoch: 162, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/209.00, Loss: 0.4023, Acc: 0.8448, Speed: 113.7k, Time: 97.0549
Epoch: 162, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/209.00, Loss: 0.4028, Acc: 0.8445, Speed: 113.7k, Time: 109.1571
Train 0.8443
Val 0.8572
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230

skip saving model for perf <= 0.8586
Epoch: 163, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/220.32, Loss: 0.4029, Acc: 0.8449, Speed: 111.3k, Time: 12.1239
Epoch: 163, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4007, Acc: 0.8464, Speed: 114.5k, Time: 23.9236
Epoch: 163, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4007, Acc: 0.8462, Speed: 115.0k, Time: 36.1156
Epoch: 163, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4004, Acc: 0.8464, Speed: 114.3k, Time: 48.2731
Epoch: 163, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4019, Acc: 0.8457, Speed: 114.8k, Time: 60.0177
Epoch: 163, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4027, Acc: 0.8449, Speed: 114.8k, Time: 72.1366
Epoch: 163, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4026, Acc: 0.8450, Speed: 114.6k, Time: 84.1792
Epoch: 163, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4023, Acc: 0.8453, Speed: 114.5k, Time: 96.2733
Epoch: 163, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/224.22, Loss: 0.4025, Acc: 0.8453, Speed: 114.3k, Time: 108.4092
Train 0.8454
Val 0.8553
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299

skip saving model for perf <= 0.8586
Epoch: 164, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/171.31, Loss: 0.4003, Acc: 0.8448, Speed: 112.9k, Time: 12.1552
Epoch: 164, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/193.92, Loss: 0.4040, Acc: 0.8439, Speed: 113.9k, Time: 24.3324
Epoch: 164, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/208.88, Loss: 0.4047, Acc: 0.8436, Speed: 113.6k, Time: 36.4187
Epoch: 164, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/294.65, Loss: 0.4055, Acc: 0.8438, Speed: 113.7k, Time: 48.5841
Epoch: 164, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/294.65, Loss: 0.4055, Acc: 0.8440, Speed: 113.5k, Time: 60.7499
Epoch: 164, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/294.65, Loss: 0.4054, Acc: 0.8441, Speed: 113.7k, Time: 72.9027
Epoch: 164, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/294.65, Loss: 0.4042, Acc: 0.8448, Speed: 114.0k, Time: 84.7613
Epoch: 164, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/294.65, Loss: 0.4035, Acc: 0.8448, Speed: 114.0k, Time: 96.8165
Epoch: 164, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/294.65, Loss: 0.4031, Acc: 0.8449, Speed: 114.1k, Time: 108.8450
Train 0.8450
Val 0.8579
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941

skip saving model for perf <= 0.8586
Epoch: 165, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/204.99, Loss: 0.4030, Acc: 0.8434, Speed: 112.1k, Time: 12.1889
Epoch: 165, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4030, Acc: 0.8445, Speed: 112.4k, Time: 24.3896
Epoch: 165, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4019, Acc: 0.8452, Speed: 113.0k, Time: 36.5170
Epoch: 165, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4014, Acc: 0.8449, Speed: 113.0k, Time: 48.6279
Epoch: 165, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4018, Acc: 0.8448, Speed: 113.1k, Time: 60.8136
Epoch: 165, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4022, Acc: 0.8445, Speed: 113.3k, Time: 72.9410
Epoch: 165, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4025, Acc: 0.8446, Speed: 113.0k, Time: 85.0828
Epoch: 165, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4024, Acc: 0.8448, Speed: 113.1k, Time: 97.2289
Epoch: 165, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/220.58, Loss: 0.4027, Acc: 0.8448, Speed: 113.3k, Time: 109.3583
Train 0.8448
Val 0.8566
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620

skip saving model for perf <= 0.8586
Epoch: 166, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/215.67, Loss: 0.4066, Acc: 0.8431, Speed: 110.9k, Time: 12.2007
Epoch: 166, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/215.67, Loss: 0.4056, Acc: 0.8439, Speed: 113.8k, Time: 23.9524
Epoch: 166, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/215.67, Loss: 0.4061, Acc: 0.8438, Speed: 113.4k, Time: 36.1245
Epoch: 166, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/215.67, Loss: 0.4054, Acc: 0.8442, Speed: 113.5k, Time: 48.3179
Epoch: 166, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/215.67, Loss: 0.4049, Acc: 0.8443, Speed: 114.1k, Time: 60.0285
Epoch: 166, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/215.67, Loss: 0.4048, Acc: 0.8443, Speed: 113.8k, Time: 72.1878
Epoch: 166, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/215.67, Loss: 0.4051, Acc: 0.8441, Speed: 113.8k, Time: 84.4097
Epoch: 166, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/217.65, Loss: 0.4054, Acc: 0.8439, Speed: 113.6k, Time: 96.6007
Epoch: 166, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/217.65, Loss: 0.4055, Acc: 0.8438, Speed: 113.8k, Time: 108.8865
Train 0.8437
Val 0.8567
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722

skip saving model for perf <= 0.8586
Epoch: 167, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4004, Acc: 0.8452, Speed: 110.9k, Time: 12.2122
Epoch: 167, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4006, Acc: 0.8452, Speed: 111.8k, Time: 24.4448
Epoch: 167, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4019, Acc: 0.8449, Speed: 112.5k, Time: 36.6718
Epoch: 167, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4030, Acc: 0.8444, Speed: 113.0k, Time: 48.8832
Epoch: 167, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4036, Acc: 0.8442, Speed: 113.0k, Time: 61.0993
Epoch: 167, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4036, Acc: 0.8442, Speed: 113.3k, Time: 73.2256
Epoch: 167, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4031, Acc: 0.8444, Speed: 113.5k, Time: 85.0654
Epoch: 167, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4032, Acc: 0.8444, Speed: 113.4k, Time: 97.1942
Epoch: 167, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/225.47, Loss: 0.4031, Acc: 0.8445, Speed: 113.3k, Time: 109.4090
Train 0.8444
Val 0.8578
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840

skip saving model for perf <= 0.8586
Epoch: 168, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4022, Acc: 0.8441, Speed: 112.4k, Time: 12.1441
Epoch: 168, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4032, Acc: 0.8440, Speed: 113.0k, Time: 24.2873
Epoch: 168, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4017, Acc: 0.8451, Speed: 112.1k, Time: 36.5409
Epoch: 168, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4029, Acc: 0.8449, Speed: 112.4k, Time: 48.7528
Epoch: 168, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4028, Acc: 0.8448, Speed: 112.2k, Time: 60.9802
Epoch: 168, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4033, Acc: 0.8445, Speed: 112.4k, Time: 73.2399
Epoch: 168, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4034, Acc: 0.8444, Speed: 112.6k, Time: 85.4771
Epoch: 168, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4033, Acc: 0.8444, Speed: 112.7k, Time: 97.6318
Epoch: 168, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/205.81, Loss: 0.4031, Acc: 0.8445, Speed: 112.7k, Time: 109.8393
Train 0.8443
Val 0.8587
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653

saving model to local_300_parikh
Epoch: 169, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/175.27, Loss: 0.3976, Acc: 0.8462, Speed: 112.5k, Time: 12.1819
Epoch: 169, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/210.60, Loss: 0.3982, Acc: 0.8457, Speed: 115.6k, Time: 24.0170
Epoch: 169, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/210.60, Loss: 0.4006, Acc: 0.8448, Speed: 114.9k, Time: 36.1659
Epoch: 169, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/210.60, Loss: 0.4012, Acc: 0.8450, Speed: 113.8k, Time: 48.4831
Epoch: 169, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/238.21, Loss: 0.4019, Acc: 0.8448, Speed: 114.4k, Time: 60.2240
Epoch: 169, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/238.21, Loss: 0.4019, Acc: 0.8447, Speed: 113.9k, Time: 72.4593
Epoch: 169, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/238.21, Loss: 0.4019, Acc: 0.8447, Speed: 113.9k, Time: 84.6387
Epoch: 169, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/238.21, Loss: 0.4026, Acc: 0.8443, Speed: 113.6k, Time: 96.7920
Epoch: 169, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/238.21, Loss: 0.4033, Acc: 0.8441, Speed: 113.5k, Time: 109.0917
Train 0.8441
Val 0.8575
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535

skip saving model for perf <= 0.8587
Epoch: 170, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.3986, Acc: 0.8469, Speed: 113.2k, Time: 12.3045
Epoch: 170, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.3987, Acc: 0.8469, Speed: 113.0k, Time: 24.5722
Epoch: 170, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.4008, Acc: 0.8453, Speed: 112.3k, Time: 36.7667
Epoch: 170, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.4000, Acc: 0.8458, Speed: 112.3k, Time: 48.9799
Epoch: 170, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.3995, Acc: 0.8459, Speed: 112.0k, Time: 61.2106
Epoch: 170, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.4003, Acc: 0.8457, Speed: 112.1k, Time: 73.3840
Epoch: 170, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.4009, Acc: 0.8453, Speed: 112.7k, Time: 85.1716
Epoch: 170, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.4014, Acc: 0.8450, Speed: 112.9k, Time: 97.3593
Epoch: 170, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.12, Loss: 0.4015, Acc: 0.8451, Speed: 113.0k, Time: 109.6309
Train 0.8454
Val 0.8588
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754

saving model to local_300_parikh
Epoch: 171, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/185.70, Loss: 0.4013, Acc: 0.8465, Speed: 115.5k, Time: 12.1538
Epoch: 171, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/193.73, Loss: 0.3987, Acc: 0.8471, Speed: 114.0k, Time: 24.4311
Epoch: 171, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/193.73, Loss: 0.3995, Acc: 0.8464, Speed: 113.3k, Time: 36.6206
Epoch: 171, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/243.15, Loss: 0.4005, Acc: 0.8459, Speed: 112.7k, Time: 48.8589
Epoch: 171, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/243.15, Loss: 0.4028, Acc: 0.8449, Speed: 113.1k, Time: 61.0538
Epoch: 171, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/243.15, Loss: 0.4032, Acc: 0.8449, Speed: 112.8k, Time: 73.3018
Epoch: 171, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/243.15, Loss: 0.4041, Acc: 0.8446, Speed: 113.2k, Time: 85.3996
Epoch: 171, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/243.15, Loss: 0.4034, Acc: 0.8448, Speed: 112.9k, Time: 97.5501
Epoch: 171, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/243.15, Loss: 0.4043, Acc: 0.8444, Speed: 112.9k, Time: 109.7216
Train 0.8445
Val 0.8578
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840

skip saving model for perf <= 0.8588
Epoch: 172, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/184.60, Loss: 0.4038, Acc: 0.8439, Speed: 115.5k, Time: 12.1809
Epoch: 172, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/184.60, Loss: 0.4034, Acc: 0.8443, Speed: 117.0k, Time: 23.8869
Epoch: 172, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/184.60, Loss: 0.4025, Acc: 0.8449, Speed: 115.6k, Time: 36.0802
Epoch: 172, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/189.49, Loss: 0.4032, Acc: 0.8443, Speed: 115.2k, Time: 48.2934
Epoch: 172, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/189.49, Loss: 0.4017, Acc: 0.8450, Speed: 115.1k, Time: 60.0710
Epoch: 172, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/189.49, Loss: 0.4023, Acc: 0.8448, Speed: 114.7k, Time: 72.2831
Epoch: 172, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/189.49, Loss: 0.4023, Acc: 0.8448, Speed: 114.1k, Time: 84.3792
Epoch: 172, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/189.49, Loss: 0.4024, Acc: 0.8448, Speed: 113.9k, Time: 96.5529
Epoch: 172, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/189.74, Loss: 0.4032, Acc: 0.8444, Speed: 113.9k, Time: 108.7360
Train 0.8443
Val 0.8571
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128

skip saving model for perf <= 0.8588
Epoch: 173, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/203.15, Loss: 0.4023, Acc: 0.8432, Speed: 111.5k, Time: 12.2711
Epoch: 173, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/203.15, Loss: 0.3995, Acc: 0.8447, Speed: 111.2k, Time: 24.3634
Epoch: 173, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/203.15, Loss: 0.4008, Acc: 0.8453, Speed: 112.1k, Time: 36.5261
Epoch: 173, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/203.15, Loss: 0.4011, Acc: 0.8455, Speed: 112.4k, Time: 48.7359
Epoch: 173, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/206.95, Loss: 0.3998, Acc: 0.8459, Speed: 112.7k, Time: 60.8940
Epoch: 173, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/243.01, Loss: 0.4020, Acc: 0.8453, Speed: 113.0k, Time: 73.0445
Epoch: 173, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/270.89, Loss: 0.4022, Acc: 0.8450, Speed: 113.6k, Time: 84.8053
Epoch: 173, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/270.89, Loss: 0.4037, Acc: 0.8444, Speed: 113.6k, Time: 96.9702
Epoch: 173, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/270.89, Loss: 0.4042, Acc: 0.8441, Speed: 113.6k, Time: 109.1839
Train 0.8441
Val 0.8573
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332

skip saving model for perf <= 0.8588
Epoch: 174, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.56, Loss: 0.3994, Acc: 0.8450, Speed: 112.0k, Time: 12.1608
Epoch: 174, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/191.73, Loss: 0.4017, Acc: 0.8445, Speed: 112.5k, Time: 24.3977
Epoch: 174, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/211.68, Loss: 0.4019, Acc: 0.8446, Speed: 112.8k, Time: 36.5375
Epoch: 174, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/211.68, Loss: 0.4020, Acc: 0.8449, Speed: 113.0k, Time: 48.7532
Epoch: 174, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/211.68, Loss: 0.4011, Acc: 0.8450, Speed: 112.8k, Time: 60.8809
Epoch: 174, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/211.68, Loss: 0.4012, Acc: 0.8451, Speed: 112.4k, Time: 73.2144
Epoch: 174, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/211.68, Loss: 0.4017, Acc: 0.8451, Speed: 112.7k, Time: 85.3589
Epoch: 174, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/211.68, Loss: 0.4019, Acc: 0.8451, Speed: 113.0k, Time: 97.5222
Epoch: 174, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/211.68, Loss: 0.4025, Acc: 0.8449, Speed: 113.0k, Time: 109.6551
Train 0.8451
Val 0.8583
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348

skip saving model for perf <= 0.8588
Epoch: 175, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/167.72, Loss: 0.4018, Acc: 0.8450, Speed: 113.1k, Time: 12.1930
Epoch: 175, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/167.72, Loss: 0.4025, Acc: 0.8444, Speed: 114.2k, Time: 24.0637
Epoch: 175, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/180.15, Loss: 0.4034, Acc: 0.8442, Speed: 114.0k, Time: 36.2301
Epoch: 175, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/180.50, Loss: 0.4045, Acc: 0.8438, Speed: 113.5k, Time: 48.3865
Epoch: 175, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/236.69, Loss: 0.4036, Acc: 0.8444, Speed: 114.1k, Time: 60.2107
Epoch: 175, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/236.69, Loss: 0.4030, Acc: 0.8448, Speed: 114.0k, Time: 72.3346
Epoch: 175, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/236.69, Loss: 0.4038, Acc: 0.8447, Speed: 114.4k, Time: 84.4011
Epoch: 175, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/236.69, Loss: 0.4031, Acc: 0.8450, Speed: 114.4k, Time: 96.4763
Epoch: 175, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/236.69, Loss: 0.4031, Acc: 0.8451, Speed: 114.3k, Time: 108.5766
Train 0.8451
Val 0.8579
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941

skip saving model for perf <= 0.8588
Epoch: 176, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/183.72, Loss: 0.4055, Acc: 0.8443, Speed: 112.1k, Time: 12.0951
Epoch: 176, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/183.72, Loss: 0.4012, Acc: 0.8454, Speed: 111.4k, Time: 24.2255
Epoch: 176, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/183.72, Loss: 0.4003, Acc: 0.8455, Speed: 112.2k, Time: 36.3596
Epoch: 176, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/187.34, Loss: 0.4007, Acc: 0.8455, Speed: 112.9k, Time: 48.5053
Epoch: 176, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/187.34, Loss: 0.4013, Acc: 0.8450, Speed: 112.9k, Time: 60.7423
Epoch: 176, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.34, Loss: 0.4013, Acc: 0.8451, Speed: 113.1k, Time: 72.7957
Epoch: 176, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.38, Loss: 0.4011, Acc: 0.8453, Speed: 113.9k, Time: 84.5687
Epoch: 176, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.38, Loss: 0.4015, Acc: 0.8451, Speed: 113.7k, Time: 96.7160
Epoch: 176, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.38, Loss: 0.4020, Acc: 0.8449, Speed: 113.8k, Time: 108.8325
Train 0.8447
Val 0.8588
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754

skip saving model for perf <= 0.8588
Epoch: 177, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/172.37, Loss: 0.4010, Acc: 0.8446, Speed: 114.4k, Time: 12.1181
Epoch: 177, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/191.74, Loss: 0.4017, Acc: 0.8449, Speed: 113.1k, Time: 24.3517
Epoch: 177, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/191.74, Loss: 0.4014, Acc: 0.8452, Speed: 112.7k, Time: 36.4135
Epoch: 177, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/191.74, Loss: 0.4017, Acc: 0.8451, Speed: 112.8k, Time: 48.5561
Epoch: 177, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/212.30, Loss: 0.4009, Acc: 0.8454, Speed: 112.9k, Time: 60.7047
Epoch: 177, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/261.00, Loss: 0.4018, Acc: 0.8450, Speed: 112.9k, Time: 72.8719
Epoch: 177, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/261.00, Loss: 0.4024, Acc: 0.8447, Speed: 113.3k, Time: 84.9909
Epoch: 177, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/261.00, Loss: 0.4026, Acc: 0.8446, Speed: 113.5k, Time: 97.1016
Epoch: 177, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/261.00, Loss: 0.4024, Acc: 0.8446, Speed: 113.4k, Time: 109.2762
Train 0.8446
Val 0.8574
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433

skip saving model for perf <= 0.8588
Epoch: 178, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/161.86, Loss: 0.4044, Acc: 0.8447, Speed: 111.3k, Time: 12.1511
Epoch: 178, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4005, Acc: 0.8461, Speed: 113.5k, Time: 23.8827
Epoch: 178, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.3995, Acc: 0.8463, Speed: 113.5k, Time: 36.1111
Epoch: 178, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4008, Acc: 0.8458, Speed: 113.4k, Time: 48.3098
Epoch: 178, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.92, Loss: 0.4010, Acc: 0.8458, Speed: 114.4k, Time: 60.0902
Epoch: 178, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/213.67, Loss: 0.4010, Acc: 0.8457, Speed: 114.0k, Time: 72.2158
Epoch: 178, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/213.67, Loss: 0.4016, Acc: 0.8457, Speed: 114.0k, Time: 84.3680
Epoch: 178, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/213.67, Loss: 0.4018, Acc: 0.8455, Speed: 114.3k, Time: 96.5551
Epoch: 178, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/213.67, Loss: 0.4018, Acc: 0.8455, Speed: 114.0k, Time: 108.7176
Train 0.8454
Val 0.8559
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909

skip saving model for perf <= 0.8588
Epoch: 179, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/167.12, Loss: 0.3962, Acc: 0.8476, Speed: 110.6k, Time: 12.2277
Epoch: 179, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/204.21, Loss: 0.3995, Acc: 0.8463, Speed: 112.0k, Time: 24.3094
Epoch: 179, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/208.25, Loss: 0.4013, Acc: 0.8454, Speed: 112.7k, Time: 36.3863
Epoch: 179, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/208.25, Loss: 0.4010, Acc: 0.8457, Speed: 113.7k, Time: 48.5136
Epoch: 179, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/208.25, Loss: 0.4019, Acc: 0.8451, Speed: 113.8k, Time: 60.6789
Epoch: 179, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/208.25, Loss: 0.4023, Acc: 0.8450, Speed: 113.8k, Time: 72.8163
Epoch: 179, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/208.25, Loss: 0.4017, Acc: 0.8455, Speed: 113.8k, Time: 84.5314
Epoch: 179, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/220.88, Loss: 0.4017, Acc: 0.8454, Speed: 113.9k, Time: 96.6303
Epoch: 179, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/220.88, Loss: 0.4019, Acc: 0.8452, Speed: 114.2k, Time: 108.6864
Train 0.8452
Val 0.8567
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722

skip saving model for perf <= 0.8588
Epoch: 180, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.4009, Acc: 0.8462, Speed: 113.9k, Time: 12.1618
Epoch: 180, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/194.16, Loss: 0.3988, Acc: 0.8468, Speed: 113.4k, Time: 24.1461
Epoch: 180, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/208.41, Loss: 0.3991, Acc: 0.8467, Speed: 114.1k, Time: 36.2315
Epoch: 180, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/208.41, Loss: 0.4007, Acc: 0.8459, Speed: 113.2k, Time: 48.4054
Epoch: 180, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/283.20, Loss: 0.4010, Acc: 0.8458, Speed: 113.5k, Time: 60.5087
Epoch: 180, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/283.20, Loss: 0.4008, Acc: 0.8457, Speed: 113.4k, Time: 72.6421
Epoch: 180, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/283.20, Loss: 0.4011, Acc: 0.8455, Speed: 113.4k, Time: 84.9224
Epoch: 180, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/283.20, Loss: 0.4006, Acc: 0.8457, Speed: 113.8k, Time: 96.8199
Epoch: 180, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/283.20, Loss: 0.4006, Acc: 0.8456, Speed: 114.0k, Time: 108.6820
Train 0.8455
Val 0.8565
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519

skip saving model for perf <= 0.8588
Epoch: 181, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/163.71, Loss: 0.3928, Acc: 0.8483, Speed: 114.8k, Time: 11.8969
Epoch: 181, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/197.20, Loss: 0.3978, Acc: 0.8469, Speed: 116.7k, Time: 23.4977
Epoch: 181, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/197.20, Loss: 0.3995, Acc: 0.8467, Speed: 116.9k, Time: 35.3369
Epoch: 181, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.20, Loss: 0.4001, Acc: 0.8460, Speed: 116.3k, Time: 47.3343
Epoch: 181, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/201.32, Loss: 0.3996, Acc: 0.8464, Speed: 116.3k, Time: 59.0838
Epoch: 181, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/201.32, Loss: 0.4000, Acc: 0.8463, Speed: 116.3k, Time: 71.0675
Epoch: 181, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/201.32, Loss: 0.4004, Acc: 0.8461, Speed: 115.9k, Time: 83.2407
Epoch: 181, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/201.32, Loss: 0.4009, Acc: 0.8458, Speed: 115.6k, Time: 95.3932
Epoch: 181, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/201.32, Loss: 0.4008, Acc: 0.8460, Speed: 115.3k, Time: 107.4902
Train 0.8461
Val 0.8572
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230

skip saving model for perf <= 0.8588
Epoch: 182, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4020, Acc: 0.8458, Speed: 113.8k, Time: 12.1898
Epoch: 182, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4001, Acc: 0.8461, Speed: 113.5k, Time: 24.3812
Epoch: 182, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.3998, Acc: 0.8467, Speed: 112.9k, Time: 36.4755
Epoch: 182, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4000, Acc: 0.8467, Speed: 113.2k, Time: 48.6540
Epoch: 182, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4003, Acc: 0.8459, Speed: 113.3k, Time: 60.7743
Epoch: 182, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4004, Acc: 0.8458, Speed: 113.1k, Time: 72.9886
Epoch: 182, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4005, Acc: 0.8459, Speed: 113.3k, Time: 85.0237
Epoch: 182, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4004, Acc: 0.8460, Speed: 113.8k, Time: 96.9555
Epoch: 182, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/291.97, Loss: 0.4002, Acc: 0.8461, Speed: 113.7k, Time: 109.0783
Train 0.8459
Val 0.8567
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722

skip saving model for perf <= 0.8588
Epoch: 183, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.35, Loss: 0.3967, Acc: 0.8480, Speed: 118.1k, Time: 11.7700
Epoch: 183, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/202.12, Loss: 0.3979, Acc: 0.8475, Speed: 115.9k, Time: 23.9310
Epoch: 183, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/202.12, Loss: 0.3970, Acc: 0.8476, Speed: 115.0k, Time: 36.1011
Epoch: 183, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/202.12, Loss: 0.3970, Acc: 0.8470, Speed: 114.5k, Time: 48.1811
Epoch: 183, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/202.12, Loss: 0.3975, Acc: 0.8466, Speed: 114.5k, Time: 60.3314
Epoch: 183, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/202.12, Loss: 0.3987, Acc: 0.8462, Speed: 114.2k, Time: 72.4695
Epoch: 183, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/359.18, Loss: 0.3996, Acc: 0.8458, Speed: 114.0k, Time: 84.6220
Epoch: 183, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/359.18, Loss: 0.4008, Acc: 0.8453, Speed: 113.9k, Time: 96.8011
Epoch: 183, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/359.18, Loss: 0.4016, Acc: 0.8451, Speed: 113.8k, Time: 108.9926
Train 0.8451
Val 0.8593
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262

saving model to local_300_parikh
Epoch: 184, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/188.16, Loss: 0.4035, Acc: 0.8443, Speed: 115.2k, Time: 12.1050
Epoch: 184, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/245.12, Loss: 0.4029, Acc: 0.8444, Speed: 116.0k, Time: 24.2115
Epoch: 184, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/245.12, Loss: 0.4024, Acc: 0.8442, Speed: 116.5k, Time: 35.9699
Epoch: 184, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/245.12, Loss: 0.4007, Acc: 0.8455, Speed: 115.0k, Time: 48.2354
Epoch: 184, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/245.12, Loss: 0.4003, Acc: 0.8459, Speed: 114.6k, Time: 60.2257
Epoch: 184, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/245.77, Loss: 0.4004, Acc: 0.8460, Speed: 114.9k, Time: 72.1999
Epoch: 184, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/245.77, Loss: 0.4015, Acc: 0.8456, Speed: 114.4k, Time: 84.3810
Epoch: 184, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/245.77, Loss: 0.4008, Acc: 0.8459, Speed: 114.3k, Time: 96.5292
Epoch: 184, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/245.77, Loss: 0.4010, Acc: 0.8458, Speed: 114.4k, Time: 108.6482
Train 0.8457
Val 0.8580
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043

skip saving model for perf <= 0.8593
Epoch: 185, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.77, Loss: 0.3991, Acc: 0.8467, Speed: 114.9k, Time: 12.1897
Epoch: 185, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/177.98, Loss: 0.3979, Acc: 0.8479, Speed: 114.1k, Time: 24.3189
Epoch: 185, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/177.98, Loss: 0.3976, Acc: 0.8474, Speed: 113.1k, Time: 36.5282
Epoch: 185, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/194.21, Loss: 0.4001, Acc: 0.8463, Speed: 113.4k, Time: 48.6178
Epoch: 185, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/194.21, Loss: 0.3989, Acc: 0.8467, Speed: 113.9k, Time: 60.7441
Epoch: 185, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/194.21, Loss: 0.3996, Acc: 0.8461, Speed: 113.7k, Time: 72.7828
Epoch: 185, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/194.21, Loss: 0.3999, Acc: 0.8461, Speed: 113.5k, Time: 84.9769
Epoch: 185, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/206.08, Loss: 0.4000, Acc: 0.8460, Speed: 113.7k, Time: 96.7996
Epoch: 185, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/206.08, Loss: 0.4003, Acc: 0.8459, Speed: 113.9k, Time: 108.8689
Train 0.8459
Val 0.8590
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957

skip saving model for perf <= 0.8593
Epoch: 186, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/185.67, Loss: 0.4033, Acc: 0.8445, Speed: 117.7k, Time: 11.8123
Epoch: 186, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/185.67, Loss: 0.4016, Acc: 0.8454, Speed: 114.9k, Time: 24.0099
Epoch: 186, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/192.06, Loss: 0.4021, Acc: 0.8451, Speed: 115.5k, Time: 36.0922
Epoch: 186, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/193.47, Loss: 0.4021, Acc: 0.8448, Speed: 115.4k, Time: 48.2681
Epoch: 186, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/193.47, Loss: 0.4029, Acc: 0.8443, Speed: 114.9k, Time: 60.3858
Epoch: 186, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.25, Loss: 0.4026, Acc: 0.8443, Speed: 114.2k, Time: 72.5595
Epoch: 186, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/204.68, Loss: 0.4021, Acc: 0.8447, Speed: 114.3k, Time: 84.6700
Epoch: 186, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/204.68, Loss: 0.4018, Acc: 0.8449, Speed: 113.9k, Time: 96.8492
Epoch: 186, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/204.68, Loss: 0.4015, Acc: 0.8451, Speed: 113.8k, Time: 109.0165
Train 0.8450
Val 0.8587
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653

skip saving model for perf <= 0.8593
Epoch: 187, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/158.91, Loss: 0.3969, Acc: 0.8485, Speed: 113.4k, Time: 12.1699
Epoch: 187, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/183.21, Loss: 0.3966, Acc: 0.8479, Speed: 114.2k, Time: 24.3226
Epoch: 187, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/193.11, Loss: 0.3946, Acc: 0.8493, Speed: 114.6k, Time: 36.0731
Epoch: 187, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/193.11, Loss: 0.3966, Acc: 0.8481, Speed: 114.1k, Time: 48.1498
Epoch: 187, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/193.11, Loss: 0.3980, Acc: 0.8473, Speed: 113.8k, Time: 60.1718
Epoch: 187, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/193.11, Loss: 0.3979, Acc: 0.8474, Speed: 114.1k, Time: 72.0175
Epoch: 187, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/193.11, Loss: 0.3983, Acc: 0.8470, Speed: 114.0k, Time: 84.1745
Epoch: 187, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/193.11, Loss: 0.3983, Acc: 0.8471, Speed: 114.3k, Time: 96.2602
Epoch: 187, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/193.11, Loss: 0.3988, Acc: 0.8468, Speed: 114.0k, Time: 108.4548
Train 0.8464
Val 0.8597
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669

saving model to local_300_parikh
Epoch: 188, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3973, Acc: 0.8460, Speed: 110.7k, Time: 12.1445
Epoch: 188, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3989, Acc: 0.8456, Speed: 112.5k, Time: 24.3249
Epoch: 188, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3988, Acc: 0.8462, Speed: 112.7k, Time: 36.4463
Epoch: 188, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3989, Acc: 0.8463, Speed: 112.2k, Time: 48.5440
Epoch: 188, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3990, Acc: 0.8461, Speed: 112.9k, Time: 60.6283
Epoch: 188, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3995, Acc: 0.8458, Speed: 113.0k, Time: 72.8082
Epoch: 188, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3996, Acc: 0.8459, Speed: 113.3k, Time: 84.8903
Epoch: 188, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3998, Acc: 0.8456, Speed: 113.9k, Time: 96.6861
Epoch: 188, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/428.98, Loss: 0.3990, Acc: 0.8461, Speed: 113.9k, Time: 108.8205
Train 0.8461
Val 0.8564
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417

skip saving model for perf <= 0.8597
Epoch: 189, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.24, Loss: 0.4002, Acc: 0.8448, Speed: 114.8k, Time: 11.7381
Epoch: 189, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/200.24, Loss: 0.3999, Acc: 0.8458, Speed: 113.8k, Time: 23.8575
Epoch: 189, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/209.14, Loss: 0.3987, Acc: 0.8464, Speed: 113.8k, Time: 36.0023
Epoch: 189, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/209.14, Loss: 0.3992, Acc: 0.8463, Speed: 113.8k, Time: 48.1578
Epoch: 189, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/209.14, Loss: 0.3998, Acc: 0.8462, Speed: 113.7k, Time: 60.3596
Epoch: 189, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/209.14, Loss: 0.4001, Acc: 0.8461, Speed: 113.7k, Time: 72.5053
Epoch: 189, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/209.14, Loss: 0.4003, Acc: 0.8463, Speed: 113.6k, Time: 84.6441
Epoch: 189, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/209.14, Loss: 0.4004, Acc: 0.8464, Speed: 113.4k, Time: 96.8695
Epoch: 189, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/209.14, Loss: 0.4006, Acc: 0.8461, Speed: 113.7k, Time: 108.9412
Train 0.8460
Val 0.8573
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332

skip saving model for perf <= 0.8597
Epoch: 190, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3989, Acc: 0.8479, Speed: 113.7k, Time: 12.1327
Epoch: 190, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3994, Acc: 0.8469, Speed: 113.1k, Time: 24.3308
Epoch: 190, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3992, Acc: 0.8469, Speed: 114.5k, Time: 36.0148
Epoch: 190, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3976, Acc: 0.8475, Speed: 113.8k, Time: 48.1935
Epoch: 190, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3979, Acc: 0.8471, Speed: 113.4k, Time: 60.4120
Epoch: 190, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3984, Acc: 0.8467, Speed: 114.3k, Time: 72.2436
Epoch: 190, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3983, Acc: 0.8466, Speed: 114.4k, Time: 84.3383
Epoch: 190, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3981, Acc: 0.8466, Speed: 114.3k, Time: 96.4710
Epoch: 190, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/212.91, Loss: 0.3984, Acc: 0.8466, Speed: 114.2k, Time: 108.5865
Train 0.8465
Val 0.8573
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332

skip saving model for perf <= 0.8597
Epoch: 191, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.4001, Acc: 0.8458, Speed: 113.6k, Time: 12.1638
Epoch: 191, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.3977, Acc: 0.8474, Speed: 112.3k, Time: 24.2150
Epoch: 191, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.3965, Acc: 0.8477, Speed: 113.0k, Time: 36.3393
Epoch: 191, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.3985, Acc: 0.8466, Speed: 114.0k, Time: 48.4642
Epoch: 191, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.3994, Acc: 0.8459, Speed: 113.7k, Time: 60.5666
Epoch: 191, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.4001, Acc: 0.8456, Speed: 113.7k, Time: 72.7126
Epoch: 191, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.3998, Acc: 0.8459, Speed: 113.7k, Time: 84.9412
Epoch: 191, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.3993, Acc: 0.8461, Speed: 114.2k, Time: 96.7029
Epoch: 191, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/213.99, Loss: 0.3987, Acc: 0.8463, Speed: 114.0k, Time: 108.7910
Train 0.8463
Val 0.8577
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738

skip saving model for perf <= 0.8597
Epoch: 192, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/173.83, Loss: 0.3965, Acc: 0.8473, Speed: 120.1k, Time: 11.7740
Epoch: 192, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/200.45, Loss: 0.3997, Acc: 0.8467, Speed: 116.5k, Time: 23.9866
Epoch: 192, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/200.45, Loss: 0.3997, Acc: 0.8465, Speed: 114.6k, Time: 36.0872
Epoch: 192, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.45, Loss: 0.3978, Acc: 0.8471, Speed: 113.9k, Time: 48.2245
Epoch: 192, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.45, Loss: 0.3982, Acc: 0.8468, Speed: 113.3k, Time: 60.4374
Epoch: 192, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/202.37, Loss: 0.3985, Acc: 0.8469, Speed: 113.7k, Time: 72.5250
Epoch: 192, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/202.37, Loss: 0.3987, Acc: 0.8467, Speed: 113.8k, Time: 84.5183
Epoch: 192, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/202.37, Loss: 0.3990, Acc: 0.8463, Speed: 114.0k, Time: 96.4766
Epoch: 192, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/202.37, Loss: 0.3989, Acc: 0.8462, Speed: 114.2k, Time: 108.3860
Train 0.8465
Val 0.8586
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551

skip saving model for perf <= 0.8597
Epoch: 193, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/179.96, Loss: 0.3943, Acc: 0.8488, Speed: 115.3k, Time: 11.9107
Epoch: 193, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.96, Loss: 0.3960, Acc: 0.8479, Speed: 115.8k, Time: 23.8207
Epoch: 193, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/182.90, Loss: 0.3975, Acc: 0.8471, Speed: 117.1k, Time: 35.3720
Epoch: 193, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.27, Loss: 0.3987, Acc: 0.8465, Speed: 116.6k, Time: 47.2987
Epoch: 193, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.27, Loss: 0.3976, Acc: 0.8469, Speed: 116.0k, Time: 59.2285
Epoch: 193, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.27, Loss: 0.3967, Acc: 0.8476, Speed: 116.2k, Time: 70.8358
Epoch: 193, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/200.27, Loss: 0.3965, Acc: 0.8477, Speed: 115.6k, Time: 83.0231
Epoch: 193, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/200.27, Loss: 0.3969, Acc: 0.8475, Speed: 115.3k, Time: 95.1280
Epoch: 193, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/200.27, Loss: 0.3980, Acc: 0.8469, Speed: 115.4k, Time: 107.3294
Train 0.8469
Val 0.8586
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551

skip saving model for perf <= 0.8597
Epoch: 194, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3923, Acc: 0.8495, Speed: 113.4k, Time: 12.1998
Epoch: 194, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3958, Acc: 0.8477, Speed: 114.5k, Time: 24.2638
Epoch: 194, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3970, Acc: 0.8472, Speed: 114.5k, Time: 36.4274
Epoch: 194, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3973, Acc: 0.8468, Speed: 114.2k, Time: 48.6341
Epoch: 194, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3975, Acc: 0.8472, Speed: 113.6k, Time: 60.6707
Epoch: 194, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3968, Acc: 0.8474, Speed: 113.4k, Time: 72.7172
Epoch: 194, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3970, Acc: 0.8472, Speed: 113.5k, Time: 84.8173
Epoch: 194, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3972, Acc: 0.8471, Speed: 114.0k, Time: 96.6174
Epoch: 194, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/223.55, Loss: 0.3974, Acc: 0.8468, Speed: 114.0k, Time: 108.7701
Train 0.8468
Val 0.8599
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872

saving model to local_300_parikh
Epoch: 195, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/166.10, Loss: 0.3958, Acc: 0.8462, Speed: 116.9k, Time: 11.7834
Epoch: 195, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/170.99, Loss: 0.3970, Acc: 0.8464, Speed: 115.0k, Time: 23.9874
Epoch: 195, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/194.68, Loss: 0.3962, Acc: 0.8471, Speed: 114.7k, Time: 36.2252
Epoch: 195, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/237.23, Loss: 0.3976, Acc: 0.8464, Speed: 115.0k, Time: 48.3406
Epoch: 195, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/237.23, Loss: 0.3971, Acc: 0.8467, Speed: 114.5k, Time: 60.4181
Epoch: 195, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/237.23, Loss: 0.3973, Acc: 0.8468, Speed: 114.6k, Time: 72.5500
Epoch: 195, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/237.23, Loss: 0.3971, Acc: 0.8470, Speed: 114.1k, Time: 84.7143
Epoch: 195, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/237.23, Loss: 0.3970, Acc: 0.8470, Speed: 113.9k, Time: 96.9383
Epoch: 195, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/237.23, Loss: 0.3975, Acc: 0.8468, Speed: 113.7k, Time: 109.1191
Train 0.8467
Val 0.8590
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957

skip saving model for perf <= 0.8599
Epoch: 196, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/179.96, Loss: 0.3984, Acc: 0.8448, Speed: 114.0k, Time: 12.2713
Epoch: 196, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.96, Loss: 0.3964, Acc: 0.8467, Speed: 112.0k, Time: 24.3581
Epoch: 196, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.96, Loss: 0.3965, Acc: 0.8466, Speed: 113.3k, Time: 36.4048
Epoch: 196, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/198.54, Loss: 0.3969, Acc: 0.8464, Speed: 113.5k, Time: 48.3457
Epoch: 196, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/216.32, Loss: 0.3969, Acc: 0.8467, Speed: 113.6k, Time: 60.4750
Epoch: 196, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.32, Loss: 0.3975, Acc: 0.8465, Speed: 114.4k, Time: 72.2418
Epoch: 196, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.32, Loss: 0.3976, Acc: 0.8463, Speed: 113.9k, Time: 84.4427
Epoch: 196, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.32, Loss: 0.3984, Acc: 0.8460, Speed: 113.7k, Time: 96.6200
Epoch: 196, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.32, Loss: 0.3986, Acc: 0.8461, Speed: 113.8k, Time: 108.7346
Train 0.8461
Val 0.8590
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957

skip saving model for perf <= 0.8599
Epoch: 197, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/168.09, Loss: 0.3947, Acc: 0.8493, Speed: 112.2k, Time: 12.1289
Epoch: 197, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3952, Acc: 0.8480, Speed: 112.7k, Time: 24.3514
Epoch: 197, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3968, Acc: 0.8475, Speed: 113.0k, Time: 36.5566
Epoch: 197, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3967, Acc: 0.8476, Speed: 113.0k, Time: 48.6513
Epoch: 197, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3975, Acc: 0.8475, Speed: 112.8k, Time: 60.8164
Epoch: 197, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3971, Acc: 0.8474, Speed: 112.6k, Time: 72.9930
Epoch: 197, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3980, Acc: 0.8470, Speed: 112.5k, Time: 85.1534
Epoch: 197, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3978, Acc: 0.8470, Speed: 113.2k, Time: 97.1143
Epoch: 197, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/218.99, Loss: 0.3984, Acc: 0.8467, Speed: 113.7k, Time: 109.1477
Train 0.8465
Val 0.8587
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653

skip saving model for perf <= 0.8599
Epoch: 198, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/210.52, Loss: 0.3985, Acc: 0.8468, Speed: 116.9k, Time: 11.7252
Epoch: 198, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/210.52, Loss: 0.4006, Acc: 0.8451, Speed: 115.6k, Time: 23.8679
Epoch: 198, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/317.85, Loss: 0.4018, Acc: 0.8456, Speed: 115.0k, Time: 36.0364
Epoch: 198, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/317.85, Loss: 0.4025, Acc: 0.8450, Speed: 114.4k, Time: 48.2079
Epoch: 198, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/317.85, Loss: 0.4022, Acc: 0.8454, Speed: 114.1k, Time: 60.3390
Epoch: 198, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/317.85, Loss: 0.4021, Acc: 0.8454, Speed: 114.2k, Time: 72.4328
Epoch: 198, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/317.85, Loss: 0.4023, Acc: 0.8452, Speed: 114.1k, Time: 84.5981
Epoch: 198, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/317.85, Loss: 0.4019, Acc: 0.8452, Speed: 114.0k, Time: 96.7569
Epoch: 198, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/317.85, Loss: 0.4013, Acc: 0.8455, Speed: 113.9k, Time: 108.8924
Train 0.8455
Val 0.8620
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006

saving model to local_300_parikh
Epoch: 199, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/163.57, Loss: 0.3998, Acc: 0.8463, Speed: 112.4k, Time: 12.1778
Epoch: 199, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/170.38, Loss: 0.3992, Acc: 0.8462, Speed: 113.7k, Time: 24.3060
Epoch: 199, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/172.48, Loss: 0.3986, Acc: 0.8464, Speed: 113.9k, Time: 36.3704
Epoch: 199, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/203.24, Loss: 0.3974, Acc: 0.8471, Speed: 114.7k, Time: 48.2617
Epoch: 199, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/203.24, Loss: 0.3974, Acc: 0.8473, Speed: 114.6k, Time: 60.2205
Epoch: 199, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/217.77, Loss: 0.3978, Acc: 0.8468, Speed: 115.0k, Time: 72.0492
Epoch: 199, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/217.77, Loss: 0.3974, Acc: 0.8470, Speed: 114.7k, Time: 84.2275
Epoch: 199, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/217.77, Loss: 0.3977, Acc: 0.8468, Speed: 114.1k, Time: 96.4352
Epoch: 199, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/217.77, Loss: 0.3980, Acc: 0.8467, Speed: 113.9k, Time: 108.6791
Train 0.8468
Val 0.8601
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075

skip saving model for perf <= 0.8620
Epoch: 200, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/187.67, Loss: 0.3934, Acc: 0.8495, Speed: 114.6k, Time: 12.1653
Epoch: 200, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/187.67, Loss: 0.3975, Acc: 0.8471, Speed: 114.0k, Time: 24.4019
Epoch: 200, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/187.67, Loss: 0.3967, Acc: 0.8477, Speed: 115.0k, Time: 36.5610
Epoch: 200, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/267.42, Loss: 0.3960, Acc: 0.8479, Speed: 113.8k, Time: 48.6815
Epoch: 200, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/267.42, Loss: 0.3967, Acc: 0.8477, Speed: 113.8k, Time: 60.9162
Epoch: 200, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/267.42, Loss: 0.3967, Acc: 0.8476, Speed: 113.5k, Time: 72.9923
Epoch: 200, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/267.42, Loss: 0.3972, Acc: 0.8476, Speed: 113.6k, Time: 85.0802
Epoch: 200, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/267.42, Loss: 0.3974, Acc: 0.8474, Speed: 113.6k, Time: 97.1194
Epoch: 200, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/267.42, Loss: 0.3976, Acc: 0.8474, Speed: 113.7k, Time: 109.0970
Train 0.8474
Val 0.8603
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278

skip saving model for perf <= 0.8620
Epoch: 201, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/168.03, Loss: 0.3973, Acc: 0.8464, Speed: 118.5k, Time: 11.8247
Epoch: 201, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/168.03, Loss: 0.3936, Acc: 0.8483, Speed: 115.0k, Time: 23.9589
Epoch: 201, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/186.17, Loss: 0.3958, Acc: 0.8474, Speed: 114.3k, Time: 36.1474
Epoch: 201, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/186.17, Loss: 0.3964, Acc: 0.8471, Speed: 114.4k, Time: 48.2425
Epoch: 201, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/210.09, Loss: 0.3968, Acc: 0.8469, Speed: 114.2k, Time: 60.3445
Epoch: 201, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/210.09, Loss: 0.3960, Acc: 0.8470, Speed: 114.5k, Time: 72.4173
Epoch: 201, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/210.09, Loss: 0.3967, Acc: 0.8469, Speed: 114.1k, Time: 84.6168
Epoch: 201, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3970, Acc: 0.8470, Speed: 113.8k, Time: 96.7429
Epoch: 201, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3976, Acc: 0.8468, Speed: 113.8k, Time: 108.8870
Train 0.8467
Val 0.8604
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380

skip saving model for perf <= 0.8620
Epoch: 202, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/195.26, Loss: 0.3968, Acc: 0.8464, Speed: 112.3k, Time: 12.2575
Epoch: 202, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/195.26, Loss: 0.3968, Acc: 0.8468, Speed: 112.7k, Time: 24.4249
Epoch: 202, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/196.67, Loss: 0.3961, Acc: 0.8474, Speed: 113.7k, Time: 36.5435
Epoch: 202, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/196.67, Loss: 0.3966, Acc: 0.8473, Speed: 114.0k, Time: 48.1980
Epoch: 202, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/196.67, Loss: 0.3958, Acc: 0.8476, Speed: 113.9k, Time: 60.3163
Epoch: 202, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/196.67, Loss: 0.3960, Acc: 0.8471, Speed: 114.3k, Time: 72.0523
Epoch: 202, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/196.67, Loss: 0.3959, Acc: 0.8472, Speed: 113.9k, Time: 84.2557
Epoch: 202, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/196.67, Loss: 0.3960, Acc: 0.8471, Speed: 113.6k, Time: 96.4695
Epoch: 202, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/196.67, Loss: 0.3968, Acc: 0.8468, Speed: 113.9k, Time: 108.7237
Train 0.8470
Val 0.8599
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872

skip saving model for perf <= 0.8620
Epoch: 203, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/173.87, Loss: 0.3910, Acc: 0.8501, Speed: 111.5k, Time: 12.1184
Epoch: 203, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/173.87, Loss: 0.3919, Acc: 0.8499, Speed: 112.5k, Time: 24.2694
Epoch: 203, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/177.51, Loss: 0.3942, Acc: 0.8488, Speed: 112.0k, Time: 36.5150
Epoch: 203, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/177.51, Loss: 0.3950, Acc: 0.8486, Speed: 112.0k, Time: 48.7291
Epoch: 203, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/185.19, Loss: 0.3970, Acc: 0.8477, Speed: 112.4k, Time: 60.9701
Epoch: 203, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/188.21, Loss: 0.3967, Acc: 0.8477, Speed: 112.7k, Time: 73.2240
Epoch: 203, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/188.21, Loss: 0.3963, Acc: 0.8478, Speed: 112.9k, Time: 85.3972
Epoch: 203, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/191.64, Loss: 0.3959, Acc: 0.8481, Speed: 113.0k, Time: 97.4468
Epoch: 203, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/191.64, Loss: 0.3964, Acc: 0.8477, Speed: 113.4k, Time: 109.3672
Train 0.8477
Val 0.8582
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246

skip saving model for perf <= 0.8620
Epoch: 204, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/180.15, Loss: 0.3890, Acc: 0.8504, Speed: 115.5k, Time: 11.8802
Epoch: 204, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3915, Acc: 0.8496, Speed: 115.0k, Time: 24.1143
Epoch: 204, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3935, Acc: 0.8487, Speed: 114.1k, Time: 36.2417
Epoch: 204, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3940, Acc: 0.8485, Speed: 114.0k, Time: 48.5078
Epoch: 204, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3961, Acc: 0.8476, Speed: 113.5k, Time: 60.7698
Epoch: 204, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3961, Acc: 0.8476, Speed: 113.5k, Time: 72.9667
Epoch: 204, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3967, Acc: 0.8475, Speed: 113.2k, Time: 85.2191
Epoch: 204, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3965, Acc: 0.8474, Speed: 113.2k, Time: 97.3377
Epoch: 204, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/261.87, Loss: 0.3968, Acc: 0.8472, Speed: 113.2k, Time: 109.5277
Train 0.8470
Val 0.8603
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278

skip saving model for perf <= 0.8620
Epoch: 205, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/185.58, Loss: 0.3972, Acc: 0.8478, Speed: 114.0k, Time: 12.1287
Epoch: 205, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/185.58, Loss: 0.3981, Acc: 0.8475, Speed: 112.8k, Time: 24.3563
Epoch: 205, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/185.58, Loss: 0.3969, Acc: 0.8476, Speed: 112.5k, Time: 36.4872
Epoch: 205, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/185.58, Loss: 0.3966, Acc: 0.8475, Speed: 113.6k, Time: 48.3910
Epoch: 205, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/185.58, Loss: 0.3963, Acc: 0.8476, Speed: 113.6k, Time: 60.4752
Epoch: 205, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/185.58, Loss: 0.3968, Acc: 0.8474, Speed: 114.5k, Time: 72.2492
Epoch: 205, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/185.58, Loss: 0.3974, Acc: 0.8472, Speed: 114.3k, Time: 84.4568
Epoch: 205, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/191.92, Loss: 0.3968, Acc: 0.8476, Speed: 114.1k, Time: 96.6570
Epoch: 205, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/229.74, Loss: 0.3963, Acc: 0.8477, Speed: 114.3k, Time: 108.7509
Train 0.8477
Val 0.8603
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278

skip saving model for perf <= 0.8620
Epoch: 206, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/160.66, Loss: 0.3928, Acc: 0.8503, Speed: 113.7k, Time: 12.2017
Epoch: 206, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/195.43, Loss: 0.3956, Acc: 0.8481, Speed: 114.4k, Time: 24.4438
Epoch: 206, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/195.43, Loss: 0.3952, Acc: 0.8480, Speed: 113.1k, Time: 36.7295
Epoch: 206, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/195.43, Loss: 0.3952, Acc: 0.8482, Speed: 113.5k, Time: 48.9425
Epoch: 206, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/216.18, Loss: 0.3958, Acc: 0.8476, Speed: 113.1k, Time: 61.1355
Epoch: 206, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.18, Loss: 0.3951, Acc: 0.8477, Speed: 113.6k, Time: 73.2689
Epoch: 206, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.18, Loss: 0.3948, Acc: 0.8480, Speed: 113.3k, Time: 85.5103
Epoch: 206, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.18, Loss: 0.3949, Acc: 0.8478, Speed: 113.2k, Time: 97.5523
Epoch: 206, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.18, Loss: 0.3957, Acc: 0.8476, Speed: 113.3k, Time: 109.3763
Train 0.8476
Val 0.8597
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669

skip saving model for perf <= 0.8620
Epoch: 207, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.93, Loss: 0.3956, Acc: 0.8473, Speed: 114.7k, Time: 11.8695
Epoch: 207, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3943, Acc: 0.8476, Speed: 113.3k, Time: 24.0573
Epoch: 207, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3930, Acc: 0.8478, Speed: 113.5k, Time: 36.2043
Epoch: 207, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3939, Acc: 0.8476, Speed: 113.1k, Time: 48.3884
Epoch: 207, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3948, Acc: 0.8473, Speed: 113.1k, Time: 60.5381
Epoch: 207, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3955, Acc: 0.8473, Speed: 113.3k, Time: 72.6610
Epoch: 207, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3956, Acc: 0.8474, Speed: 113.4k, Time: 84.9385
Epoch: 207, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3953, Acc: 0.8475, Speed: 113.4k, Time: 97.0811
Epoch: 207, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/234.87, Loss: 0.3952, Acc: 0.8476, Speed: 113.6k, Time: 109.1907
Train 0.8476
Val 0.8599
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872

skip saving model for perf <= 0.8620
Epoch: 208, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3982, Acc: 0.8465, Speed: 112.2k, Time: 12.1353
Epoch: 208, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3965, Acc: 0.8468, Speed: 113.6k, Time: 24.2841
Epoch: 208, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3950, Acc: 0.8476, Speed: 113.6k, Time: 36.4729
Epoch: 208, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3964, Acc: 0.8471, Speed: 114.1k, Time: 48.2964
Epoch: 208, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3958, Acc: 0.8474, Speed: 113.9k, Time: 60.4833
Epoch: 208, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3957, Acc: 0.8476, Speed: 114.5k, Time: 72.2562
Epoch: 208, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3957, Acc: 0.8479, Speed: 114.3k, Time: 84.5079
Epoch: 208, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/202.19, Loss: 0.3952, Acc: 0.8481, Speed: 114.1k, Time: 96.7562
Epoch: 208, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/255.48, Loss: 0.3954, Acc: 0.8481, Speed: 113.7k, Time: 108.9506
Train 0.8481
Val 0.8604
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380

skip saving model for perf <= 0.8620
Epoch: 209, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/177.88, Loss: 0.4014, Acc: 0.8452, Speed: 114.7k, Time: 12.0995
Epoch: 209, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/186.30, Loss: 0.3960, Acc: 0.8475, Speed: 114.3k, Time: 24.2571
Epoch: 209, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/186.30, Loss: 0.3943, Acc: 0.8483, Speed: 114.0k, Time: 36.4342
Epoch: 209, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/186.30, Loss: 0.3934, Acc: 0.8481, Speed: 113.6k, Time: 48.5839
Epoch: 209, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/186.30, Loss: 0.3945, Acc: 0.8475, Speed: 113.5k, Time: 60.7693
Epoch: 209, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/211.60, Loss: 0.3948, Acc: 0.8474, Speed: 113.4k, Time: 73.0217
Epoch: 209, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/211.60, Loss: 0.3948, Acc: 0.8475, Speed: 113.2k, Time: 85.2560
Epoch: 209, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/211.60, Loss: 0.3958, Acc: 0.8472, Speed: 113.5k, Time: 97.3215
Epoch: 209, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/211.60, Loss: 0.3951, Acc: 0.8476, Speed: 113.8k, Time: 109.1957
Train 0.8476
Val 0.8600
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974

skip saving model for perf <= 0.8620
Epoch: 210, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/187.71, Loss: 0.3929, Acc: 0.8497, Speed: 117.2k, Time: 11.7882
Epoch: 210, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/187.71, Loss: 0.3966, Acc: 0.8477, Speed: 115.2k, Time: 23.9655
Epoch: 210, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/187.71, Loss: 0.3969, Acc: 0.8478, Speed: 115.1k, Time: 36.0949
Epoch: 210, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.61, Loss: 0.3960, Acc: 0.8475, Speed: 114.3k, Time: 48.1900
Epoch: 210, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/197.61, Loss: 0.3961, Acc: 0.8473, Speed: 114.3k, Time: 60.2946
Epoch: 210, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.61, Loss: 0.3963, Acc: 0.8474, Speed: 114.1k, Time: 72.5051
Epoch: 210, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/197.61, Loss: 0.3962, Acc: 0.8475, Speed: 114.1k, Time: 84.7066
Epoch: 210, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/197.61, Loss: 0.3947, Acc: 0.8482, Speed: 113.8k, Time: 96.8263
Epoch: 210, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/211.11, Loss: 0.3944, Acc: 0.8483, Speed: 113.9k, Time: 108.9661
Train 0.8483
Val 0.8593
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262

skip saving model for perf <= 0.8620
Epoch: 211, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.84, Loss: 0.3979, Acc: 0.8474, Speed: 113.6k, Time: 12.1188
Epoch: 211, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/202.13, Loss: 0.3967, Acc: 0.8480, Speed: 112.9k, Time: 24.3520
Epoch: 211, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/202.13, Loss: 0.3967, Acc: 0.8479, Speed: 113.3k, Time: 36.5501
Epoch: 211, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/202.13, Loss: 0.3959, Acc: 0.8480, Speed: 113.7k, Time: 48.3188
Epoch: 211, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/251.88, Loss: 0.3959, Acc: 0.8478, Speed: 113.6k, Time: 60.5907
Epoch: 211, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/251.88, Loss: 0.3955, Acc: 0.8479, Speed: 114.2k, Time: 72.4769
Epoch: 211, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/251.88, Loss: 0.3958, Acc: 0.8478, Speed: 114.1k, Time: 84.7285
Epoch: 211, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/251.88, Loss: 0.3958, Acc: 0.8477, Speed: 113.9k, Time: 96.9025
Epoch: 211, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/251.88, Loss: 0.3954, Acc: 0.8478, Speed: 113.9k, Time: 109.0688
Train 0.8482
Val 0.8579
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941

skip saving model for perf <= 0.8620
Epoch: 212, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/167.75, Loss: 0.3928, Acc: 0.8495, Speed: 113.9k, Time: 12.2076
Epoch: 212, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/176.40, Loss: 0.3959, Acc: 0.8481, Speed: 112.8k, Time: 24.3968
Epoch: 212, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/215.58, Loss: 0.3968, Acc: 0.8472, Speed: 113.9k, Time: 36.5526
Epoch: 212, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/215.58, Loss: 0.3972, Acc: 0.8472, Speed: 113.6k, Time: 48.7643
Epoch: 212, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/215.58, Loss: 0.3960, Acc: 0.8479, Speed: 113.8k, Time: 60.8878
Epoch: 212, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/215.58, Loss: 0.3962, Acc: 0.8477, Speed: 113.4k, Time: 73.0579
Epoch: 212, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/215.58, Loss: 0.3959, Acc: 0.8478, Speed: 113.0k, Time: 85.2119
Epoch: 212, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/215.58, Loss: 0.3961, Acc: 0.8476, Speed: 113.1k, Time: 97.4338
Epoch: 212, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/215.58, Loss: 0.3954, Acc: 0.8479, Speed: 113.7k, Time: 109.1402
Train 0.8477
Val 0.8599
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872

skip saving model for perf <= 0.8620
Epoch: 213, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/171.69, Loss: 0.3879, Acc: 0.8511, Speed: 114.1k, Time: 11.6538
Epoch: 213, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3880, Acc: 0.8511, Speed: 115.2k, Time: 23.5921
Epoch: 213, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3939, Acc: 0.8486, Speed: 116.9k, Time: 35.5035
Epoch: 213, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3946, Acc: 0.8480, Speed: 116.6k, Time: 47.3835
Epoch: 213, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3942, Acc: 0.8480, Speed: 116.0k, Time: 59.4198
Epoch: 213, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3944, Acc: 0.8481, Speed: 116.2k, Time: 71.2309
Epoch: 213, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3953, Acc: 0.8479, Speed: 116.1k, Time: 83.1545
Epoch: 213, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3948, Acc: 0.8480, Speed: 115.9k, Time: 95.0640
Epoch: 213, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/219.15, Loss: 0.3954, Acc: 0.8479, Speed: 115.6k, Time: 106.9858
Train 0.8477
Val 0.8577
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738

skip saving model for perf <= 0.8620
Epoch: 214, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.87, Loss: 0.3911, Acc: 0.8489, Speed: 113.9k, Time: 11.8580
Epoch: 214, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/197.87, Loss: 0.3910, Acc: 0.8489, Speed: 114.3k, Time: 23.8045
Epoch: 214, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/210.90, Loss: 0.3918, Acc: 0.8486, Speed: 114.8k, Time: 35.6656
Epoch: 214, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/210.90, Loss: 0.3934, Acc: 0.8483, Speed: 115.3k, Time: 47.3816
Epoch: 214, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/210.90, Loss: 0.3935, Acc: 0.8483, Speed: 115.1k, Time: 59.6273
Epoch: 214, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/263.74, Loss: 0.3932, Acc: 0.8487, Speed: 114.6k, Time: 71.8930
Epoch: 214, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/263.74, Loss: 0.3938, Acc: 0.8484, Speed: 114.7k, Time: 84.0187
Epoch: 214, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/263.74, Loss: 0.3942, Acc: 0.8482, Speed: 114.5k, Time: 96.2231
Epoch: 214, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/263.74, Loss: 0.3936, Acc: 0.8485, Speed: 114.2k, Time: 108.4979
Train 0.8482
Val 0.8595
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466

skip saving model for perf <= 0.8620
Epoch: 215, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/172.41, Loss: 0.3957, Acc: 0.8471, Speed: 109.5k, Time: 12.3802
Epoch: 215, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/216.50, Loss: 0.3937, Acc: 0.8481, Speed: 111.7k, Time: 24.6551
Epoch: 215, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/248.10, Loss: 0.3930, Acc: 0.8484, Speed: 112.2k, Time: 37.0458
Epoch: 215, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/248.10, Loss: 0.3924, Acc: 0.8487, Speed: 111.7k, Time: 49.2512
Epoch: 215, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/248.10, Loss: 0.3920, Acc: 0.8488, Speed: 112.0k, Time: 61.4912
Epoch: 215, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/248.10, Loss: 0.3919, Acc: 0.8487, Speed: 112.0k, Time: 73.8262
Epoch: 215, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/248.10, Loss: 0.3924, Acc: 0.8486, Speed: 111.7k, Time: 86.2005
Epoch: 215, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/248.10, Loss: 0.3921, Acc: 0.8488, Speed: 112.2k, Time: 98.0497
Epoch: 215, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/248.10, Loss: 0.3930, Acc: 0.8484, Speed: 112.8k, Time: 109.7901
Train 0.8481
Val 0.8600
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974

skip saving model for perf <= 0.8620
Epoch: 216, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/184.02, Loss: 0.3970, Acc: 0.8475, Speed: 113.0k, Time: 11.9584
Epoch: 216, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/187.14, Loss: 0.3951, Acc: 0.8481, Speed: 113.2k, Time: 24.2666
Epoch: 216, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/221.86, Loss: 0.3951, Acc: 0.8483, Speed: 112.8k, Time: 36.5218
Epoch: 216, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/221.86, Loss: 0.3955, Acc: 0.8484, Speed: 112.2k, Time: 48.7820
Epoch: 216, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/221.86, Loss: 0.3956, Acc: 0.8480, Speed: 112.1k, Time: 61.1447
Epoch: 216, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/256.18, Loss: 0.3938, Acc: 0.8486, Speed: 112.2k, Time: 73.4425
Epoch: 216, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/256.18, Loss: 0.3938, Acc: 0.8486, Speed: 112.2k, Time: 85.7420
Epoch: 216, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/256.18, Loss: 0.3934, Acc: 0.8489, Speed: 111.9k, Time: 98.0587
Epoch: 216, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/256.18, Loss: 0.3935, Acc: 0.8489, Speed: 112.1k, Time: 110.3507
Train 0.8485
Val 0.8594
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364

skip saving model for perf <= 0.8620
Epoch: 217, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3981, Acc: 0.8478, Speed: 112.7k, Time: 12.2896
Epoch: 217, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3954, Acc: 0.8488, Speed: 112.1k, Time: 24.6685
Epoch: 217, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3944, Acc: 0.8489, Speed: 111.2k, Time: 37.0118
Epoch: 217, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3941, Acc: 0.8486, Speed: 112.3k, Time: 48.8829
Epoch: 217, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3951, Acc: 0.8481, Speed: 112.8k, Time: 61.1901
Epoch: 217, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3951, Acc: 0.8481, Speed: 113.1k, Time: 73.0854
Epoch: 217, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3949, Acc: 0.8483, Speed: 112.5k, Time: 85.4123
Epoch: 217, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3954, Acc: 0.8479, Speed: 112.6k, Time: 97.7662
Epoch: 217, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/211.49, Loss: 0.3945, Acc: 0.8483, Speed: 112.7k, Time: 110.0540
Train 0.8482
Val 0.8605
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482

skip saving model for perf <= 0.8620
Epoch: 218, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/179.53, Loss: 0.4007, Acc: 0.8468, Speed: 113.3k, Time: 12.3060
Epoch: 218, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/210.73, Loss: 0.3973, Acc: 0.8473, Speed: 111.8k, Time: 24.6127
Epoch: 218, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/210.73, Loss: 0.3973, Acc: 0.8476, Speed: 111.0k, Time: 36.9469
Epoch: 218, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/210.73, Loss: 0.3962, Acc: 0.8480, Speed: 111.3k, Time: 49.1533
Epoch: 218, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/216.66, Loss: 0.3963, Acc: 0.8480, Speed: 111.8k, Time: 61.4535
Epoch: 218, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.66, Loss: 0.3953, Acc: 0.8483, Speed: 112.1k, Time: 73.6983
Epoch: 218, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/245.47, Loss: 0.3949, Acc: 0.8484, Speed: 112.2k, Time: 85.9214
Epoch: 218, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/245.47, Loss: 0.3953, Acc: 0.8479, Speed: 112.5k, Time: 98.1314
Epoch: 218, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/245.47, Loss: 0.3951, Acc: 0.8480, Speed: 112.7k, Time: 110.0861
Train 0.8482
Val 0.8608
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787

skip saving model for perf <= 0.8620
Epoch: 219, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/193.04, Loss: 0.3963, Acc: 0.8469, Speed: 116.2k, Time: 11.8488
Epoch: 219, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/201.29, Loss: 0.3973, Acc: 0.8463, Speed: 114.5k, Time: 24.1790
Epoch: 219, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/201.29, Loss: 0.3959, Acc: 0.8473, Speed: 113.4k, Time: 36.3711
Epoch: 219, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/201.29, Loss: 0.3951, Acc: 0.8476, Speed: 113.0k, Time: 48.6443
Epoch: 219, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/201.29, Loss: 0.3946, Acc: 0.8479, Speed: 112.5k, Time: 60.8208
Epoch: 219, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/201.29, Loss: 0.3953, Acc: 0.8476, Speed: 112.4k, Time: 73.0175
Epoch: 219, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/201.29, Loss: 0.3951, Acc: 0.8477, Speed: 112.6k, Time: 85.2275
Epoch: 219, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/201.29, Loss: 0.3958, Acc: 0.8475, Speed: 112.9k, Time: 97.4400
Epoch: 219, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/237.79, Loss: 0.3959, Acc: 0.8474, Speed: 113.1k, Time: 109.6581
Train 0.8476
Val 0.8583
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348

skip saving model for perf <= 0.8620
Epoch: 220, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/223.07, Loss: 0.3990, Acc: 0.8468, Speed: 115.2k, Time: 12.2583
Epoch: 220, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/223.07, Loss: 0.3935, Acc: 0.8497, Speed: 113.2k, Time: 24.4194
Epoch: 220, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/223.07, Loss: 0.3946, Acc: 0.8488, Speed: 113.5k, Time: 36.4799
Epoch: 220, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/223.07, Loss: 0.3951, Acc: 0.8484, Speed: 114.4k, Time: 48.4592
Epoch: 220, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/223.07, Loss: 0.3959, Acc: 0.8477, Speed: 114.0k, Time: 60.6289
Epoch: 220, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/380.89, Loss: 0.3956, Acc: 0.8475, Speed: 114.1k, Time: 72.5834
Epoch: 220, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/380.89, Loss: 0.3955, Acc: 0.8477, Speed: 113.7k, Time: 84.7803
Epoch: 220, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/380.89, Loss: 0.3960, Acc: 0.8477, Speed: 113.8k, Time: 96.9409
Epoch: 220, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/380.89, Loss: 0.3953, Acc: 0.8478, Speed: 113.6k, Time: 109.1761
Train 0.8478
Val 0.8595
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466

skip saving model for perf <= 0.8620
Epoch: 221, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/192.41, Loss: 0.3863, Acc: 0.8515, Speed: 113.7k, Time: 12.1947
Epoch: 221, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/192.41, Loss: 0.3863, Acc: 0.8516, Speed: 113.1k, Time: 24.5093
Epoch: 221, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/192.41, Loss: 0.3921, Acc: 0.8492, Speed: 112.6k, Time: 36.7860
Epoch: 221, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/192.41, Loss: 0.3914, Acc: 0.8493, Speed: 113.3k, Time: 48.7102
Epoch: 221, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/192.41, Loss: 0.3925, Acc: 0.8490, Speed: 114.0k, Time: 60.6475
Epoch: 221, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/192.41, Loss: 0.3932, Acc: 0.8483, Speed: 114.0k, Time: 72.7117
Epoch: 221, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/207.37, Loss: 0.3935, Acc: 0.8482, Speed: 114.3k, Time: 84.5474
Epoch: 221, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/207.37, Loss: 0.3938, Acc: 0.8480, Speed: 114.5k, Time: 96.3816
Epoch: 221, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/207.37, Loss: 0.3937, Acc: 0.8479, Speed: 114.8k, Time: 108.0078
Train 0.8479
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177

skip saving model for perf <= 0.8620
Epoch: 222, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3952, Acc: 0.8480, Speed: 118.9k, Time: 11.6918
Epoch: 222, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3928, Acc: 0.8485, Speed: 116.4k, Time: 23.9978
Epoch: 222, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3918, Acc: 0.8489, Speed: 114.9k, Time: 36.1255
Epoch: 222, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3931, Acc: 0.8484, Speed: 114.0k, Time: 48.4361
Epoch: 222, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3925, Acc: 0.8486, Speed: 114.3k, Time: 60.6358
Epoch: 222, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3919, Acc: 0.8489, Speed: 113.7k, Time: 72.9380
Epoch: 222, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3934, Acc: 0.8482, Speed: 113.5k, Time: 85.1451
Epoch: 222, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3929, Acc: 0.8484, Speed: 113.3k, Time: 97.4482
Epoch: 222, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/204.75, Loss: 0.3928, Acc: 0.8486, Speed: 113.1k, Time: 109.6188
Train 0.8486
Val 0.8601
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075

skip saving model for perf <= 0.8620
Epoch: 223, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3924, Acc: 0.8502, Speed: 112.9k, Time: 12.2858
Epoch: 223, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3936, Acc: 0.8488, Speed: 113.0k, Time: 24.4749
Epoch: 223, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3952, Acc: 0.8481, Speed: 112.7k, Time: 36.5210
Epoch: 223, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3940, Acc: 0.8486, Speed: 113.2k, Time: 48.5328
Epoch: 223, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3930, Acc: 0.8486, Speed: 113.3k, Time: 60.7334
Epoch: 223, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3929, Acc: 0.8487, Speed: 113.8k, Time: 72.6171
Epoch: 223, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3940, Acc: 0.8484, Speed: 113.5k, Time: 84.8428
Epoch: 223, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3942, Acc: 0.8483, Speed: 113.7k, Time: 96.6602
Epoch: 223, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/265.78, Loss: 0.3939, Acc: 0.8484, Speed: 114.5k, Time: 108.2423
Train 0.8483
Val 0.8598
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770

skip saving model for perf <= 0.8620
Epoch: 224, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/179.08, Loss: 0.3916, Acc: 0.8514, Speed: 119.1k, Time: 11.6703
Epoch: 224, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.08, Loss: 0.3903, Acc: 0.8509, Speed: 118.6k, Time: 23.3561
Epoch: 224, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/200.22, Loss: 0.3898, Acc: 0.8504, Speed: 118.8k, Time: 34.9351
Epoch: 224, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/200.22, Loss: 0.3914, Acc: 0.8501, Speed: 118.3k, Time: 46.6417
Epoch: 224, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/200.22, Loss: 0.3917, Acc: 0.8500, Speed: 118.7k, Time: 58.2603
Epoch: 224, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.22, Loss: 0.3919, Acc: 0.8499, Speed: 118.5k, Time: 69.9556
Epoch: 224, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/200.22, Loss: 0.3922, Acc: 0.8496, Speed: 118.4k, Time: 81.6121
Epoch: 224, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/200.22, Loss: 0.3929, Acc: 0.8492, Speed: 118.5k, Time: 93.1849
Epoch: 224, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/200.22, Loss: 0.3932, Acc: 0.8489, Speed: 118.4k, Time: 104.7589
Train 0.8487
Val 0.8582
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246

skip saving model for perf <= 0.8620
Epoch: 225, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.25, Loss: 0.3930, Acc: 0.8467, Speed: 117.9k, Time: 11.8124
Epoch: 225, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/203.53, Loss: 0.3930, Acc: 0.8478, Speed: 114.9k, Time: 23.8929
Epoch: 225, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/203.53, Loss: 0.3947, Acc: 0.8475, Speed: 114.3k, Time: 35.9562
Epoch: 225, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/203.53, Loss: 0.3931, Acc: 0.8482, Speed: 113.7k, Time: 48.0323
Epoch: 225, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/203.53, Loss: 0.3929, Acc: 0.8484, Speed: 113.8k, Time: 60.0683
Epoch: 225, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/203.53, Loss: 0.3936, Acc: 0.8481, Speed: 114.1k, Time: 72.1438
Epoch: 225, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/203.53, Loss: 0.3940, Acc: 0.8480, Speed: 114.1k, Time: 84.2809
Epoch: 225, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/218.86, Loss: 0.3941, Acc: 0.8480, Speed: 114.2k, Time: 96.3304
Epoch: 225, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/218.86, Loss: 0.3940, Acc: 0.8480, Speed: 114.7k, Time: 108.1322
Train 0.8483
Val 0.8588
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754

skip saving model for perf <= 0.8620
Epoch: 226, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3916, Acc: 0.8490, Speed: 115.5k, Time: 11.6565
Epoch: 226, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3915, Acc: 0.8491, Speed: 115.8k, Time: 23.2823
Epoch: 226, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3919, Acc: 0.8496, Speed: 117.2k, Time: 34.9595
Epoch: 226, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3923, Acc: 0.8492, Speed: 117.3k, Time: 46.6537
Epoch: 226, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3924, Acc: 0.8491, Speed: 118.2k, Time: 58.0669
Epoch: 226, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3933, Acc: 0.8486, Speed: 117.4k, Time: 70.2479
Epoch: 226, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3930, Acc: 0.8489, Speed: 117.3k, Time: 81.9961
Epoch: 226, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3930, Acc: 0.8488, Speed: 116.9k, Time: 94.1652
Epoch: 226, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/228.06, Loss: 0.3927, Acc: 0.8489, Speed: 116.5k, Time: 106.4178
Train 0.8489
Val 0.8595
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466

skip saving model for perf <= 0.8620
Epoch: 227, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3911, Acc: 0.8506, Speed: 113.5k, Time: 12.1512
Epoch: 227, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3922, Acc: 0.8496, Speed: 112.9k, Time: 24.3419
Epoch: 227, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3915, Acc: 0.8500, Speed: 113.4k, Time: 36.4280
Epoch: 227, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3919, Acc: 0.8492, Speed: 114.0k, Time: 48.4778
Epoch: 227, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3913, Acc: 0.8495, Speed: 113.7k, Time: 60.6441
Epoch: 227, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3921, Acc: 0.8491, Speed: 114.0k, Time: 72.8235
Epoch: 227, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3922, Acc: 0.8490, Speed: 114.0k, Time: 84.9419
Epoch: 227, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3926, Acc: 0.8489, Speed: 113.7k, Time: 97.0913
Epoch: 227, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/210.69, Loss: 0.3931, Acc: 0.8487, Speed: 113.7k, Time: 109.2172
Train 0.8488
Val 0.8589
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856

skip saving model for perf <= 0.8620
Epoch: 228, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/162.80, Loss: 0.3890, Acc: 0.8504, Speed: 114.6k, Time: 11.9277
Epoch: 228, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/218.01, Loss: 0.3879, Acc: 0.8514, Speed: 116.4k, Time: 23.7178
Epoch: 228, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/218.01, Loss: 0.3909, Acc: 0.8502, Speed: 116.0k, Time: 35.7181
Epoch: 228, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/218.01, Loss: 0.3925, Acc: 0.8494, Speed: 115.4k, Time: 47.8589
Epoch: 228, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/251.98, Loss: 0.3921, Acc: 0.8494, Speed: 114.7k, Time: 60.0340
Epoch: 228, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/251.98, Loss: 0.3921, Acc: 0.8496, Speed: 114.6k, Time: 72.1202
Epoch: 228, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/251.98, Loss: 0.3928, Acc: 0.8493, Speed: 114.4k, Time: 84.2678
Epoch: 228, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/251.98, Loss: 0.3929, Acc: 0.8492, Speed: 114.2k, Time: 96.3797
Epoch: 228, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/251.98, Loss: 0.3927, Acc: 0.8491, Speed: 114.2k, Time: 108.4983
Train 0.8491
Val 0.8608
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787

skip saving model for perf <= 0.8620
Epoch: 229, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/172.57, Loss: 0.3849, Acc: 0.8532, Speed: 112.0k, Time: 12.1524
Epoch: 229, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/180.08, Loss: 0.3896, Acc: 0.8510, Speed: 113.5k, Time: 24.2893
Epoch: 229, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/220.86, Loss: 0.3909, Acc: 0.8501, Speed: 112.8k, Time: 36.3627
Epoch: 229, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/220.86, Loss: 0.3901, Acc: 0.8502, Speed: 113.0k, Time: 48.5420
Epoch: 229, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/220.86, Loss: 0.3913, Acc: 0.8495, Speed: 113.3k, Time: 60.5222
Epoch: 229, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/220.86, Loss: 0.3908, Acc: 0.8497, Speed: 113.4k, Time: 72.6074
Epoch: 229, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/220.86, Loss: 0.3914, Acc: 0.8494, Speed: 114.1k, Time: 84.4095
Epoch: 229, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/225.11, Loss: 0.3915, Acc: 0.8493, Speed: 114.1k, Time: 96.5186
Epoch: 229, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/225.11, Loss: 0.3917, Acc: 0.8493, Speed: 114.3k, Time: 108.6352
Train 0.8495
Val 0.8584
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449

skip saving model for perf <= 0.8620
Epoch: 230, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3867, Acc: 0.8506, Speed: 114.7k, Time: 11.9887
Epoch: 230, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3883, Acc: 0.8501, Speed: 114.0k, Time: 24.0633
Epoch: 230, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3887, Acc: 0.8504, Speed: 113.5k, Time: 36.2720
Epoch: 230, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3891, Acc: 0.8504, Speed: 113.9k, Time: 48.3217
Epoch: 230, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3908, Acc: 0.8497, Speed: 113.9k, Time: 60.4877
Epoch: 230, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3903, Acc: 0.8500, Speed: 113.9k, Time: 72.6530
Epoch: 230, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3916, Acc: 0.8494, Speed: 113.9k, Time: 84.7541
Epoch: 230, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3918, Acc: 0.8493, Speed: 113.7k, Time: 96.9233
Epoch: 230, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/217.23, Loss: 0.3921, Acc: 0.8491, Speed: 113.6k, Time: 109.1199
Train 0.8492
Val 0.8584
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449

skip saving model for perf <= 0.8620
Epoch: 231, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/188.08, Loss: 0.3890, Acc: 0.8504, Speed: 117.4k, Time: 11.8135
Epoch: 231, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/188.08, Loss: 0.3903, Acc: 0.8504, Speed: 118.3k, Time: 23.4724
Epoch: 231, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/189.08, Loss: 0.3911, Acc: 0.8500, Speed: 117.3k, Time: 35.6142
Epoch: 231, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/189.08, Loss: 0.3903, Acc: 0.8503, Speed: 116.0k, Time: 47.6954
Epoch: 231, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/189.08, Loss: 0.3902, Acc: 0.8503, Speed: 114.8k, Time: 59.8135
Epoch: 231, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/199.48, Loss: 0.3916, Acc: 0.8496, Speed: 115.0k, Time: 72.0276
Epoch: 231, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/199.48, Loss: 0.3917, Acc: 0.8494, Speed: 114.7k, Time: 84.2523
Epoch: 231, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/199.48, Loss: 0.3921, Acc: 0.8493, Speed: 114.3k, Time: 96.3280
Epoch: 231, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/199.48, Loss: 0.3922, Acc: 0.8491, Speed: 114.4k, Time: 108.4835
Train 0.8492
Val 0.8597
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669

skip saving model for perf <= 0.8620
Epoch: 232, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/204.62, Loss: 0.3886, Acc: 0.8523, Speed: 111.8k, Time: 12.1971
Epoch: 232, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/204.62, Loss: 0.3878, Acc: 0.8521, Speed: 112.3k, Time: 24.4436
Epoch: 232, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/204.62, Loss: 0.3913, Acc: 0.8503, Speed: 112.8k, Time: 36.7538
Epoch: 232, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/204.62, Loss: 0.3912, Acc: 0.8499, Speed: 112.7k, Time: 49.0414
Epoch: 232, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/209.77, Loss: 0.3923, Acc: 0.8494, Speed: 112.8k, Time: 61.1976
Epoch: 232, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/209.77, Loss: 0.3919, Acc: 0.8494, Speed: 113.0k, Time: 73.2145
Epoch: 232, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/228.43, Loss: 0.3925, Acc: 0.8491, Speed: 113.6k, Time: 84.9756
Epoch: 232, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/228.43, Loss: 0.3925, Acc: 0.8491, Speed: 113.8k, Time: 97.1847
Epoch: 232, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/241.01, Loss: 0.3923, Acc: 0.8491, Speed: 113.7k, Time: 109.3606
Train 0.8491
Val 0.8596
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567

skip saving model for perf <= 0.8620
Epoch: 233, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/186.54, Loss: 0.3927, Acc: 0.8501, Speed: 115.7k, Time: 11.9877
Epoch: 233, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3929, Acc: 0.8493, Speed: 113.5k, Time: 24.1194
Epoch: 233, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3930, Acc: 0.8497, Speed: 113.2k, Time: 36.3256
Epoch: 233, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3928, Acc: 0.8498, Speed: 113.8k, Time: 48.4634
Epoch: 233, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3922, Acc: 0.8497, Speed: 113.7k, Time: 60.6521
Epoch: 233, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3925, Acc: 0.8497, Speed: 113.5k, Time: 72.7492
Epoch: 233, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3918, Acc: 0.8499, Speed: 113.5k, Time: 84.8281
Epoch: 233, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3918, Acc: 0.8496, Speed: 113.6k, Time: 96.8841
Epoch: 233, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/224.91, Loss: 0.3920, Acc: 0.8496, Speed: 113.8k, Time: 108.9705
Train 0.8495
Val 0.8587
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653

skip saving model for perf <= 0.8620
Epoch: 234, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3875, Acc: 0.8536, Speed: 116.1k, Time: 11.7567
Epoch: 234, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3905, Acc: 0.8504, Speed: 117.8k, Time: 23.4923
Epoch: 234, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3900, Acc: 0.8505, Speed: 116.0k, Time: 35.6022
Epoch: 234, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3890, Acc: 0.8507, Speed: 115.4k, Time: 47.6042
Epoch: 234, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3901, Acc: 0.8501, Speed: 115.0k, Time: 59.6846
Epoch: 234, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3909, Acc: 0.8496, Speed: 114.7k, Time: 71.8843
Epoch: 234, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3905, Acc: 0.8494, Speed: 114.7k, Time: 84.0370
Epoch: 234, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3906, Acc: 0.8494, Speed: 114.6k, Time: 96.1854
Epoch: 234, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/278.10, Loss: 0.3909, Acc: 0.8492, Speed: 114.4k, Time: 108.3310
Train 0.8492
Val 0.8579
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941

skip saving model for perf <= 0.8620
Epoch: 235, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/179.66, Loss: 0.3887, Acc: 0.8497, Speed: 112.5k, Time: 12.2301
Epoch: 235, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/222.70, Loss: 0.3911, Acc: 0.8491, Speed: 113.7k, Time: 24.3517
Epoch: 235, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/222.70, Loss: 0.3906, Acc: 0.8495, Speed: 114.0k, Time: 36.4317
Epoch: 235, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/222.70, Loss: 0.3904, Acc: 0.8497, Speed: 113.7k, Time: 48.6685
Epoch: 235, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/222.70, Loss: 0.3898, Acc: 0.8505, Speed: 114.0k, Time: 60.7409
Epoch: 235, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/230.15, Loss: 0.3901, Acc: 0.8505, Speed: 114.1k, Time: 72.5483
Epoch: 235, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/230.15, Loss: 0.3905, Acc: 0.8503, Speed: 114.5k, Time: 84.2798
Epoch: 235, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/230.15, Loss: 0.3910, Acc: 0.8502, Speed: 114.5k, Time: 96.3655
Epoch: 235, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/230.15, Loss: 0.3908, Acc: 0.8501, Speed: 114.3k, Time: 108.4756
Train 0.8501
Val 0.8582
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246

skip saving model for perf <= 0.8620
Epoch: 236, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/193.42, Loss: 0.3881, Acc: 0.8497, Speed: 111.7k, Time: 12.1268
Epoch: 236, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/193.42, Loss: 0.3896, Acc: 0.8500, Speed: 112.8k, Time: 24.2922
Epoch: 236, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/193.42, Loss: 0.3909, Acc: 0.8495, Speed: 112.6k, Time: 36.5061
Epoch: 236, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/193.42, Loss: 0.3911, Acc: 0.8495, Speed: 112.9k, Time: 48.6780
Epoch: 236, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/193.42, Loss: 0.3919, Acc: 0.8492, Speed: 113.1k, Time: 60.9194
Epoch: 236, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/223.11, Loss: 0.3911, Acc: 0.8495, Speed: 113.4k, Time: 72.9752
Epoch: 236, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/250.52, Loss: 0.3913, Acc: 0.8495, Speed: 113.4k, Time: 85.0805
Epoch: 236, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/250.52, Loss: 0.3911, Acc: 0.8495, Speed: 113.3k, Time: 97.1579
Epoch: 236, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/250.52, Loss: 0.3907, Acc: 0.8496, Speed: 113.4k, Time: 109.2713
Train 0.8494
Val 0.8596
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567

skip saving model for perf <= 0.8620
Epoch: 237, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/182.98, Loss: 0.3938, Acc: 0.8489, Speed: 117.2k, Time: 11.8085
Epoch: 237, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3929, Acc: 0.8488, Speed: 116.7k, Time: 23.6491
Epoch: 237, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3922, Acc: 0.8489, Speed: 115.4k, Time: 35.7981
Epoch: 237, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3911, Acc: 0.8495, Speed: 115.3k, Time: 47.8519
Epoch: 237, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3905, Acc: 0.8498, Speed: 115.1k, Time: 59.9295
Epoch: 237, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3911, Acc: 0.8497, Speed: 114.8k, Time: 72.2065
Epoch: 237, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3913, Acc: 0.8497, Speed: 114.5k, Time: 84.2802
Epoch: 237, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3911, Acc: 0.8496, Speed: 114.5k, Time: 96.1631
Epoch: 237, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/206.17, Loss: 0.3913, Acc: 0.8495, Speed: 114.8k, Time: 107.9313
Train 0.8497
Val 0.8604
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380

skip saving model for perf <= 0.8620
Epoch: 238, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/189.75, Loss: 0.3916, Acc: 0.8500, Speed: 115.0k, Time: 11.8167
Epoch: 238, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/189.75, Loss: 0.3908, Acc: 0.8507, Speed: 117.3k, Time: 23.5856
Epoch: 238, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/208.30, Loss: 0.3905, Acc: 0.8503, Speed: 117.7k, Time: 35.4285
Epoch: 238, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/208.30, Loss: 0.3901, Acc: 0.8504, Speed: 116.7k, Time: 47.2481
Epoch: 238, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/208.30, Loss: 0.3898, Acc: 0.8504, Speed: 116.2k, Time: 59.0924
Epoch: 238, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/208.30, Loss: 0.3909, Acc: 0.8499, Speed: 116.7k, Time: 70.6851
Epoch: 238, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/208.30, Loss: 0.3902, Acc: 0.8502, Speed: 116.3k, Time: 82.6675
Epoch: 238, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/208.30, Loss: 0.3898, Acc: 0.8502, Speed: 116.2k, Time: 94.6855
Epoch: 238, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/218.54, Loss: 0.3900, Acc: 0.8501, Speed: 115.7k, Time: 106.9439
Train 0.8501
Val 0.8619
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904

skip saving model for perf <= 0.8620
Epoch: 239, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/171.00, Loss: 0.3923, Acc: 0.8485, Speed: 113.8k, Time: 12.1707
Epoch: 239, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/171.00, Loss: 0.3915, Acc: 0.8486, Speed: 113.9k, Time: 24.3748
Epoch: 239, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/171.89, Loss: 0.3916, Acc: 0.8485, Speed: 113.0k, Time: 36.7002
Epoch: 239, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/198.11, Loss: 0.3912, Acc: 0.8490, Speed: 113.0k, Time: 48.8705
Epoch: 239, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/198.11, Loss: 0.3913, Acc: 0.8488, Speed: 113.0k, Time: 61.1654
Epoch: 239, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/198.11, Loss: 0.3910, Acc: 0.8491, Speed: 112.6k, Time: 73.4713
Epoch: 239, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/198.11, Loss: 0.3910, Acc: 0.8492, Speed: 112.5k, Time: 85.7169
Epoch: 239, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/198.11, Loss: 0.3908, Acc: 0.8494, Speed: 112.5k, Time: 97.9431
Epoch: 239, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/211.72, Loss: 0.3910, Acc: 0.8492, Speed: 112.5k, Time: 110.2225
Train 0.8495
Val 0.8606
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583

skip saving model for perf <= 0.8620
Epoch: 240, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/190.82, Loss: 0.3892, Acc: 0.8522, Speed: 117.3k, Time: 11.9049
Epoch: 240, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/191.44, Loss: 0.3889, Acc: 0.8513, Speed: 116.9k, Time: 23.7431
Epoch: 240, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/191.44, Loss: 0.3891, Acc: 0.8508, Speed: 114.9k, Time: 35.9131
Epoch: 240, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/191.44, Loss: 0.3886, Acc: 0.8511, Speed: 114.4k, Time: 48.1097
Epoch: 240, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/199.34, Loss: 0.3890, Acc: 0.8507, Speed: 113.5k, Time: 60.5076
Epoch: 240, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/199.34, Loss: 0.3896, Acc: 0.8502, Speed: 113.5k, Time: 72.7501
Epoch: 240, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/199.34, Loss: 0.3897, Acc: 0.8502, Speed: 113.5k, Time: 85.0175
Epoch: 240, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/199.34, Loss: 0.3901, Acc: 0.8500, Speed: 113.4k, Time: 97.2387
Epoch: 240, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/199.34, Loss: 0.3895, Acc: 0.8503, Speed: 113.4k, Time: 109.4022
Train 0.8503
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177

skip saving model for perf <= 0.8620
Epoch: 241, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/184.57, Loss: 0.3869, Acc: 0.8511, Speed: 113.4k, Time: 12.2268
Epoch: 241, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/190.85, Loss: 0.3877, Acc: 0.8507, Speed: 111.4k, Time: 24.4850
Epoch: 241, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/190.85, Loss: 0.3891, Acc: 0.8500, Speed: 111.6k, Time: 36.7246
Epoch: 241, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/190.85, Loss: 0.3900, Acc: 0.8497, Speed: 111.8k, Time: 48.9093
Epoch: 241, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/198.21, Loss: 0.3910, Acc: 0.8490, Speed: 112.1k, Time: 61.2026
Epoch: 241, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/207.02, Loss: 0.3906, Acc: 0.8492, Speed: 112.7k, Time: 73.0817
Epoch: 241, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/218.06, Loss: 0.3906, Acc: 0.8492, Speed: 113.2k, Time: 84.9827
Epoch: 241, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/218.06, Loss: 0.3904, Acc: 0.8493, Speed: 113.4k, Time: 97.2346
Epoch: 241, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/218.06, Loss: 0.3910, Acc: 0.8492, Speed: 113.4k, Time: 109.4377
Train 0.8493
Val 0.8601
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075

skip saving model for perf <= 0.8620
Epoch: 242, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/184.09, Loss: 0.3892, Acc: 0.8506, Speed: 112.9k, Time: 12.2604
Epoch: 242, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/184.09, Loss: 0.3913, Acc: 0.8486, Speed: 112.4k, Time: 24.5056
Epoch: 242, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/184.09, Loss: 0.3911, Acc: 0.8484, Speed: 113.1k, Time: 36.7897
Epoch: 242, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/198.67, Loss: 0.3903, Acc: 0.8487, Speed: 112.5k, Time: 49.0743
Epoch: 242, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/198.67, Loss: 0.3901, Acc: 0.8490, Speed: 112.4k, Time: 61.3248
Epoch: 242, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/198.67, Loss: 0.3907, Acc: 0.8490, Speed: 112.6k, Time: 73.5568
Epoch: 242, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/198.67, Loss: 0.3911, Acc: 0.8489, Speed: 112.4k, Time: 85.7490
Epoch: 242, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/204.04, Loss: 0.3903, Acc: 0.8492, Speed: 112.4k, Time: 97.9534
Epoch: 242, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/204.04, Loss: 0.3903, Acc: 0.8492, Speed: 112.4k, Time: 110.2298
Train 0.8494
Val 0.8593
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262

skip saving model for perf <= 0.8620
Epoch: 243, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/185.02, Loss: 0.3922, Acc: 0.8479, Speed: 116.2k, Time: 11.7384
Epoch: 243, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/238.14, Loss: 0.3900, Acc: 0.8495, Speed: 115.8k, Time: 23.6314
Epoch: 243, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/238.14, Loss: 0.3879, Acc: 0.8507, Speed: 113.9k, Time: 35.9505
Epoch: 243, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/238.14, Loss: 0.3894, Acc: 0.8502, Speed: 114.0k, Time: 48.1473
Epoch: 243, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/238.14, Loss: 0.3902, Acc: 0.8500, Speed: 114.0k, Time: 60.3979
Epoch: 243, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/238.14, Loss: 0.3916, Acc: 0.8492, Speed: 114.0k, Time: 72.5317
Epoch: 243, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/260.71, Loss: 0.3913, Acc: 0.8492, Speed: 113.7k, Time: 84.7851
Epoch: 243, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/260.71, Loss: 0.3913, Acc: 0.8492, Speed: 113.6k, Time: 97.0152
Epoch: 243, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/260.71, Loss: 0.3916, Acc: 0.8490, Speed: 113.5k, Time: 109.3031
Train 0.8489
Val 0.8609
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888

skip saving model for perf <= 0.8620
Epoch: 244, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/175.48, Loss: 0.3924, Acc: 0.8493, Speed: 112.8k, Time: 12.3127
Epoch: 244, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/189.27, Loss: 0.3906, Acc: 0.8501, Speed: 112.5k, Time: 24.4463
Epoch: 244, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/205.25, Loss: 0.3895, Acc: 0.8504, Speed: 112.8k, Time: 36.6799
Epoch: 244, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/205.25, Loss: 0.3902, Acc: 0.8502, Speed: 112.7k, Time: 48.9566
Epoch: 244, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/251.92, Loss: 0.3917, Acc: 0.8493, Speed: 112.8k, Time: 61.2024
Epoch: 244, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/251.92, Loss: 0.3921, Acc: 0.8488, Speed: 113.4k, Time: 73.0616
Epoch: 244, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/251.92, Loss: 0.3922, Acc: 0.8487, Speed: 114.2k, Time: 84.9220
Epoch: 244, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/251.92, Loss: 0.3921, Acc: 0.8487, Speed: 113.7k, Time: 97.2252
Epoch: 244, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/251.92, Loss: 0.3926, Acc: 0.8485, Speed: 113.6k, Time: 109.4459
Train 0.8484
Val 0.8573
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332

skip saving model for perf <= 0.8620
Epoch: 245, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/203.40, Loss: 0.3964, Acc: 0.8465, Speed: 110.9k, Time: 12.2226
Epoch: 245, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3941, Acc: 0.8479, Speed: 112.3k, Time: 24.4889
Epoch: 245, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3946, Acc: 0.8478, Speed: 112.4k, Time: 36.7137
Epoch: 245, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3939, Acc: 0.8481, Speed: 112.5k, Time: 48.9374
Epoch: 245, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3927, Acc: 0.8488, Speed: 112.9k, Time: 61.1654
Epoch: 245, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3921, Acc: 0.8491, Speed: 112.9k, Time: 73.3821
Epoch: 245, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3920, Acc: 0.8491, Speed: 112.9k, Time: 85.6111
Epoch: 245, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3919, Acc: 0.8492, Speed: 113.0k, Time: 97.7406
Epoch: 245, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/256.37, Loss: 0.3916, Acc: 0.8492, Speed: 112.8k, Time: 110.0643
Train 0.8493
Val 0.8595
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466

skip saving model for perf <= 0.8620
Epoch: 246, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/180.51, Loss: 0.3876, Acc: 0.8512, Speed: 112.4k, Time: 11.9865
Epoch: 246, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/213.56, Loss: 0.3900, Acc: 0.8503, Speed: 115.4k, Time: 23.8105
Epoch: 246, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/213.56, Loss: 0.3884, Acc: 0.8506, Speed: 113.2k, Time: 36.0910
Epoch: 246, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/213.56, Loss: 0.3893, Acc: 0.8505, Speed: 113.3k, Time: 48.4829
Epoch: 246, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/213.56, Loss: 0.3892, Acc: 0.8504, Speed: 113.3k, Time: 60.7595
Epoch: 246, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/229.78, Loss: 0.3885, Acc: 0.8507, Speed: 112.7k, Time: 73.1176
Epoch: 246, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/229.78, Loss: 0.3887, Acc: 0.8504, Speed: 112.7k, Time: 85.3987
Epoch: 246, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/229.78, Loss: 0.3892, Acc: 0.8503, Speed: 112.9k, Time: 97.6849
Epoch: 246, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/229.78, Loss: 0.3895, Acc: 0.8502, Speed: 113.0k, Time: 109.9232
Train 0.8501
Val 0.8594
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364

skip saving model for perf <= 0.8620
Epoch: 247, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/176.85, Loss: 0.3904, Acc: 0.8501, Speed: 112.9k, Time: 12.2093
Epoch: 247, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3927, Acc: 0.8494, Speed: 112.6k, Time: 24.4118
Epoch: 247, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3929, Acc: 0.8490, Speed: 112.6k, Time: 36.5902
Epoch: 247, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3916, Acc: 0.8495, Speed: 113.3k, Time: 48.7687
Epoch: 247, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3897, Acc: 0.8504, Speed: 113.4k, Time: 60.5401
Epoch: 247, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3894, Acc: 0.8504, Speed: 114.0k, Time: 72.3670
Epoch: 247, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3900, Acc: 0.8503, Speed: 113.8k, Time: 84.6083
Epoch: 247, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3903, Acc: 0.8501, Speed: 113.8k, Time: 96.8900
Epoch: 247, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/237.29, Loss: 0.3905, Acc: 0.8501, Speed: 113.7k, Time: 109.0505
Train 0.8500
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177

skip saving model for perf <= 0.8620
Epoch: 248, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/213.45, Loss: 0.3937, Acc: 0.8477, Speed: 112.2k, Time: 12.2296
Epoch: 248, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/232.41, Loss: 0.3886, Acc: 0.8509, Speed: 112.6k, Time: 24.4667
Epoch: 248, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/232.41, Loss: 0.3899, Acc: 0.8496, Speed: 112.5k, Time: 36.6983
Epoch: 248, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/232.41, Loss: 0.3900, Acc: 0.8496, Speed: 112.6k, Time: 48.8790
Epoch: 248, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/244.12, Loss: 0.3903, Acc: 0.8496, Speed: 112.2k, Time: 61.2136
Epoch: 248, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/244.12, Loss: 0.3903, Acc: 0.8497, Speed: 112.2k, Time: 73.3479
Epoch: 248, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/244.12, Loss: 0.3898, Acc: 0.8500, Speed: 112.2k, Time: 85.6035
Epoch: 248, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/244.12, Loss: 0.3899, Acc: 0.8501, Speed: 112.2k, Time: 97.8131
Epoch: 248, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/244.12, Loss: 0.3900, Acc: 0.8499, Speed: 112.3k, Time: 110.0814
Train 0.8498
Val 0.8618
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803

skip saving model for perf <= 0.8620
Epoch: 249, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/165.43, Loss: 0.3907, Acc: 0.8510, Speed: 117.9k, Time: 11.8031
Epoch: 249, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/192.67, Loss: 0.3911, Acc: 0.8507, Speed: 114.8k, Time: 23.9886
Epoch: 249, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/192.67, Loss: 0.3916, Acc: 0.8501, Speed: 114.5k, Time: 36.1913
Epoch: 249, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/192.67, Loss: 0.3917, Acc: 0.8499, Speed: 114.0k, Time: 48.3454
Epoch: 249, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/197.67, Loss: 0.3904, Acc: 0.8504, Speed: 113.4k, Time: 60.5146
Epoch: 249, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.67, Loss: 0.3903, Acc: 0.8503, Speed: 113.8k, Time: 72.7122
Epoch: 249, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/197.67, Loss: 0.3904, Acc: 0.8503, Speed: 113.5k, Time: 84.9421
Epoch: 249, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/198.95, Loss: 0.3907, Acc: 0.8501, Speed: 113.6k, Time: 97.1536
Epoch: 249, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/198.95, Loss: 0.3908, Acc: 0.8499, Speed: 113.4k, Time: 109.4275
Train 0.8499
Val 0.8596
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567

skip saving model for perf <= 0.8620
Epoch: 250, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3886, Acc: 0.8500, Speed: 111.7k, Time: 12.2422
Epoch: 250, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3908, Acc: 0.8493, Speed: 114.0k, Time: 24.4496
Epoch: 250, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3887, Acc: 0.8507, Speed: 113.5k, Time: 36.7037
Epoch: 250, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3891, Acc: 0.8504, Speed: 113.4k, Time: 48.9445
Epoch: 250, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3899, Acc: 0.8500, Speed: 114.1k, Time: 60.8772
Epoch: 250, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3900, Acc: 0.8500, Speed: 114.2k, Time: 72.8250
Epoch: 250, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3910, Acc: 0.8499, Speed: 114.1k, Time: 84.9648
Epoch: 250, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3912, Acc: 0.8498, Speed: 113.9k, Time: 97.2438
Epoch: 250, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/266.30, Loss: 0.3915, Acc: 0.8496, Speed: 113.6k, Time: 109.3742
Train 0.8497
Val 0.8600
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974

skip saving model for perf <= 0.8620
Epoch: 251, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/195.44, Loss: 0.3880, Acc: 0.8509, Speed: 112.9k, Time: 12.2101
Epoch: 251, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3875, Acc: 0.8507, Speed: 113.3k, Time: 24.3547
Epoch: 251, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3899, Acc: 0.8500, Speed: 112.2k, Time: 36.6841
Epoch: 251, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3902, Acc: 0.8501, Speed: 112.2k, Time: 48.9903
Epoch: 251, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3911, Acc: 0.8497, Speed: 111.9k, Time: 61.2903
Epoch: 251, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3911, Acc: 0.8497, Speed: 111.9k, Time: 73.5049
Epoch: 251, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3913, Acc: 0.8496, Speed: 112.1k, Time: 85.6747
Epoch: 251, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3912, Acc: 0.8496, Speed: 112.3k, Time: 97.8616
Epoch: 251, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/206.77, Loss: 0.3908, Acc: 0.8497, Speed: 112.4k, Time: 110.1040
Train 0.8499
Val 0.8606
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583

skip saving model for perf <= 0.8620
Epoch: 252, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/206.71, Loss: 0.3880, Acc: 0.8527, Speed: 116.5k, Time: 11.8265
Epoch: 252, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/206.71, Loss: 0.3920, Acc: 0.8504, Speed: 114.4k, Time: 24.0490
Epoch: 252, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/206.71, Loss: 0.3915, Acc: 0.8500, Speed: 113.7k, Time: 36.3244
Epoch: 252, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/206.71, Loss: 0.3905, Acc: 0.8507, Speed: 113.7k, Time: 48.5516
Epoch: 252, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/214.71, Loss: 0.3910, Acc: 0.8504, Speed: 113.3k, Time: 60.7699
Epoch: 252, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/214.71, Loss: 0.3914, Acc: 0.8500, Speed: 113.6k, Time: 72.9461
Epoch: 252, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/214.71, Loss: 0.3908, Acc: 0.8501, Speed: 113.3k, Time: 85.2084
Epoch: 252, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/218.71, Loss: 0.3905, Acc: 0.8500, Speed: 113.0k, Time: 97.4410
Epoch: 252, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/218.71, Loss: 0.3898, Acc: 0.8502, Speed: 112.9k, Time: 109.7344
Train 0.8501
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177

skip saving model for perf <= 0.8620
Epoch: 253, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/179.71, Loss: 0.3915, Acc: 0.8476, Speed: 109.3k, Time: 12.2245
Epoch: 253, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/179.71, Loss: 0.3897, Acc: 0.8492, Speed: 111.8k, Time: 24.4202
Epoch: 253, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/179.71, Loss: 0.3890, Acc: 0.8499, Speed: 112.3k, Time: 36.5466
Epoch: 253, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/179.71, Loss: 0.3894, Acc: 0.8498, Speed: 112.7k, Time: 48.7286
Epoch: 253, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/179.71, Loss: 0.3887, Acc: 0.8501, Speed: 113.8k, Time: 60.5831
Epoch: 253, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/180.80, Loss: 0.3891, Acc: 0.8498, Speed: 114.0k, Time: 72.4620
Epoch: 253, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/207.61, Loss: 0.3900, Acc: 0.8495, Speed: 114.1k, Time: 84.6693
Epoch: 253, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/207.61, Loss: 0.3906, Acc: 0.8494, Speed: 114.1k, Time: 96.8619
Epoch: 253, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/207.61, Loss: 0.3904, Acc: 0.8495, Speed: 113.7k, Time: 109.1764
Train 0.8497
Val 0.8605
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482

skip saving model for perf <= 0.8620
Epoch: 254, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/166.51, Loss: 0.3929, Acc: 0.8493, Speed: 113.9k, Time: 12.2204
Epoch: 254, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/192.58, Loss: 0.3890, Acc: 0.8503, Speed: 112.9k, Time: 24.4587
Epoch: 254, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/227.97, Loss: 0.3891, Acc: 0.8498, Speed: 112.8k, Time: 36.6854
Epoch: 254, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/227.97, Loss: 0.3890, Acc: 0.8501, Speed: 113.2k, Time: 48.9634
Epoch: 254, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/227.97, Loss: 0.3883, Acc: 0.8501, Speed: 112.8k, Time: 61.1084
Epoch: 254, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/227.97, Loss: 0.3889, Acc: 0.8500, Speed: 112.7k, Time: 73.3705
Epoch: 254, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/227.97, Loss: 0.3891, Acc: 0.8500, Speed: 112.5k, Time: 85.5987
Epoch: 254, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/241.81, Loss: 0.3895, Acc: 0.8498, Speed: 112.8k, Time: 97.8026
Epoch: 254, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/241.81, Loss: 0.3896, Acc: 0.8499, Speed: 113.0k, Time: 109.6542
Train 0.8497
Val 0.8606
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583

skip saving model for perf <= 0.8620
Epoch: 255, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/178.59, Loss: 0.3917, Acc: 0.8500, Speed: 115.8k, Time: 11.8729
Epoch: 255, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/178.59, Loss: 0.3905, Acc: 0.8495, Speed: 115.0k, Time: 24.1071
Epoch: 255, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/217.29, Loss: 0.3925, Acc: 0.8482, Speed: 114.2k, Time: 36.2970
Epoch: 255, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/220.80, Loss: 0.3917, Acc: 0.8484, Speed: 113.2k, Time: 48.5363
Epoch: 255, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/220.80, Loss: 0.3921, Acc: 0.8484, Speed: 113.5k, Time: 60.6680
Epoch: 255, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/221.96, Loss: 0.3914, Acc: 0.8490, Speed: 113.3k, Time: 72.9584
Epoch: 255, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/221.96, Loss: 0.3918, Acc: 0.8489, Speed: 113.4k, Time: 85.1813
Epoch: 255, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/221.96, Loss: 0.3919, Acc: 0.8491, Speed: 113.3k, Time: 97.3719
Epoch: 255, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/221.96, Loss: 0.3916, Acc: 0.8494, Speed: 113.4k, Time: 109.5846
Train 0.8497
Val 0.8608
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787

skip saving model for perf <= 0.8620
Epoch: 256, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3899, Acc: 0.8498, Speed: 113.2k, Time: 12.2767
Epoch: 256, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3889, Acc: 0.8498, Speed: 111.9k, Time: 24.4960
Epoch: 256, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3887, Acc: 0.8506, Speed: 113.1k, Time: 36.4958
Epoch: 256, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3883, Acc: 0.8508, Speed: 115.3k, Time: 47.9497
Epoch: 256, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3875, Acc: 0.8510, Speed: 115.5k, Time: 59.6286
Epoch: 256, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3878, Acc: 0.8507, Speed: 115.7k, Time: 71.5375
Epoch: 256, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3879, Acc: 0.8509, Speed: 115.4k, Time: 83.5689
Epoch: 256, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3882, Acc: 0.8508, Speed: 115.4k, Time: 95.6530
Epoch: 256, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/241.06, Loss: 0.3886, Acc: 0.8505, Speed: 115.3k, Time: 107.6170
Train 0.8500
Val 0.8613
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295

skip saving model for perf <= 0.8620
Epoch: 257, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/192.23, Loss: 0.3880, Acc: 0.8511, Speed: 114.3k, Time: 12.0301
Epoch: 257, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/201.83, Loss: 0.3876, Acc: 0.8509, Speed: 113.1k, Time: 24.0439
Epoch: 257, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/216.67, Loss: 0.3893, Acc: 0.8500, Speed: 114.2k, Time: 36.1297
Epoch: 257, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/216.67, Loss: 0.3891, Acc: 0.8502, Speed: 114.8k, Time: 48.1308
Epoch: 257, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/216.67, Loss: 0.3892, Acc: 0.8502, Speed: 114.5k, Time: 60.1762
Epoch: 257, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.67, Loss: 0.3893, Acc: 0.8501, Speed: 114.2k, Time: 72.2658
Epoch: 257, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.67, Loss: 0.3899, Acc: 0.8499, Speed: 114.4k, Time: 84.3029
Epoch: 257, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.67, Loss: 0.3904, Acc: 0.8497, Speed: 114.6k, Time: 96.2538
Epoch: 257, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.67, Loss: 0.3901, Acc: 0.8500, Speed: 114.8k, Time: 108.1021
Train 0.8499
Val 0.8592
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161

skip saving model for perf <= 0.8620
Epoch: 258, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.47, Loss: 0.3935, Acc: 0.8484, Speed: 120.2k, Time: 11.7012
Epoch: 258, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3911, Acc: 0.8504, Speed: 118.4k, Time: 23.7669
Epoch: 258, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3923, Acc: 0.8498, Speed: 116.0k, Time: 35.8204
Epoch: 258, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3920, Acc: 0.8498, Speed: 115.9k, Time: 47.9866
Epoch: 258, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3905, Acc: 0.8499, Speed: 115.5k, Time: 60.0858
Epoch: 258, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3902, Acc: 0.8503, Speed: 115.0k, Time: 72.0981
Epoch: 258, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3905, Acc: 0.8501, Speed: 114.6k, Time: 84.1017
Epoch: 258, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3902, Acc: 0.8501, Speed: 114.3k, Time: 96.2057
Epoch: 258, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/204.44, Loss: 0.3898, Acc: 0.8502, Speed: 114.6k, Time: 108.1340
Train 0.8502
Val 0.8613
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295

skip saving model for perf <= 0.8620
Epoch: 259, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/188.30, Loss: 0.3865, Acc: 0.8516, Speed: 112.9k, Time: 12.0962
Epoch: 259, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/188.30, Loss: 0.3866, Acc: 0.8518, Speed: 114.1k, Time: 24.1091
Epoch: 259, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/191.92, Loss: 0.3876, Acc: 0.8508, Speed: 114.1k, Time: 36.3016
Epoch: 259, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/215.74, Loss: 0.3884, Acc: 0.8508, Speed: 114.3k, Time: 48.4226
Epoch: 259, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/215.74, Loss: 0.3880, Acc: 0.8508, Speed: 115.2k, Time: 60.1429
Epoch: 259, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/215.74, Loss: 0.3878, Acc: 0.8510, Speed: 114.9k, Time: 71.8920
Epoch: 259, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/215.74, Loss: 0.3889, Acc: 0.8507, Speed: 115.0k, Time: 83.8491
Epoch: 259, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/215.74, Loss: 0.3892, Acc: 0.8505, Speed: 114.9k, Time: 95.9644
Epoch: 259, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/215.74, Loss: 0.3890, Acc: 0.8505, Speed: 114.6k, Time: 108.0532
Train 0.8506
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177

skip saving model for perf <= 0.8620
Epoch: 260, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/206.99, Loss: 0.3898, Acc: 0.8511, Speed: 116.1k, Time: 12.1018
Epoch: 260, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/228.69, Loss: 0.3880, Acc: 0.8511, Speed: 114.6k, Time: 24.1468
Epoch: 260, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/228.69, Loss: 0.3868, Acc: 0.8514, Speed: 113.8k, Time: 36.1821
Epoch: 260, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/228.69, Loss: 0.3871, Acc: 0.8511, Speed: 113.6k, Time: 48.2711
Epoch: 260, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/228.69, Loss: 0.3876, Acc: 0.8508, Speed: 113.9k, Time: 60.2507
Epoch: 260, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/228.69, Loss: 0.3885, Acc: 0.8504, Speed: 114.6k, Time: 72.2649
Epoch: 260, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/228.69, Loss: 0.3882, Acc: 0.8507, Speed: 114.6k, Time: 84.3480
Epoch: 260, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/228.69, Loss: 0.3885, Acc: 0.8507, Speed: 114.5k, Time: 96.5625
Epoch: 260, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/270.50, Loss: 0.3881, Acc: 0.8508, Speed: 114.4k, Time: 108.5252
Train 0.8507
Val 0.8597
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669

skip saving model for perf <= 0.8620
Epoch: 261, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.03, Loss: 0.3818, Acc: 0.8530, Speed: 116.3k, Time: 11.8100
Epoch: 261, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3866, Acc: 0.8508, Speed: 113.8k, Time: 24.0299
Epoch: 261, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3881, Acc: 0.8508, Speed: 113.4k, Time: 36.1382
Epoch: 261, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3880, Acc: 0.8508, Speed: 113.9k, Time: 48.1825
Epoch: 261, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3871, Acc: 0.8512, Speed: 114.1k, Time: 60.2414
Epoch: 261, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3871, Acc: 0.8513, Speed: 114.5k, Time: 72.2441
Epoch: 261, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3876, Acc: 0.8511, Speed: 114.3k, Time: 84.3363
Epoch: 261, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3880, Acc: 0.8509, Speed: 114.6k, Time: 96.3758
Epoch: 261, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/216.08, Loss: 0.3885, Acc: 0.8507, Speed: 114.6k, Time: 108.3699
Train 0.8507
Val 0.8596
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567

skip saving model for perf <= 0.8620
Epoch: 262, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/181.62, Loss: 0.3925, Acc: 0.8486, Speed: 114.6k, Time: 12.0863
Epoch: 262, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/191.37, Loss: 0.3930, Acc: 0.8485, Speed: 113.5k, Time: 24.1540
Epoch: 262, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/211.29, Loss: 0.3905, Acc: 0.8497, Speed: 114.9k, Time: 36.1127
Epoch: 262, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/211.29, Loss: 0.3879, Acc: 0.8509, Speed: 114.2k, Time: 48.1616
Epoch: 262, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/243.60, Loss: 0.3870, Acc: 0.8513, Speed: 115.8k, Time: 59.8246
Epoch: 262, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/243.60, Loss: 0.3873, Acc: 0.8510, Speed: 115.9k, Time: 71.5527
Epoch: 262, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/258.75, Loss: 0.3887, Acc: 0.8505, Speed: 115.7k, Time: 83.5635
Epoch: 262, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/258.75, Loss: 0.3886, Acc: 0.8504, Speed: 115.5k, Time: 95.7399
Epoch: 262, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/258.75, Loss: 0.3884, Acc: 0.8503, Speed: 115.2k, Time: 107.6940
Train 0.8503
Val 0.8594
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364

skip saving model for perf <= 0.8620
Epoch: 263, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/186.88, Loss: 0.3829, Acc: 0.8532, Speed: 114.5k, Time: 12.1139
Epoch: 263, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/202.26, Loss: 0.3886, Acc: 0.8502, Speed: 114.0k, Time: 24.1546
Epoch: 263, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/202.26, Loss: 0.3887, Acc: 0.8509, Speed: 114.7k, Time: 36.2227
Epoch: 263, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/202.26, Loss: 0.3899, Acc: 0.8501, Speed: 114.1k, Time: 48.3491
Epoch: 263, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/202.26, Loss: 0.3898, Acc: 0.8499, Speed: 114.1k, Time: 60.3779
Epoch: 263, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/208.07, Loss: 0.3895, Acc: 0.8499, Speed: 114.1k, Time: 72.4755
Epoch: 263, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/208.07, Loss: 0.3896, Acc: 0.8498, Speed: 114.3k, Time: 84.4964
Epoch: 263, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/208.07, Loss: 0.3902, Acc: 0.8497, Speed: 114.4k, Time: 96.4688
Epoch: 263, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/208.07, Loss: 0.3904, Acc: 0.8498, Speed: 114.2k, Time: 108.5938
Train 0.8500
Val 0.8606
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583

skip saving model for perf <= 0.8620
Epoch: 264, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/190.92, Loss: 0.3890, Acc: 0.8512, Speed: 118.9k, Time: 11.7345
Epoch: 264, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/190.92, Loss: 0.3882, Acc: 0.8514, Speed: 116.1k, Time: 23.8029
Epoch: 264, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/190.92, Loss: 0.3890, Acc: 0.8505, Speed: 114.8k, Time: 35.8259
Epoch: 264, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/190.92, Loss: 0.3874, Acc: 0.8513, Speed: 114.3k, Time: 47.9215
Epoch: 264, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/196.46, Loss: 0.3883, Acc: 0.8507, Speed: 114.1k, Time: 59.9722
Epoch: 264, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/196.46, Loss: 0.3885, Acc: 0.8508, Speed: 114.2k, Time: 72.0783
Epoch: 264, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/196.46, Loss: 0.3880, Acc: 0.8508, Speed: 114.1k, Time: 84.2501
Epoch: 264, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/203.58, Loss: 0.3886, Acc: 0.8506, Speed: 114.4k, Time: 96.3160
Epoch: 264, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/203.58, Loss: 0.3888, Acc: 0.8505, Speed: 114.3k, Time: 108.3865
Train 0.8506
Val 0.8603
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278

skip saving model for perf <= 0.8620
Epoch: 265, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/167.67, Loss: 0.3846, Acc: 0.8521, Speed: 114.0k, Time: 12.1173
Epoch: 265, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/167.67, Loss: 0.3849, Acc: 0.8523, Speed: 112.7k, Time: 24.1008
Epoch: 265, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/211.61, Loss: 0.3845, Acc: 0.8524, Speed: 113.2k, Time: 36.1312
Epoch: 265, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/211.61, Loss: 0.3855, Acc: 0.8515, Speed: 113.4k, Time: 48.1910
Epoch: 265, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/211.61, Loss: 0.3855, Acc: 0.8514, Speed: 114.7k, Time: 59.8250
Epoch: 265, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/211.61, Loss: 0.3856, Acc: 0.8514, Speed: 115.3k, Time: 71.5058
Epoch: 265, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/251.13, Loss: 0.3862, Acc: 0.8514, Speed: 115.0k, Time: 83.5632
Epoch: 265, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/251.13, Loss: 0.3871, Acc: 0.8511, Speed: 115.1k, Time: 95.7061
Epoch: 265, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/251.13, Loss: 0.3876, Acc: 0.8510, Speed: 114.9k, Time: 107.7550
Train 0.8507
Val 0.8610
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990

skip saving model for perf <= 0.8620
Epoch: 266, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.45, Loss: 0.3857, Acc: 0.8516, Speed: 113.6k, Time: 12.1032
Epoch: 266, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3852, Acc: 0.8514, Speed: 113.6k, Time: 24.2490
Epoch: 266, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3846, Acc: 0.8525, Speed: 113.7k, Time: 36.3492
Epoch: 266, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3849, Acc: 0.8519, Speed: 113.5k, Time: 48.4262
Epoch: 266, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3855, Acc: 0.8520, Speed: 113.7k, Time: 60.4475
Epoch: 266, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3870, Acc: 0.8515, Speed: 113.9k, Time: 72.4910
Epoch: 266, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3878, Acc: 0.8510, Speed: 114.2k, Time: 84.4820
Epoch: 266, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3880, Acc: 0.8508, Speed: 114.2k, Time: 96.5687
Epoch: 266, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/212.07, Loss: 0.3882, Acc: 0.8508, Speed: 114.1k, Time: 108.7080
Train 0.8507
Val 0.8609
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888

skip saving model for perf <= 0.8620
Epoch: 267, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.31, Loss: 0.3796, Acc: 0.8531, Speed: 118.6k, Time: 11.7523
Epoch: 267, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/197.31, Loss: 0.3816, Acc: 0.8528, Speed: 117.0k, Time: 23.7704
Epoch: 267, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/197.31, Loss: 0.3836, Acc: 0.8520, Speed: 116.3k, Time: 35.8616
Epoch: 267, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.31, Loss: 0.3851, Acc: 0.8512, Speed: 115.8k, Time: 47.8390
Epoch: 267, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/197.67, Loss: 0.3860, Acc: 0.8509, Speed: 115.7k, Time: 59.8160
Epoch: 267, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.67, Loss: 0.3857, Acc: 0.8510, Speed: 115.9k, Time: 71.8133
Epoch: 267, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/197.67, Loss: 0.3863, Acc: 0.8507, Speed: 115.8k, Time: 83.7527
Epoch: 267, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/197.67, Loss: 0.3866, Acc: 0.8507, Speed: 115.5k, Time: 95.8553
Epoch: 267, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/210.08, Loss: 0.3871, Acc: 0.8506, Speed: 115.1k, Time: 107.9233
Train 0.8506
Val 0.8599
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872

skip saving model for perf <= 0.8620
Epoch: 268, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/166.66, Loss: 0.3849, Acc: 0.8510, Speed: 112.1k, Time: 12.1576
Epoch: 268, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/199.06, Loss: 0.3834, Acc: 0.8521, Speed: 113.0k, Time: 24.3610
Epoch: 268, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/199.06, Loss: 0.3830, Acc: 0.8522, Speed: 112.9k, Time: 36.3797
Epoch: 268, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/199.06, Loss: 0.3856, Acc: 0.8515, Speed: 113.2k, Time: 48.4461
Epoch: 268, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/199.06, Loss: 0.3846, Acc: 0.8520, Speed: 114.3k, Time: 60.0820
Epoch: 268, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/200.67, Loss: 0.3839, Acc: 0.8521, Speed: 114.8k, Time: 71.7222
Epoch: 268, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/204.04, Loss: 0.3850, Acc: 0.8518, Speed: 114.8k, Time: 83.7669
Epoch: 268, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/228.97, Loss: 0.3855, Acc: 0.8515, Speed: 115.0k, Time: 95.7746
Epoch: 268, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/228.97, Loss: 0.3866, Acc: 0.8513, Speed: 115.1k, Time: 107.7495
Train 0.8511
Val 0.8590
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957

skip saving model for perf <= 0.8620
Epoch: 269, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/162.90, Loss: 0.3847, Acc: 0.8518, Speed: 115.8k, Time: 12.0694
Epoch: 269, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/223.62, Loss: 0.3909, Acc: 0.8503, Speed: 114.9k, Time: 24.2039
Epoch: 269, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/223.62, Loss: 0.3908, Acc: 0.8502, Speed: 114.3k, Time: 36.2281
Epoch: 269, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/223.62, Loss: 0.3909, Acc: 0.8503, Speed: 114.2k, Time: 48.2984
Epoch: 269, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/233.71, Loss: 0.3898, Acc: 0.8505, Speed: 114.3k, Time: 60.3231
Epoch: 269, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/233.71, Loss: 0.3902, Acc: 0.8503, Speed: 114.3k, Time: 72.4487
Epoch: 269, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/233.71, Loss: 0.3895, Acc: 0.8507, Speed: 114.3k, Time: 84.5427
Epoch: 269, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/233.71, Loss: 0.3896, Acc: 0.8506, Speed: 114.0k, Time: 96.7248
Epoch: 269, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/233.71, Loss: 0.3894, Acc: 0.8505, Speed: 114.0k, Time: 108.8079
Train 0.8506
Val 0.8596
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567

skip saving model for perf <= 0.8620
Epoch: 270, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/202.91, Loss: 0.3855, Acc: 0.8525, Speed: 116.7k, Time: 11.6977
Epoch: 270, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/207.83, Loss: 0.3890, Acc: 0.8505, Speed: 115.3k, Time: 23.7569
Epoch: 270, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/207.83, Loss: 0.3904, Acc: 0.8499, Speed: 115.1k, Time: 35.8214
Epoch: 270, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/243.05, Loss: 0.3896, Acc: 0.8504, Speed: 115.1k, Time: 47.9171
Epoch: 270, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/243.05, Loss: 0.3882, Acc: 0.8508, Speed: 114.8k, Time: 60.0006
Epoch: 270, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/243.05, Loss: 0.3877, Acc: 0.8512, Speed: 114.9k, Time: 72.0288
Epoch: 270, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/243.05, Loss: 0.3873, Acc: 0.8513, Speed: 115.0k, Time: 84.0642
Epoch: 270, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/243.05, Loss: 0.3876, Acc: 0.8511, Speed: 115.1k, Time: 96.1374
Epoch: 270, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/243.05, Loss: 0.3873, Acc: 0.8512, Speed: 114.7k, Time: 108.2709
Train 0.8510
Val 0.8605
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482

skip saving model for perf <= 0.8620
Epoch: 271, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/175.12, Loss: 0.3928, Acc: 0.8487, Speed: 113.3k, Time: 12.0456
Epoch: 271, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/203.13, Loss: 0.3914, Acc: 0.8493, Speed: 112.9k, Time: 24.0892
Epoch: 271, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/203.13, Loss: 0.3894, Acc: 0.8506, Speed: 112.5k, Time: 36.2185
Epoch: 271, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/209.21, Loss: 0.3884, Acc: 0.8509, Speed: 113.3k, Time: 48.2054
Epoch: 271, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/219.23, Loss: 0.3876, Acc: 0.8514, Speed: 114.1k, Time: 59.9249
Epoch: 271, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/219.23, Loss: 0.3876, Acc: 0.8514, Speed: 115.0k, Time: 71.5703
Epoch: 271, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/219.23, Loss: 0.3875, Acc: 0.8513, Speed: 115.2k, Time: 83.6511
Epoch: 271, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/219.23, Loss: 0.3884, Acc: 0.8507, Speed: 115.0k, Time: 95.7807
Epoch: 271, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/227.76, Loss: 0.3894, Acc: 0.8501, Speed: 114.9k, Time: 107.8787
Train 0.8502
Val 0.8606
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583

skip saving model for perf <= 0.8620
Epoch: 272, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/193.33, Loss: 0.3847, Acc: 0.8523, Speed: 114.7k, Time: 12.0348
Epoch: 272, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/197.29, Loss: 0.3883, Acc: 0.8508, Speed: 114.9k, Time: 24.1014
Epoch: 272, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/197.29, Loss: 0.3889, Acc: 0.8505, Speed: 114.0k, Time: 36.2195
Epoch: 272, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.29, Loss: 0.3895, Acc: 0.8504, Speed: 113.8k, Time: 48.3813
Epoch: 272, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/197.29, Loss: 0.3897, Acc: 0.8503, Speed: 114.1k, Time: 60.2927
Epoch: 272, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.29, Loss: 0.3892, Acc: 0.8504, Speed: 114.1k, Time: 72.3965
Epoch: 272, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/197.29, Loss: 0.3883, Acc: 0.8508, Speed: 114.1k, Time: 84.4571
Epoch: 272, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/197.29, Loss: 0.3874, Acc: 0.8511, Speed: 114.3k, Time: 96.4338
Epoch: 272, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/235.21, Loss: 0.3875, Acc: 0.8511, Speed: 114.3k, Time: 108.5028
Train 0.8509
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177

skip saving model for perf <= 0.8620
Epoch: 273, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/186.51, Loss: 0.3878, Acc: 0.8506, Speed: 118.0k, Time: 11.5444
Epoch: 273, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/193.48, Loss: 0.3838, Acc: 0.8532, Speed: 116.1k, Time: 23.5310
Epoch: 273, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/205.78, Loss: 0.3873, Acc: 0.8514, Speed: 115.0k, Time: 35.5990
Epoch: 273, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/205.78, Loss: 0.3876, Acc: 0.8511, Speed: 114.9k, Time: 47.6136
Epoch: 273, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/205.78, Loss: 0.3877, Acc: 0.8510, Speed: 114.5k, Time: 59.6402
Epoch: 273, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/205.78, Loss: 0.3877, Acc: 0.8509, Speed: 114.6k, Time: 71.7057
Epoch: 273, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/205.78, Loss: 0.3880, Acc: 0.8507, Speed: 114.5k, Time: 83.9032
Epoch: 273, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/212.42, Loss: 0.3880, Acc: 0.8506, Speed: 114.5k, Time: 95.9920
Epoch: 273, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/212.42, Loss: 0.3879, Acc: 0.8507, Speed: 114.8k, Time: 108.0444
Train 0.8507
Val 0.8595
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466

skip saving model for perf <= 0.8620
Epoch: 274, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/195.51, Loss: 0.3842, Acc: 0.8527, Speed: 115.3k, Time: 12.0800
Epoch: 274, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/214.26, Loss: 0.3869, Acc: 0.8504, Speed: 114.9k, Time: 24.0958
Epoch: 274, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/214.26, Loss: 0.3879, Acc: 0.8501, Speed: 114.7k, Time: 36.1752
Epoch: 274, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/214.26, Loss: 0.3888, Acc: 0.8501, Speed: 115.2k, Time: 48.1782
Epoch: 274, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/214.26, Loss: 0.3888, Acc: 0.8500, Speed: 115.2k, Time: 59.9228
Epoch: 274, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/214.26, Loss: 0.3877, Acc: 0.8505, Speed: 115.7k, Time: 71.4640
Epoch: 274, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/251.11, Loss: 0.3879, Acc: 0.8506, Speed: 115.6k, Time: 83.5943
Epoch: 274, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/251.11, Loss: 0.3885, Acc: 0.8503, Speed: 115.3k, Time: 95.6223
Epoch: 274, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/251.11, Loss: 0.3885, Acc: 0.8504, Speed: 114.8k, Time: 107.6923
Train 0.8503
Val 0.8599
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872

skip saving model for perf <= 0.8620
Epoch: 275, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/189.85, Loss: 0.3909, Acc: 0.8491, Speed: 115.5k, Time: 12.1678
Epoch: 275, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/207.93, Loss: 0.3902, Acc: 0.8494, Speed: 115.5k, Time: 24.3443
Epoch: 275, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/282.38, Loss: 0.3897, Acc: 0.8493, Speed: 114.7k, Time: 36.3938
Epoch: 275, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/282.38, Loss: 0.3885, Acc: 0.8501, Speed: 114.6k, Time: 48.4805
Epoch: 275, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/282.38, Loss: 0.3884, Acc: 0.8505, Speed: 114.4k, Time: 60.5649
Epoch: 275, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/282.38, Loss: 0.3892, Acc: 0.8502, Speed: 114.2k, Time: 72.5523
Epoch: 275, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/282.38, Loss: 0.3885, Acc: 0.8505, Speed: 114.2k, Time: 84.6323
Epoch: 275, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/282.38, Loss: 0.3878, Acc: 0.8509, Speed: 114.1k, Time: 96.6095
Epoch: 275, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/282.38, Loss: 0.3878, Acc: 0.8508, Speed: 114.2k, Time: 108.6463
Train 0.8506
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177

skip saving model for perf <= 0.8620
Epoch: 276, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/214.95, Loss: 0.3874, Acc: 0.8503, Speed: 117.1k, Time: 11.4522
Epoch: 276, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/214.95, Loss: 0.3862, Acc: 0.8510, Speed: 116.9k, Time: 23.2313
Epoch: 276, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/214.95, Loss: 0.3860, Acc: 0.8513, Speed: 115.0k, Time: 35.3186
Epoch: 276, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/215.43, Loss: 0.3870, Acc: 0.8510, Speed: 114.9k, Time: 47.4347
Epoch: 276, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/215.43, Loss: 0.3874, Acc: 0.8509, Speed: 114.6k, Time: 59.4401
Epoch: 276, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/215.43, Loss: 0.3883, Acc: 0.8506, Speed: 114.7k, Time: 71.5464
Epoch: 276, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/215.43, Loss: 0.3883, Acc: 0.8507, Speed: 114.7k, Time: 83.6173
Epoch: 276, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/215.43, Loss: 0.3881, Acc: 0.8507, Speed: 115.0k, Time: 95.6553
Epoch: 276, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/215.43, Loss: 0.3880, Acc: 0.8508, Speed: 115.1k, Time: 107.7120
Train 0.8508
Val 0.8614
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396

skip saving model for perf <= 0.8620
Epoch: 277, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/187.93, Loss: 0.3892, Acc: 0.8510, Speed: 113.8k, Time: 12.0747
Epoch: 277, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/209.23, Loss: 0.3860, Acc: 0.8520, Speed: 114.3k, Time: 24.1134
Epoch: 277, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/209.23, Loss: 0.3878, Acc: 0.8506, Speed: 114.8k, Time: 36.0601
Epoch: 277, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/209.23, Loss: 0.3891, Acc: 0.8502, Speed: 114.6k, Time: 48.1392
Epoch: 277, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/209.23, Loss: 0.3887, Acc: 0.8504, Speed: 115.0k, Time: 60.1817
Epoch: 277, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/209.23, Loss: 0.3888, Acc: 0.8502, Speed: 115.3k, Time: 71.8234
Epoch: 277, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/306.82, Loss: 0.3893, Acc: 0.8501, Speed: 115.7k, Time: 83.5609
Epoch: 277, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/306.82, Loss: 0.3889, Acc: 0.8501, Speed: 115.6k, Time: 95.6552
Epoch: 277, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/306.82, Loss: 0.3883, Acc: 0.8505, Speed: 115.0k, Time: 107.7238
Train 0.8507
Val 0.8597
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669

skip saving model for perf <= 0.8620
Epoch: 278, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3918, Acc: 0.8486, Speed: 116.6k, Time: 12.0495
Epoch: 278, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3883, Acc: 0.8499, Speed: 114.7k, Time: 24.0655
Epoch: 278, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3886, Acc: 0.8498, Speed: 114.2k, Time: 36.1619
Epoch: 278, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3883, Acc: 0.8504, Speed: 114.8k, Time: 48.2371
Epoch: 278, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3874, Acc: 0.8508, Speed: 114.8k, Time: 60.1561
Epoch: 278, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3868, Acc: 0.8512, Speed: 114.6k, Time: 72.3226
Epoch: 278, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3865, Acc: 0.8511, Speed: 114.4k, Time: 84.4682
Epoch: 278, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3868, Acc: 0.8513, Speed: 114.2k, Time: 96.5660
Epoch: 278, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/234.64, Loss: 0.3866, Acc: 0.8514, Speed: 114.2k, Time: 108.6398
Train 0.8514
Val 0.8621
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108

saving model to local_300_parikh
Epoch: 279, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/225.03, Loss: 0.3843, Acc: 0.8519, Speed: 118.6k, Time: 11.7096
Epoch: 279, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/254.45, Loss: 0.3867, Acc: 0.8504, Speed: 118.4k, Time: 23.4073
Epoch: 279, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/254.45, Loss: 0.3867, Acc: 0.8509, Speed: 116.4k, Time: 35.4046
Epoch: 279, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/254.45, Loss: 0.3869, Acc: 0.8509, Speed: 116.0k, Time: 47.5115
Epoch: 279, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/254.45, Loss: 0.3869, Acc: 0.8509, Speed: 115.5k, Time: 59.6858
Epoch: 279, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/254.45, Loss: 0.3870, Acc: 0.8507, Speed: 115.1k, Time: 71.7798
Epoch: 279, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/254.45, Loss: 0.3868, Acc: 0.8508, Speed: 115.4k, Time: 83.8901
Epoch: 279, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/254.45, Loss: 0.3869, Acc: 0.8511, Speed: 115.1k, Time: 95.9657
Epoch: 279, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/310.97, Loss: 0.3866, Acc: 0.8511, Speed: 115.0k, Time: 107.9692
Train 0.8513
Val 0.8614
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396

skip saving model for perf <= 0.8621
Epoch: 280, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/197.57, Loss: 0.3823, Acc: 0.8536, Speed: 112.7k, Time: 12.0680
Epoch: 280, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/199.90, Loss: 0.3865, Acc: 0.8512, Speed: 114.1k, Time: 24.1368
Epoch: 280, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/226.08, Loss: 0.3860, Acc: 0.8515, Speed: 114.3k, Time: 36.3103
Epoch: 280, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/226.08, Loss: 0.3864, Acc: 0.8513, Speed: 113.8k, Time: 48.4009
Epoch: 280, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/226.08, Loss: 0.3861, Acc: 0.8514, Speed: 114.0k, Time: 60.3869
Epoch: 280, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/226.08, Loss: 0.3858, Acc: 0.8516, Speed: 114.6k, Time: 72.0740
Epoch: 280, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/226.08, Loss: 0.3857, Acc: 0.8517, Speed: 115.1k, Time: 83.6946
Epoch: 280, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/226.08, Loss: 0.3861, Acc: 0.8516, Speed: 115.3k, Time: 95.6606
Epoch: 280, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/226.08, Loss: 0.3864, Acc: 0.8514, Speed: 115.0k, Time: 107.7056
Train 0.8513
Val 0.8616
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599

skip saving model for perf <= 0.8621
Epoch: 281, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3854, Acc: 0.8517, Speed: 114.2k, Time: 12.1031
Epoch: 281, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3861, Acc: 0.8512, Speed: 115.4k, Time: 24.2014
Epoch: 281, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3875, Acc: 0.8508, Speed: 114.5k, Time: 36.2879
Epoch: 281, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3881, Acc: 0.8505, Speed: 114.1k, Time: 48.3243
Epoch: 281, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3872, Acc: 0.8510, Speed: 114.2k, Time: 60.4369
Epoch: 281, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3868, Acc: 0.8515, Speed: 113.9k, Time: 72.4994
Epoch: 281, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3869, Acc: 0.8515, Speed: 114.2k, Time: 84.6596
Epoch: 281, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/207.55, Loss: 0.3866, Acc: 0.8516, Speed: 114.0k, Time: 96.6848
Epoch: 281, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/221.21, Loss: 0.3867, Acc: 0.8516, Speed: 113.9k, Time: 108.7809
Train 0.8516
Val 0.8614
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396

skip saving model for perf <= 0.8621
Epoch: 282, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/176.22, Loss: 0.3842, Acc: 0.8527, Speed: 118.8k, Time: 11.6442
Epoch: 282, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/176.22, Loss: 0.3849, Acc: 0.8522, Speed: 118.6k, Time: 23.2143
Epoch: 282, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/186.52, Loss: 0.3850, Acc: 0.8522, Speed: 116.4k, Time: 35.3458
Epoch: 282, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/186.52, Loss: 0.3858, Acc: 0.8517, Speed: 116.0k, Time: 47.2735
Epoch: 282, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/186.52, Loss: 0.3862, Acc: 0.8519, Speed: 115.7k, Time: 59.2706
Epoch: 282, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/186.52, Loss: 0.3861, Acc: 0.8517, Speed: 115.2k, Time: 71.4363
Epoch: 282, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/198.85, Loss: 0.3860, Acc: 0.8516, Speed: 115.1k, Time: 83.6415
Epoch: 282, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/205.55, Loss: 0.3852, Acc: 0.8519, Speed: 115.2k, Time: 95.7237
Epoch: 282, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/205.55, Loss: 0.3856, Acc: 0.8518, Speed: 115.1k, Time: 107.8142
Train 0.8518
Val 0.8610
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990

skip saving model for perf <= 0.8621
Epoch: 283, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/205.49, Loss: 0.3835, Acc: 0.8515, Speed: 118.0k, Time: 12.0938
Epoch: 283, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/205.49, Loss: 0.3849, Acc: 0.8516, Speed: 116.1k, Time: 24.1374
Epoch: 283, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/205.49, Loss: 0.3852, Acc: 0.8512, Speed: 115.3k, Time: 36.1639
Epoch: 283, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/211.10, Loss: 0.3860, Acc: 0.8511, Speed: 114.8k, Time: 48.3240
Epoch: 283, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/211.10, Loss: 0.3853, Acc: 0.8519, Speed: 114.0k, Time: 60.4963
Epoch: 283, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/227.74, Loss: 0.3850, Acc: 0.8522, Speed: 115.1k, Time: 72.0405
Epoch: 283, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/227.74, Loss: 0.3860, Acc: 0.8517, Speed: 115.8k, Time: 83.6383
Epoch: 283, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/227.74, Loss: 0.3859, Acc: 0.8516, Speed: 115.7k, Time: 95.6366
Epoch: 283, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/227.74, Loss: 0.3859, Acc: 0.8517, Speed: 115.2k, Time: 107.7509
Train 0.8515
Val 0.8606
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583

skip saving model for perf <= 0.8621
Epoch: 284, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/191.53, Loss: 0.3879, Acc: 0.8511, Speed: 114.4k, Time: 12.0228
Epoch: 284, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/191.53, Loss: 0.3874, Acc: 0.8513, Speed: 115.2k, Time: 24.0924
Epoch: 284, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3841, Acc: 0.8524, Speed: 114.5k, Time: 36.0689
Epoch: 284, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3834, Acc: 0.8527, Speed: 114.5k, Time: 48.1809
Epoch: 284, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3843, Acc: 0.8523, Speed: 114.8k, Time: 60.1902
Epoch: 284, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3847, Acc: 0.8522, Speed: 114.9k, Time: 72.3845
Epoch: 284, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3853, Acc: 0.8518, Speed: 115.0k, Time: 84.4542
Epoch: 284, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3863, Acc: 0.8516, Speed: 114.6k, Time: 96.6051
Epoch: 284, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/213.91, Loss: 0.3861, Acc: 0.8516, Speed: 114.5k, Time: 108.6902
Train 0.8517
Val 0.8608
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787

skip saving model for perf <= 0.8621
Epoch: 285, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/198.85, Loss: 0.3803, Acc: 0.8535, Speed: 118.9k, Time: 11.6538
Epoch: 285, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/207.18, Loss: 0.3820, Acc: 0.8533, Speed: 119.0k, Time: 23.2496
Epoch: 285, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/207.28, Loss: 0.3824, Acc: 0.8533, Speed: 117.3k, Time: 35.3680
Epoch: 285, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/275.26, Loss: 0.3832, Acc: 0.8530, Speed: 116.0k, Time: 47.4341
Epoch: 285, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/275.26, Loss: 0.3841, Acc: 0.8526, Speed: 115.4k, Time: 59.4562
Epoch: 285, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/275.26, Loss: 0.3860, Acc: 0.8517, Speed: 115.2k, Time: 71.5227
Epoch: 285, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/275.26, Loss: 0.3862, Acc: 0.8515, Speed: 115.1k, Time: 83.7123
Epoch: 285, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/275.26, Loss: 0.3862, Acc: 0.8515, Speed: 115.1k, Time: 95.7602
Epoch: 285, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/275.26, Loss: 0.3860, Acc: 0.8518, Speed: 114.8k, Time: 107.8713
Train 0.8518
Val 0.8613
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295

skip saving model for perf <= 0.8621
Epoch: 286, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/181.09, Loss: 0.3860, Acc: 0.8522, Speed: 113.2k, Time: 12.1551
Epoch: 286, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3871, Acc: 0.8517, Speed: 113.3k, Time: 24.1337
Epoch: 286, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3850, Acc: 0.8523, Speed: 113.3k, Time: 36.2004
Epoch: 286, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3842, Acc: 0.8527, Speed: 113.4k, Time: 48.2400
Epoch: 286, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3851, Acc: 0.8522, Speed: 113.5k, Time: 60.2834
Epoch: 286, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3848, Acc: 0.8523, Speed: 114.4k, Time: 71.8917
Epoch: 286, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3853, Acc: 0.8522, Speed: 114.9k, Time: 83.6008
Epoch: 286, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3855, Acc: 0.8520, Speed: 115.0k, Time: 95.6221
Epoch: 286, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/239.37, Loss: 0.3857, Acc: 0.8520, Speed: 115.0k, Time: 107.7103
Train 0.8521
Val 0.8625
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514

saving model to local_300_parikh
Epoch: 287, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3849, Acc: 0.8533, Speed: 112.8k, Time: 12.1022
Epoch: 287, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3836, Acc: 0.8530, Speed: 112.7k, Time: 24.1964
Epoch: 287, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3851, Acc: 0.8521, Speed: 113.7k, Time: 36.3058
Epoch: 287, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3845, Acc: 0.8525, Speed: 113.9k, Time: 48.3581
Epoch: 287, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3845, Acc: 0.8522, Speed: 114.3k, Time: 60.4567
Epoch: 287, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3841, Acc: 0.8525, Speed: 114.2k, Time: 72.4893
Epoch: 287, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3840, Acc: 0.8526, Speed: 113.9k, Time: 84.4879
Epoch: 287, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3847, Acc: 0.8523, Speed: 113.9k, Time: 96.5164
Epoch: 287, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/418.32, Loss: 0.3849, Acc: 0.8523, Speed: 114.2k, Time: 108.5864
Train 0.8524
Val 0.8631
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124

saving model to local_300_parikh
Epoch: 288, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3838, Acc: 0.8511, Speed: 119.0k, Time: 11.6666
Epoch: 288, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3867, Acc: 0.8507, Speed: 118.0k, Time: 23.3894
Epoch: 288, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3869, Acc: 0.8509, Speed: 115.7k, Time: 35.5894
Epoch: 288, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3868, Acc: 0.8509, Speed: 115.3k, Time: 47.7068
Epoch: 288, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3874, Acc: 0.8507, Speed: 115.5k, Time: 59.7565
Epoch: 288, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3873, Acc: 0.8509, Speed: 115.5k, Time: 71.8660
Epoch: 288, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3875, Acc: 0.8509, Speed: 115.3k, Time: 83.8860
Epoch: 288, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3881, Acc: 0.8506, Speed: 115.1k, Time: 95.9610
Epoch: 288, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/251.91, Loss: 0.3878, Acc: 0.8507, Speed: 115.0k, Time: 108.0188
Train 0.8509
Val 0.8600
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974

skip saving model for perf <= 0.8631
Epoch: 289, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/186.92, Loss: 0.3877, Acc: 0.8506, Speed: 113.5k, Time: 12.1478
Epoch: 289, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/198.64, Loss: 0.3871, Acc: 0.8505, Speed: 114.7k, Time: 24.1232
Epoch: 289, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/198.64, Loss: 0.3866, Acc: 0.8508, Speed: 113.9k, Time: 36.1682
Epoch: 289, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/198.64, Loss: 0.3861, Acc: 0.8509, Speed: 114.3k, Time: 48.2229
Epoch: 289, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/227.56, Loss: 0.3872, Acc: 0.8503, Speed: 114.4k, Time: 60.3448
Epoch: 289, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/227.56, Loss: 0.3866, Acc: 0.8506, Speed: 114.7k, Time: 72.0371
Epoch: 289, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/227.56, Loss: 0.3864, Acc: 0.8508, Speed: 115.0k, Time: 83.7945
Epoch: 289, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/227.56, Loss: 0.3867, Acc: 0.8507, Speed: 115.0k, Time: 95.8997
Epoch: 289, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/227.56, Loss: 0.3857, Acc: 0.8512, Speed: 114.7k, Time: 108.0543
Train 0.8511
Val 0.8608
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787

skip saving model for perf <= 0.8631
Epoch: 290, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/198.15, Loss: 0.3880, Acc: 0.8520, Speed: 116.9k, Time: 12.1954
Epoch: 290, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/205.22, Loss: 0.3879, Acc: 0.8509, Speed: 114.7k, Time: 24.2739
Epoch: 290, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/231.34, Loss: 0.3864, Acc: 0.8514, Speed: 114.7k, Time: 36.2188
Epoch: 290, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/231.34, Loss: 0.3869, Acc: 0.8514, Speed: 114.6k, Time: 48.2640
Epoch: 290, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/231.34, Loss: 0.3863, Acc: 0.8514, Speed: 114.4k, Time: 60.2758
Epoch: 290, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/231.34, Loss: 0.3872, Acc: 0.8510, Speed: 114.3k, Time: 72.3461
Epoch: 290, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/231.34, Loss: 0.3863, Acc: 0.8512, Speed: 114.5k, Time: 84.4289
Epoch: 290, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/231.34, Loss: 0.3857, Acc: 0.8516, Speed: 114.3k, Time: 96.4509
Epoch: 290, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/231.34, Loss: 0.3856, Acc: 0.8516, Speed: 114.1k, Time: 108.5707
Train 0.8518
Val 0.8586
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551

skip saving model for perf <= 0.8631
Epoch: 291, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/186.92, Loss: 0.3861, Acc: 0.8521, Speed: 119.3k, Time: 11.7169
Epoch: 291, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/186.92, Loss: 0.3851, Acc: 0.8524, Speed: 119.1k, Time: 23.2903
Epoch: 291, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/232.13, Loss: 0.3861, Acc: 0.8518, Speed: 117.2k, Time: 35.4326
Epoch: 291, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/232.13, Loss: 0.3872, Acc: 0.8513, Speed: 116.4k, Time: 47.4765
Epoch: 291, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/232.13, Loss: 0.3863, Acc: 0.8514, Speed: 116.1k, Time: 59.5930
Epoch: 291, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/232.13, Loss: 0.3861, Acc: 0.8513, Speed: 115.3k, Time: 71.7151
Epoch: 291, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/232.13, Loss: 0.3865, Acc: 0.8513, Speed: 114.7k, Time: 83.7851
Epoch: 291, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/232.13, Loss: 0.3859, Acc: 0.8516, Speed: 114.7k, Time: 95.8396
Epoch: 291, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/232.13, Loss: 0.3862, Acc: 0.8515, Speed: 114.5k, Time: 108.0093
Train 0.8514
Val 0.8609
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888

skip saving model for perf <= 0.8631
Epoch: 292, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/194.50, Loss: 0.3881, Acc: 0.8509, Speed: 114.5k, Time: 12.1862
Epoch: 292, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/194.50, Loss: 0.3895, Acc: 0.8502, Speed: 114.1k, Time: 24.2660
Epoch: 292, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/197.09, Loss: 0.3893, Acc: 0.8502, Speed: 114.5k, Time: 36.2826
Epoch: 292, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/197.09, Loss: 0.3885, Acc: 0.8505, Speed: 114.5k, Time: 48.3503
Epoch: 292, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/197.09, Loss: 0.3880, Acc: 0.8504, Speed: 114.4k, Time: 60.4866
Epoch: 292, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/197.09, Loss: 0.3872, Acc: 0.8507, Speed: 114.9k, Time: 72.1748
Epoch: 292, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/202.78, Loss: 0.3866, Acc: 0.8511, Speed: 114.8k, Time: 83.7531
Epoch: 292, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/202.78, Loss: 0.3864, Acc: 0.8512, Speed: 114.7k, Time: 95.8474
Epoch: 292, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/202.78, Loss: 0.3861, Acc: 0.8514, Speed: 114.9k, Time: 107.8616
Train 0.8513
Val 0.8602
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177

skip saving model for perf <= 0.8631
Epoch: 293, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/178.80, Loss: 0.3780, Acc: 0.8547, Speed: 116.3k, Time: 12.0586
Epoch: 293, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/178.80, Loss: 0.3797, Acc: 0.8541, Speed: 115.0k, Time: 24.2226
Epoch: 293, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/203.36, Loss: 0.3816, Acc: 0.8535, Speed: 114.5k, Time: 36.3806
Epoch: 293, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/203.36, Loss: 0.3827, Acc: 0.8536, Speed: 114.4k, Time: 48.4987
Epoch: 293, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/210.64, Loss: 0.3831, Acc: 0.8530, Speed: 114.3k, Time: 60.6350
Epoch: 293, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/210.64, Loss: 0.3833, Acc: 0.8531, Speed: 114.4k, Time: 72.6955
Epoch: 293, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/224.74, Loss: 0.3839, Acc: 0.8528, Speed: 114.4k, Time: 84.7365
Epoch: 293, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/225.39, Loss: 0.3837, Acc: 0.8530, Speed: 114.1k, Time: 96.8062
Epoch: 293, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/225.39, Loss: 0.3842, Acc: 0.8528, Speed: 113.9k, Time: 108.8753
Train 0.8526
Val 0.8616
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599

skip saving model for perf <= 0.8631
Epoch: 294, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/190.68, Loss: 0.3845, Acc: 0.8523, Speed: 115.1k, Time: 11.8789
Epoch: 294, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/190.68, Loss: 0.3825, Acc: 0.8527, Speed: 116.3k, Time: 23.2368
Epoch: 294, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/195.36, Loss: 0.3838, Acc: 0.8525, Speed: 116.6k, Time: 35.2361
Epoch: 294, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/211.19, Loss: 0.3845, Acc: 0.8523, Speed: 116.3k, Time: 47.3285
Epoch: 294, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/211.19, Loss: 0.3841, Acc: 0.8525, Speed: 115.7k, Time: 59.4309
Epoch: 294, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/211.19, Loss: 0.3846, Acc: 0.8523, Speed: 115.4k, Time: 71.5564
Epoch: 294, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/211.19, Loss: 0.3848, Acc: 0.8521, Speed: 115.2k, Time: 83.6139
Epoch: 294, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/211.19, Loss: 0.3846, Acc: 0.8524, Speed: 115.1k, Time: 95.7085
Epoch: 294, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/233.51, Loss: 0.3849, Acc: 0.8523, Speed: 114.9k, Time: 107.9289
Train 0.8523
Val 0.8616
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599
294	0.852343	0.861599

skip saving model for perf <= 0.8631
Epoch: 295, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/174.76, Loss: 0.3859, Acc: 0.8521, Speed: 111.5k, Time: 12.0753
Epoch: 295, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/186.86, Loss: 0.3853, Acc: 0.8525, Speed: 113.8k, Time: 24.1080
Epoch: 295, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/206.73, Loss: 0.3857, Acc: 0.8520, Speed: 114.0k, Time: 36.1836
Epoch: 295, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/207.63, Loss: 0.3834, Acc: 0.8524, Speed: 113.4k, Time: 48.2299
Epoch: 295, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/207.63, Loss: 0.3835, Acc: 0.8521, Speed: 113.9k, Time: 60.2960
Epoch: 295, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/207.63, Loss: 0.3840, Acc: 0.8519, Speed: 114.1k, Time: 72.2600
Epoch: 295, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/207.63, Loss: 0.3848, Acc: 0.8517, Speed: 115.1k, Time: 83.7519
Epoch: 295, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/207.63, Loss: 0.3841, Acc: 0.8522, Speed: 114.6k, Time: 95.9969
Epoch: 295, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/241.80, Loss: 0.3837, Acc: 0.8524, Speed: 114.6k, Time: 108.0440
Train 0.8521
Val 0.8597
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599
294	0.852343	0.861599
295	0.852100	0.859669

skip saving model for perf <= 0.8631
Epoch: 296, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/172.30, Loss: 0.3851, Acc: 0.8529, Speed: 112.1k, Time: 12.0265
Epoch: 296, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/181.09, Loss: 0.3840, Acc: 0.8525, Speed: 112.8k, Time: 23.9882
Epoch: 296, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/205.78, Loss: 0.3833, Acc: 0.8530, Speed: 113.4k, Time: 35.9733
Epoch: 296, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/205.78, Loss: 0.3844, Acc: 0.8524, Speed: 114.1k, Time: 48.1598
Epoch: 296, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/263.98, Loss: 0.3840, Acc: 0.8526, Speed: 114.2k, Time: 60.1807
Epoch: 296, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/263.98, Loss: 0.3847, Acc: 0.8520, Speed: 114.1k, Time: 72.3253
Epoch: 296, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/263.98, Loss: 0.3847, Acc: 0.8520, Speed: 114.1k, Time: 84.4336
Epoch: 296, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/263.98, Loss: 0.3849, Acc: 0.8518, Speed: 113.9k, Time: 96.6069
Epoch: 296, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/263.98, Loss: 0.3856, Acc: 0.8516, Speed: 114.2k, Time: 108.6710
Train 0.8516
Val 0.8631
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599
294	0.852343	0.861599
295	0.852100	0.859669
296	0.851616	0.863124

skip saving model for perf <= 0.8631
Epoch: 297, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/185.33, Loss: 0.3907, Acc: 0.8488, Speed: 114.3k, Time: 12.0406
Epoch: 297, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/185.33, Loss: 0.3884, Acc: 0.8498, Speed: 116.0k, Time: 23.5218
Epoch: 297, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/208.37, Loss: 0.3862, Acc: 0.8509, Speed: 115.4k, Time: 35.4586
Epoch: 297, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/208.37, Loss: 0.3861, Acc: 0.8512, Speed: 115.4k, Time: 47.5152
Epoch: 297, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/208.37, Loss: 0.3853, Acc: 0.8515, Speed: 115.2k, Time: 59.5580
Epoch: 297, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/208.37, Loss: 0.3858, Acc: 0.8514, Speed: 115.0k, Time: 71.6616
Epoch: 297, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/223.42, Loss: 0.3858, Acc: 0.8514, Speed: 114.9k, Time: 83.7428
Epoch: 297, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/223.42, Loss: 0.3857, Acc: 0.8514, Speed: 114.8k, Time: 95.8902
Epoch: 297, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/223.42, Loss: 0.3857, Acc: 0.8513, Speed: 114.8k, Time: 108.0120
Train 0.8516
Val 0.8619
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599
294	0.852343	0.861599
295	0.852100	0.859669
296	0.851616	0.863124
297	0.851613	0.861904

skip saving model for perf <= 0.8631
Epoch: 298, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/212.39, Loss: 0.3852, Acc: 0.8510, Speed: 115.7k, Time: 12.0680
Epoch: 298, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/212.39, Loss: 0.3844, Acc: 0.8531, Speed: 115.0k, Time: 24.0472
Epoch: 298, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/212.39, Loss: 0.3844, Acc: 0.8528, Speed: 114.6k, Time: 36.1003
Epoch: 298, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/212.39, Loss: 0.3844, Acc: 0.8526, Speed: 114.7k, Time: 48.1554
Epoch: 298, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/212.39, Loss: 0.3838, Acc: 0.8524, Speed: 114.4k, Time: 60.2371
Epoch: 298, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/216.62, Loss: 0.3835, Acc: 0.8530, Speed: 114.5k, Time: 72.3012
Epoch: 298, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/216.62, Loss: 0.3843, Acc: 0.8527, Speed: 115.3k, Time: 83.8548
Epoch: 298, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/216.62, Loss: 0.3842, Acc: 0.8526, Speed: 115.1k, Time: 95.8852
Epoch: 298, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/259.30, Loss: 0.3850, Acc: 0.8523, Speed: 115.1k, Time: 107.8943
Train 0.8523
Val 0.8603
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599
294	0.852343	0.861599
295	0.852100	0.859669
296	0.851616	0.863124
297	0.851613	0.861904
298	0.852264	0.860278

skip saving model for perf <= 0.8631
Epoch: 299, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/220.31, Loss: 0.3874, Acc: 0.8494, Speed: 113.7k, Time: 12.0776
Epoch: 299, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/220.31, Loss: 0.3844, Acc: 0.8518, Speed: 113.9k, Time: 24.2332
Epoch: 299, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/220.31, Loss: 0.3844, Acc: 0.8521, Speed: 114.2k, Time: 36.4254
Epoch: 299, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/220.31, Loss: 0.3849, Acc: 0.8519, Speed: 114.1k, Time: 48.4140
Epoch: 299, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/220.31, Loss: 0.3845, Acc: 0.8517, Speed: 114.3k, Time: 60.5040
Epoch: 299, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/220.31, Loss: 0.3842, Acc: 0.8520, Speed: 114.3k, Time: 72.5777
Epoch: 299, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/246.42, Loss: 0.3845, Acc: 0.8519, Speed: 114.2k, Time: 84.6234
Epoch: 299, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/246.42, Loss: 0.3839, Acc: 0.8520, Speed: 114.1k, Time: 96.8018
Epoch: 299, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/246.42, Loss: 0.3847, Acc: 0.8517, Speed: 114.0k, Time: 108.7873
Train 0.8518
Val 0.8601
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599
294	0.852343	0.861599
295	0.852100	0.859669
296	0.851616	0.863124
297	0.851613	0.861904
298	0.852264	0.860278
299	0.851769	0.860075

skip saving model for perf <= 0.8631
Epoch: 300, Batch: 1000/9683, LR: 0.0500, Grad: 0.00/200.29, Loss: 0.3826, Acc: 0.8533, Speed: 114.6k, Time: 11.9827
Epoch: 300, Batch: 2000/9683, LR: 0.0500, Grad: 0.00/200.29, Loss: 0.3846, Acc: 0.8517, Speed: 116.3k, Time: 23.5402
Epoch: 300, Batch: 3000/9683, LR: 0.0500, Grad: 0.00/200.29, Loss: 0.3829, Acc: 0.8526, Speed: 115.7k, Time: 35.3496
Epoch: 300, Batch: 4000/9683, LR: 0.0500, Grad: 0.00/228.62, Loss: 0.3835, Acc: 0.8525, Speed: 115.3k, Time: 47.4060
Epoch: 300, Batch: 5000/9683, LR: 0.0500, Grad: 0.00/228.62, Loss: 0.3828, Acc: 0.8527, Speed: 114.8k, Time: 59.5515
Epoch: 300, Batch: 6000/9683, LR: 0.0500, Grad: 0.00/228.62, Loss: 0.3833, Acc: 0.8527, Speed: 115.1k, Time: 71.5957
Epoch: 300, Batch: 7000/9683, LR: 0.0500, Grad: 0.00/228.62, Loss: 0.3841, Acc: 0.8524, Speed: 115.1k, Time: 83.7097
Epoch: 300, Batch: 8000/9683, LR: 0.0500, Grad: 0.00/228.62, Loss: 0.3845, Acc: 0.8523, Speed: 115.2k, Time: 95.8461
Epoch: 300, Batch: 9000/9683, LR: 0.0500, Grad: 0.00/228.62, Loss: 0.3844, Acc: 0.8525, Speed: 115.1k, Time: 107.8289
Train 0.8524
Val 0.8628
1	0.407430	0.498222
2	0.514475	0.557972
3	0.586709	0.630119
4	0.617062	0.641500
5	0.637267	0.664262
6	0.655448	0.687024
7	0.669892	0.696576
8	0.681908	0.718016
9	0.694264	0.728889
10	0.714118	0.757850
11	0.738218	0.776547
12	0.751941	0.793009
13	0.759397	0.790265
14	0.768672	0.802053
15	0.773073	0.804593
16	0.779362	0.810690
17	0.781561	0.812519
18	0.785888	0.811401
19	0.788149	0.812824
20	0.792220	0.819531
21	0.793025	0.820648
22	0.796231	0.825526
23	0.797934	0.826948
24	0.800319	0.827050
25	0.801540	0.825932
26	0.802478	0.826136
27	0.804788	0.829590
28	0.805561	0.830810
29	0.806386	0.832537
30	0.808097	0.831826
31	0.808978	0.833655
32	0.809473	0.831724
33	0.811384	0.834875
34	0.811872	0.836907
35	0.813159	0.836094
36	0.813938	0.838025
37	0.814477	0.832842
38	0.815773	0.837618
39	0.815600	0.833858
40	0.816687	0.838634
41	0.817673	0.837618
42	0.818425	0.839955
43	0.819115	0.843410
44	0.819284	0.841581
45	0.819971	0.840768
46	0.820777	0.840463
47	0.821276	0.838838
48	0.821369	0.841276
49	0.822044	0.842089
50	0.822725	0.841073
51	0.822989	0.842292
52	0.822867	0.844630
53	0.824094	0.841784
54	0.824467	0.844020
55	0.825131	0.843207
56	0.824723	0.844020
57	0.825089	0.843613
58	0.825821	0.847373
59	0.825936	0.845849
60	0.826336	0.844630
61	0.826465	0.843613
62	0.826870	0.846662
63	0.827002	0.847170
64	0.828499	0.846052
65	0.828200	0.847780
66	0.828735	0.847170
67	0.829254	0.847068
68	0.829352	0.844122
69	0.830379	0.849202
70	0.830945	0.851946
71	0.831602	0.849101
72	0.830790	0.849609
73	0.831205	0.848999
74	0.831087	0.851133
75	0.831515	0.851235
76	0.832117	0.850828
77	0.831999	0.848694
78	0.830869	0.851031
79	0.832696	0.849914
80	0.832900	0.849710
81	0.833106	0.850218
82	0.833481	0.853877
83	0.834243	0.849710
84	0.833836	0.850422
85	0.833978	0.853369
86	0.834427	0.854181
87	0.833734	0.854893
88	0.835266	0.853470
89	0.835086	0.856519
90	0.835095	0.853369
91	0.835410	0.853267
92	0.835354	0.853877
93	0.835652	0.852352
94	0.835889	0.853267
95	0.835248	0.854080
96	0.835625	0.852962
97	0.834711	0.854588
98	0.834435	0.853267
99	0.835751	0.852962
100	0.836302	0.855909
101	0.837414	0.853673
102	0.836448	0.856722
103	0.837058	0.853064
104	0.836646	0.853978
105	0.836865	0.854181
106	0.837864	0.851946
107	0.838359	0.855401
108	0.837748	0.856823
109	0.838128	0.855299
110	0.837915	0.855299
111	0.838912	0.853165
112	0.838228	0.857128
113	0.838976	0.854283
114	0.838818	0.856620
115	0.839368	0.854893
116	0.839939	0.855096
117	0.839637	0.855502
118	0.839692	0.857230
119	0.839855	0.856620
120	0.840958	0.858043
121	0.841102	0.858348
122	0.839446	0.856112
123	0.840236	0.857027
124	0.839129	0.856925
125	0.840349	0.855096
126	0.840187	0.856620
127	0.840640	0.854994
128	0.840869	0.856823
129	0.840680	0.856214
130	0.841115	0.855604
131	0.840573	0.857230
132	0.841536	0.854994
133	0.841262	0.858551
134	0.841348	0.855096
135	0.841328	0.858551
136	0.842051	0.855604
137	0.841980	0.856925
138	0.842355	0.856620
139	0.842247	0.855198
140	0.841781	0.856519
141	0.841190	0.854994
142	0.839655	0.857433
143	0.841972	0.855502
144	0.841470	0.857230
145	0.841506	0.856011
146	0.842134	0.855502
147	0.842593	0.853775
148	0.842138	0.856519
149	0.842746	0.856722
150	0.842114	0.857535
151	0.842742	0.857535
152	0.843272	0.856722
153	0.843600	0.855909
154	0.843578	0.857027
155	0.843283	0.856823
156	0.843405	0.856823
157	0.843900	0.857128
158	0.843784	0.856823
159	0.844038	0.857230
160	0.844861	0.857433
161	0.844588	0.856925
162	0.844264	0.857230
163	0.845384	0.855299
164	0.845021	0.857941
165	0.844777	0.856620
166	0.843674	0.856722
167	0.844386	0.857840
168	0.844293	0.858653
169	0.844098	0.857535
170	0.845385	0.858754
171	0.844472	0.857840
172	0.844330	0.857128
173	0.844148	0.857332
174	0.845103	0.858348
175	0.845143	0.857941
176	0.844748	0.858754
177	0.844623	0.857433
178	0.845353	0.855909
179	0.845209	0.856722
180	0.845506	0.856519
181	0.846079	0.857230
182	0.845873	0.856722
183	0.845083	0.859262
184	0.845678	0.858043
185	0.845904	0.858957
186	0.844959	0.858653
187	0.846401	0.859669
188	0.846059	0.856417
189	0.845975	0.857332
190	0.846468	0.857332
191	0.846294	0.857738
192	0.846519	0.858551
193	0.846904	0.858551
194	0.846827	0.859872
195	0.846742	0.858957
196	0.846083	0.858957
197	0.846459	0.858653
198	0.845516	0.862006
199	0.846823	0.860075
200	0.847382	0.860278
201	0.846674	0.860380
202	0.846975	0.859872
203	0.847739	0.858246
204	0.847000	0.860278
205	0.847652	0.860278
206	0.847588	0.859669
207	0.847564	0.859872
208	0.848083	0.860380
209	0.847641	0.859974
210	0.848289	0.859262
211	0.848154	0.857941
212	0.847663	0.859872
213	0.847712	0.857738
214	0.848236	0.859466
215	0.848118	0.859974
216	0.848525	0.859364
217	0.848163	0.860482
218	0.848170	0.860787
219	0.847610	0.858348
220	0.847845	0.859466
221	0.847892	0.860177
222	0.848622	0.860075
223	0.848281	0.859770
224	0.848747	0.858246
225	0.848296	0.858754
226	0.848913	0.859466
227	0.848817	0.858856
228	0.849081	0.860787
229	0.849454	0.858449
230	0.849228	0.858449
231	0.849186	0.859669
232	0.849119	0.859567
233	0.849461	0.858653
234	0.849199	0.857941
235	0.850078	0.858246
236	0.849381	0.859567
237	0.849692	0.860380
238	0.850136	0.861904
239	0.849450	0.860583
240	0.850347	0.860177
241	0.849326	0.860075
242	0.849403	0.859262
243	0.848937	0.860888
244	0.848442	0.857332
245	0.849290	0.859466
246	0.850089	0.859364
247	0.850027	0.860177
248	0.849831	0.861803
249	0.849927	0.859567
250	0.849712	0.859974
251	0.849860	0.860583
252	0.850053	0.860177
253	0.849669	0.860482
254	0.849654	0.860583
255	0.849685	0.860787
256	0.850049	0.861295
257	0.849916	0.859161
258	0.850158	0.861295
259	0.850610	0.860177
260	0.850715	0.859669
261	0.850735	0.859567
262	0.850324	0.859364
263	0.849965	0.860583
264	0.850608	0.860278
265	0.850732	0.860990
266	0.850726	0.860888
267	0.850577	0.859872
268	0.851101	0.858957
269	0.850628	0.859567
270	0.850974	0.860482
271	0.850222	0.860583
272	0.850934	0.860177
273	0.850651	0.859466
274	0.850264	0.859872
275	0.850617	0.860177
276	0.850795	0.861396
277	0.850744	0.859669
278	0.851391	0.862108
279	0.851309	0.861396
280	0.851254	0.861599
281	0.851553	0.861396
282	0.851816	0.860990
283	0.851520	0.860583
284	0.851653	0.860787
285	0.851755	0.861295
286	0.852055	0.862514
287	0.852401	0.863124
288	0.850881	0.859974
289	0.851079	0.860787
290	0.851813	0.858551
291	0.851400	0.860888
292	0.851309	0.860177
293	0.852632	0.861599
294	0.852343	0.861599
295	0.852100	0.859669
296	0.851616	0.863124
297	0.851613	0.861904
298	0.852264	0.860278
299	0.851769	0.860075
300	0.852364	0.862819

skip saving model for perf <= 0.8631
