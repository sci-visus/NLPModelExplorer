%
% File emnlp2018.tex
%
%% Based on the style files for EMNLP 2018, which were
%% Based on the style files for ACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by
%% e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{emnlp2018}
\usepackage{times}
\usepackage{latexsym}
\usepackage{url}


%\aclfinalcopy % Uncomment this line for the final submission

%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\usepackage{graphicx}
\graphicspath{{figures/}{pictures/}{figs/}{./}} % where to search for the images

\newcommand\BibTeX{B{\sc ib}\TeX}
\newcommand\confname{EMNLP 2018}
%\newcommand\conforg{SIGDAT}

\title{Visual Interrogation of Attention-Based Models: \\ Applications in Language Inference and Machine Comprehension}

\author{Shusen Liu \\
  Lawrence Livermore National Laboratory\\
  {\tt liu42@llnl.gov} \\\And
  Tao Li,  Zhimin Li,  Vivek Srikumar, Valerio Pascucci \\
  School of Computing, University of Utah\\
    {\tt {tao.li, zhimin.li, vivek, pacucci}@utah.edu}
} 

\date{}

\begin{document}
\maketitle

\begin{abstract}
Neural networks models have gained unprecedented popularity in natural language processing due to their state-of-the-art performance and the flexible end-to-end training scheme. Despite their advantages, the lack of interpretability hinders the further development and refinement of the model.
%These models often relying on the attention mechanism, which not only helps improve predicting performance but also provide interpretable representations for users to peak into the opaque models that are usually considered as black boxes.
%
In this work, we present a flexible visualization library for creating customized visual analytic environments, which enables the user to investigate and interrogate the relationship among the input, the model internals (i.e., attention), and the output predictions that in turn shed light on the model decision making processing.
 
\end{abstract}


\input{intro.tex}
\input{relatedWorks.tex}
\input{system.tex}
\input{result.tex}

\bibliographystyle{acl_natbib_nourl}
\bibliography{NLPvis.bib}

\end{document}
