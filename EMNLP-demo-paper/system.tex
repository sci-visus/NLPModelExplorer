
\section{Visualization System}
As illustrated in Figure~\ref{fig:modelPipeline}, many recent end-to-end NLP model follows a similar encoder, attention, and classifier structure, in which the attention stage provide a window to peek into the model decision making process. 
However, the static attention alone likely does not tell the whole story, 
the proposed system utilizes a perturbation-driven exploration strategy that allows the user manually or automatically perturb part of the pipeline and observe the changes in others.
%
The system consists of several visualization components that can be selectively combined to form a functional interactive system for a given task. In the following section, we will cover some of the essential components (the usage of all components can be found in the accompanying video).
%such as a prediction summary statistics the entire development set, as well as a scheme to update the model based 

\begin{figure}[htbp]
\centering
\vspace{-2mm}
 \includegraphics[width=0.9\linewidth]{sentence}
 \vspace{-2mm}
 \caption{
The interface for showing input sentences. The user can manually edit the words or apply automatic perturbation/paraphrasing of the inputs. In the ``perturbed'' drop-down menu, the blue words are the ones not exist in the original sentence.
 }
 \vspace{-1mm}
\label{fig:sentence}
\end{figure}

\subsection{Input Sentences Perturbation}
\label{sec:perturb}
Due to the discrete nature of the natural language, automatically applying perturbation to sentence for sensitivity analysis can be particularly challenging (compared to other domain, i.e., image), as small changes in words can leading to drastic differences in the semantics of the sentences.
To reduce the potential semantic deviation, we first devise a straightforward perturbation method by replacing \emph{nouns} and \emph{verbs} by their synonyms in the wordNet~\cite{Miller1995}. However, the limitation is apparent, as synonyms replacement does not guarantee the meaning of the sentence remains the same. And the WordNet often produces rare/obscure usages that may lead to less meaningful sentences. However, this method requires minimal computation and is easy to implement. 

To improve the perturbation quality, we also adopted a translation based paraphrasing technique that is similar to the one discussed in \cite{mallinson2017paraphrasing}. Here, we translate the original English sentence into several other languages and then translate back into English. Provided the translation produce correct result (in our case, we utilized the Google cloud translation platform), we obtain paraphrasing of the original sentences (see Figure~\ref{fig:sentence}, where the drop-down menu shows the some of the paraphrased/perturbed sentences).

\begin{figure}[htbp]
\centering
\vspace{-2mm}
 \includegraphics[width=0.8\linewidth]{prediction}
 \caption{
Summarize the prediction results of the perturbed input for the natural language inference model.
the prediction is encoded as a point in the barycentric coordinate system of the triangle, in which each vertex corresponds to one prediction label.
}
\vspace{-3mm}
\label{fig:prediction}
\end{figure}

\subsection{Prediction Visualization}
Efficient visual encoding for prediction is crucial for communicating the model behavior. And to fully support the input perturbation feature, the visual encoding should also allow multiple predictions to be shown in the same visualization.
%
For the natural language inference task, as illustrated in Figure~\ref{fig:prediction}, the predicted probabilities are encoded in the triangle barycentric coordinate, where the three vertices represent the three possible predictions (namely, \emph{entail}, \emph{contradict}, and \emph{neutral}). The prediction for the original unperturbed input is illustrated by a larger yellow circle, whereas the prediction of perturbed inputs is represented by smaller grey circles.
A density contour of the prediction is computed to emphasize the highly cluttered areas and detect outliers.

\begin{figure*}[t]
\centering
\vspace{-2mm}
 \includegraphics[width=0.95\linewidth]{attentionPanels}
  \vspace{-3mm}
 \caption{
Attention visualization. In the graph attention view (a), a bipartite graph encoding is adopted, in which the edge thickness corresponds to the attention value. The same values can also be directly visualized in the matrix form (b). 
The user can edit the attention values via the pop-up interface illustrated in (c).
We overlay the dependency tree ($a_1$) grammar structure to highlight important words and allow simplification of complex sentence based on the grammar structure.
%
For highly asymmetric attention relationship, we utilized a zoomable hierarchical visual representation (d). The user can focus on the individual sentence by clicking the rectangular bars.
}
\vspace{-3mm}
\label{fig:attentionVis}
\end{figure*}

\subsection{Attention Visualization}
As illustrated in Figure~\ref{fig:attentionVis}(a)(b), the most widely adopted technique to visualize attention matrix are bipartie graph (a) and heatmap (b). 
%
In the graph attention view (Fig.~\ref{fig:attentionVis}(a)), a bipartite graph encoding is adopted, in which the edge thickness corresponds to the attention value. %The color of the rectangle text block encodes the sum of all edge values connected to it (darker shade of blues correspond to higher values).
%
The graph view is suitable for highlighting the most dominant alignments. However, the edges may become cluttered if multiple attention values are high. The matrix attention view (Fig.~\ref{fig:attentionVis}(b)) resolve these issues, despite being more verbose and less efficient in highlighting the dominant alignments. 
We also enable the linkage between highlighted actions in both views (see Fig.~\ref{fig:attentionVis}(a)(b), one the most dominant attention is highlighted in orange).
%
To facilitate the perturbation of attention (see Figure~\ref{fig:modelPipeline}), as illustrated in Figure~\ref{fig:attentionVis}(c), we implement an interface in the matrix view for user to directly manipulate the attention value.

To address the challenge of visualizing long sentence, we augmented the standard visual encoding with grammar structure, and allow dynamic simplification of the sentence based on the dependency tree (see Figure~\ref{fig:attentionVis}(a1)). We also show how the dependency information can potentially improve the prediction result in Section~\ref{sec:NLIexample}

However, when the one of the text sequence become signification longer, i.e., a full paragraph as in the machine comprehension task, the even the simplified sentence can not be meaningfully represented in the graph or matrix visual encoding. To address this visualization challenge, as illustrated in Figure~\ref{fig:attentionVis}(d), we introduce the hierarchical representation. Here, a pure graphical encoding (the color bars marked by \emph{att2}) is used to capture the aggregated alignment information of the whole paragraph, and the user can focus on localized attention information by selecting the a pixel bar that presents a single sentence. We can also link this attention representation with matrix, such that whenever a sentence is selected the local attention relationship is allow shown in the matrix view (see Figure~\ref{fig:MCexample}(a)).

\subsection{Implementation}
The initial setup cost and unnecessary learning curve are often the barriers to the broad adaptation of a tool. 
Therefore, instead of design visualization system as a monolithic standalone application, 
we implement the proposed system as a python library with modularity and ease of use in mind.
The different pieces of the visualization (i.e., matrix-based attention encoding) can be accessed individually, 
or combined in other componenets to fit one's workflow via a simple API.
More importantly, the library-based design allows easy integration with the existing model implemented in python.
%To create a visualization, users only need to import the library, create an instance of the visualization object, and specify a set of callback functions, such as generating a prediction, accessing attention, to link the visualization to their NLP models. 
The code for creating an interactive exploration environment for a machine comprehension model is illustrated below.

\begin{lstlisting}[language=Python, caption=Code for setting up the visualization system shown in Figure~\ref{fig:MCexample}(a).]
from visPackage import MCModule
from bidaf_src import bidafModelInterface
from NLPutility import translationPerturbation

#initialize machine comprehension model
model = bidafModelInterface(
    wordDict="data/bidaf/squad.word.dict",
    wordVec="data/bidaf/glove.hdf5",
    model="data/bidaf/bidaf.ema")
gen = translationPerturbation()
#visualization components
visLayout = {
  "column":[{"row": ["Paragraph", 
                     "AttentionSubMatrix"]},
            {"row": ["AttentionAsymmetric"]}]
  }
#setup interface
modelVis = MCModule(visLayout)
modelVis.setPredictionHook(model.predict)
modelVis.setAttentionHook(model.attention)
modelVis.setSentenceHook(gen.perturbSentence)
#open browser for the web-based visualization
modelVis.show()
\end{lstlisting}




