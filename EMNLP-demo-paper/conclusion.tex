\section{Discussion}
In this work, we introduce a visualization library for creating customized environments that allow the user to interrogate the relationship between different parts of the model pipeline via interactive queries.
%
We demonstrate the usability and flexibility of the tool by configuring the visual components to investigate models for different NLP tasks (e.g., NLI, MC).
%
We also conducted a small-scale user evaluation, in which five Ph.D. level students with NLP background spent 30 minutes with the tool and then provided feedback. Most suggested the environment allowed them to refine queries iteratively and identify potential issues with the model, but some also mentioned the tool might not provide enough guidance for users who do not have an in-depth understanding of the model at hand.

Even though we designed the individual components with versatility in mind, due to a large number of variants of attention networks, it is hard to ensure compatibility with all the available configurations.
%
In the future, we plan to improve upon the current attention interface, release the library as an open-source package, and expand the visualization components to handle tasks such as neural machine translation and more.
